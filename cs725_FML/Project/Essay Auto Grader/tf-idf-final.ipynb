{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-26T07:06:56.963011Z","iopub.execute_input":"2022-11-26T07:06:56.963367Z","iopub.status.idle":"2022-11-26T07:06:56.976823Z","shell.execute_reply.started":"2022-11-26T07:06:56.963289Z","shell.execute_reply":"2022-11-26T07:06:56.975522Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/feedback-prize-english-language-learning/sample_submission.csv\n/kaggle/input/feedback-prize-english-language-learning/train.csv\n/kaggle/input/feedback-prize-english-language-learning/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Lambda, Flatten, Bidirectional\nfrom tensorflow.keras.models import Sequential, load_model, model_from_config\nimport tensorflow.keras.backend as K \nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.linear_model import LinearRegression","metadata":{"execution":{"iopub.status.busy":"2022-11-26T07:06:56.978533Z","iopub.execute_input":"2022-11-26T07:06:56.978971Z","iopub.status.idle":"2022-11-26T07:07:05.375682Z","shell.execute_reply.started":"2022-11-26T07:06:56.978937Z","shell.execute_reply":"2022-11-26T07:07:05.374378Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"X=pd.read_csv(\"/kaggle/input/feedback-prize-english-language-learning/train.csv\")\ntest=pd.read_csv(\"/kaggle/input/feedback-prize-english-language-learning/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-11-26T09:23:22.681141Z","iopub.execute_input":"2022-11-26T09:23:22.681547Z","iopub.status.idle":"2022-11-26T09:23:22.788866Z","shell.execute_reply.started":"2022-11-26T09:23:22.681514Z","shell.execute_reply":"2022-11-26T09:23:22.787707Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"X.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-26T09:23:23.103563Z","iopub.execute_input":"2022-11-26T09:23:23.104419Z","iopub.status.idle":"2022-11-26T09:23:23.120919Z","shell.execute_reply.started":"2022-11-26T09:23:23.104377Z","shell.execute_reply":"2022-11-26T09:23:23.119966Z"},"trusted":true},"execution_count":70,"outputs":[{"execution_count":70,"output_type":"execute_result","data":{"text/plain":"        text_id                                          full_text  cohesion  \\\n0  0016926B079C  I think that students would benefit from learn...       3.5   \n1  0022683E9EA5  When a problem is a change you have to let it ...       2.5   \n2  00299B378633  Dear, Principal\\n\\nIf u change the school poli...       3.0   \n3  003885A45F42  The best time in life is when you become yours...       4.5   \n4  0049B1DF5CCC  Small act of kindness can impact in other peop...       2.5   \n\n   syntax  vocabulary  phraseology  grammar  conventions  \n0     3.5         3.0          3.0      4.0          3.0  \n1     2.5         3.0          2.0      2.0          2.5  \n2     3.5         3.0          3.0      3.0          2.5  \n3     4.5         4.5          4.5      4.0          5.0  \n4     3.0         3.0          3.0      2.5          2.5  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text_id</th>\n      <th>full_text</th>\n      <th>cohesion</th>\n      <th>syntax</th>\n      <th>vocabulary</th>\n      <th>phraseology</th>\n      <th>grammar</th>\n      <th>conventions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0016926B079C</td>\n      <td>I think that students would benefit from learn...</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0022683E9EA5</td>\n      <td>When a problem is a change you have to let it ...</td>\n      <td>2.5</td>\n      <td>2.5</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00299B378633</td>\n      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>2.5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>003885A45F42</td>\n      <td>The best time in life is when you become yours...</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>4.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0049B1DF5CCC</td>\n      <td>Small act of kindness can impact in other peop...</td>\n      <td>2.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>2.5</td>\n      <td>2.5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-26T09:23:23.946490Z","iopub.execute_input":"2022-11-26T09:23:23.947187Z","iopub.status.idle":"2022-11-26T09:23:23.958829Z","shell.execute_reply.started":"2022-11-26T09:23:23.947147Z","shell.execute_reply":"2022-11-26T09:23:23.957547Z"},"trusted":true},"execution_count":71,"outputs":[{"execution_count":71,"output_type":"execute_result","data":{"text/plain":"        text_id                                          full_text\n0  0000C359D63E  when a person has no experience on a job their...\n1  000BAD50D026  Do you think students would benefit from being...\n2  00367BB2546B  Thomas Jefferson once states that \"it is wonde...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text_id</th>\n      <th>full_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000C359D63E</td>\n      <td>when a person has no experience on a job their...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000BAD50D026</td>\n      <td>Do you think students would benefit from being...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00367BB2546B</td>\n      <td>Thomas Jefferson once states that \"it is wonde...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"X1=X[\"full_text\"]\nt1=test[\"full_text\"]","metadata":{"execution":{"iopub.status.busy":"2022-11-26T09:23:26.616105Z","iopub.execute_input":"2022-11-26T09:23:26.616475Z","iopub.status.idle":"2022-11-26T09:23:26.623802Z","shell.execute_reply.started":"2022-11-26T09:23:26.616444Z","shell.execute_reply":"2022-11-26T09:23:26.622904Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"X1","metadata":{"execution":{"iopub.status.busy":"2022-11-26T09:23:27.039670Z","iopub.execute_input":"2022-11-26T09:23:27.040946Z","iopub.status.idle":"2022-11-26T09:23:27.049292Z","shell.execute_reply.started":"2022-11-26T09:23:27.040896Z","shell.execute_reply":"2022-11-26T09:23:27.048335Z"},"trusted":true},"execution_count":73,"outputs":[{"execution_count":73,"output_type":"execute_result","data":{"text/plain":"0       I think that students would benefit from learn...\n1       When a problem is a change you have to let it ...\n2       Dear, Principal\\n\\nIf u change the school poli...\n3       The best time in life is when you become yours...\n4       Small act of kindness can impact in other peop...\n                              ...                        \n3906    I believe using cellphones in class for educat...\n3907    Working alone, students do not have to argue w...\n3908    \"A problem is a chance for you to do your best...\n3909    Many people disagree with Albert Schweitzer's ...\n3910    Do you think that failure is the main thing fo...\nName: full_text, Length: 3911, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"t1","metadata":{"execution":{"iopub.status.busy":"2022-11-26T09:23:27.588863Z","iopub.execute_input":"2022-11-26T09:23:27.589253Z","iopub.status.idle":"2022-11-26T09:23:27.596993Z","shell.execute_reply.started":"2022-11-26T09:23:27.589220Z","shell.execute_reply":"2022-11-26T09:23:27.595874Z"},"trusted":true},"execution_count":74,"outputs":[{"execution_count":74,"output_type":"execute_result","data":{"text/plain":"0    when a person has no experience on a job their...\n1    Do you think students would benefit from being...\n2    Thomas Jefferson once states that \"it is wonde...\nName: full_text, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"X_new=X1.append(t1,ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2022-11-26T09:23:28.714256Z","iopub.execute_input":"2022-11-26T09:23:28.715020Z","iopub.status.idle":"2022-11-26T09:23:28.721266Z","shell.execute_reply.started":"2022-11-26T09:23:28.714982Z","shell.execute_reply":"2022-11-26T09:23:28.719926Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"X_new","metadata":{"execution":{"iopub.status.busy":"2022-11-26T09:23:29.185672Z","iopub.execute_input":"2022-11-26T09:23:29.186851Z","iopub.status.idle":"2022-11-26T09:23:29.196294Z","shell.execute_reply.started":"2022-11-26T09:23:29.186769Z","shell.execute_reply":"2022-11-26T09:23:29.194787Z"},"trusted":true},"execution_count":76,"outputs":[{"execution_count":76,"output_type":"execute_result","data":{"text/plain":"0       I think that students would benefit from learn...\n1       When a problem is a change you have to let it ...\n2       Dear, Principal\\n\\nIf u change the school poli...\n3       The best time in life is when you become yours...\n4       Small act of kindness can impact in other peop...\n                              ...                        \n3909    Many people disagree with Albert Schweitzer's ...\n3910    Do you think that failure is the main thing fo...\n3911    when a person has no experience on a job their...\n3912    Do you think students would benefit from being...\n3913    Thomas Jefferson once states that \"it is wonde...\nName: full_text, Length: 3914, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"tfidf = TfidfVectorizer()\nresult = tfidf.fit_transform(X_new)","metadata":{"execution":{"iopub.status.busy":"2022-11-26T09:23:30.177372Z","iopub.execute_input":"2022-11-26T09:23:30.177789Z","iopub.status.idle":"2022-11-26T09:23:31.325946Z","shell.execute_reply.started":"2022-11-26T09:23:30.177756Z","shell.execute_reply":"2022-11-26T09:23:31.324831Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"tfidf=result.toarray()","metadata":{"execution":{"iopub.status.busy":"2022-11-26T09:23:31.327564Z","iopub.execute_input":"2022-11-26T09:23:31.327922Z","iopub.status.idle":"2022-11-26T09:23:32.223342Z","shell.execute_reply.started":"2022-11-26T09:23:31.327890Z","shell.execute_reply":"2022-11-26T09:23:32.222308Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"tfidf.shape","metadata":{"execution":{"iopub.status.busy":"2022-11-26T09:23:32.225567Z","iopub.execute_input":"2022-11-26T09:23:32.226036Z","iopub.status.idle":"2022-11-26T09:23:32.234179Z","shell.execute_reply.started":"2022-11-26T09:23:32.225991Z","shell.execute_reply":"2022-11-26T09:23:32.232917Z"},"trusted":true},"execution_count":79,"outputs":[{"execution_count":79,"output_type":"execute_result","data":{"text/plain":"(3914, 21370)"},"metadata":{}}]},{"cell_type":"code","source":"X2=tfidf[:len(X1)]\ntest=tfidf[len(X1):]","metadata":{"execution":{"iopub.status.busy":"2022-11-26T09:23:32.626330Z","iopub.execute_input":"2022-11-26T09:23:32.626733Z","iopub.status.idle":"2022-11-26T09:23:32.632545Z","shell.execute_reply.started":"2022-11-26T09:23:32.626698Z","shell.execute_reply":"2022-11-26T09:23:32.631318Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"test.shape","metadata":{"execution":{"iopub.status.busy":"2022-11-26T09:23:34.786769Z","iopub.execute_input":"2022-11-26T09:23:34.787156Z","iopub.status.idle":"2022-11-26T09:23:34.793607Z","shell.execute_reply.started":"2022-11-26T09:23:34.787125Z","shell.execute_reply":"2022-11-26T09:23:34.792594Z"},"trusted":true},"execution_count":81,"outputs":[{"execution_count":81,"output_type":"execute_result","data":{"text/plain":"(3, 21370)"},"metadata":{}}]},{"cell_type":"code","source":"X.shape","metadata":{"execution":{"iopub.status.busy":"2022-11-26T09:23:36.834997Z","iopub.execute_input":"2022-11-26T09:23:36.835406Z","iopub.status.idle":"2022-11-26T09:23:36.841675Z","shell.execute_reply.started":"2022-11-26T09:23:36.835371Z","shell.execute_reply":"2022-11-26T09:23:36.840705Z"},"trusted":true},"execution_count":82,"outputs":[{"execution_count":82,"output_type":"execute_result","data":{"text/plain":"(3911, 8)"},"metadata":{}}]},{"cell_type":"code","source":"X2.shape","metadata":{"execution":{"iopub.status.busy":"2022-11-26T09:23:37.839517Z","iopub.execute_input":"2022-11-26T09:23:37.840179Z","iopub.status.idle":"2022-11-26T09:23:37.847147Z","shell.execute_reply.started":"2022-11-26T09:23:37.840142Z","shell.execute_reply":"2022-11-26T09:23:37.845936Z"},"trusted":true},"execution_count":83,"outputs":[{"execution_count":83,"output_type":"execute_result","data":{"text/plain":"(3911, 21370)"},"metadata":{}}]},{"cell_type":"code","source":"IP=X2.shape[1]\nIP","metadata":{"execution":{"iopub.status.busy":"2022-11-26T09:23:38.685710Z","iopub.execute_input":"2022-11-26T09:23:38.686317Z","iopub.status.idle":"2022-11-26T09:23:38.692054Z","shell.execute_reply.started":"2022-11-26T09:23:38.686282Z","shell.execute_reply":"2022-11-26T09:23:38.691058Z"},"trusted":true},"execution_count":84,"outputs":[{"execution_count":84,"output_type":"execute_result","data":{"text/plain":"21370"},"metadata":{}}]},{"cell_type":"code","source":"L=int(len(X.index))\nL","metadata":{"execution":{"iopub.status.busy":"2022-11-26T09:23:39.691162Z","iopub.execute_input":"2022-11-26T09:23:39.691565Z","iopub.status.idle":"2022-11-26T09:23:39.697306Z","shell.execute_reply.started":"2022-11-26T09:23:39.691530Z","shell.execute_reply":"2022-11-26T09:23:39.696384Z"},"trusted":true},"execution_count":85,"outputs":[{"execution_count":85,"output_type":"execute_result","data":{"text/plain":"3911"},"metadata":{}}]},{"cell_type":"code","source":"X1_train = X.loc[:int(L*0.8)]\ny_train = X1_train[['syntax','cohesion','vocabulary','phraseology','grammar','conventions']]\nX1_val = X.loc[int(L*0.8)+1:int(L*0.9)]\ny_val = X1_val[['syntax','cohesion','vocabulary','phraseology','grammar','conventions']]\nX1_test = X.loc[int(L*0.9)+1:]\ny_test = X1_test[['syntax','cohesion','vocabulary','phraseology','grammar','conventions']]","metadata":{"execution":{"iopub.status.busy":"2022-11-26T09:23:40.939460Z","iopub.execute_input":"2022-11-26T09:23:40.940183Z","iopub.status.idle":"2022-11-26T09:23:40.951720Z","shell.execute_reply.started":"2022-11-26T09:23:40.940039Z","shell.execute_reply":"2022-11-26T09:23:40.950856Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"tfidf_train=X2[:int(len(X.index)*0.8)+1]\ntfidf_val=X2[int(len(X.index)*0.8)+1:int(len(X.index)*0.9)+1]\ntfidf_test=X2[int(len(X.index)*0.9)+1:]","metadata":{"execution":{"iopub.status.busy":"2022-11-26T09:23:42.371830Z","iopub.execute_input":"2022-11-26T09:23:42.372604Z","iopub.status.idle":"2022-11-26T09:23:42.447423Z","shell.execute_reply.started":"2022-11-26T09:23:42.372568Z","shell.execute_reply":"2022-11-26T09:23:42.446156Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"y1_train=y_train[\"syntax\"]\ny2_train=y_train[\"cohesion\"]\ny3_train=y_train[\"vocabulary\"]\ny4_train=y_train[\"phraseology\"]\ny5_train=y_train[\"grammar\"]\ny6_train=y_train[\"conventions\"]\n\ny1_val=y_val[\"syntax\"]\ny2_val=y_val[\"cohesion\"]\ny3_val=y_val[\"vocabulary\"]\ny4_val=y_val[\"phraseology\"]\ny5_val=y_val[\"grammar\"]\ny6_val=y_val[\"conventions\"]\n\ny1_test=y_test[\"syntax\"]\ny2_test=y_test[\"cohesion\"]\ny3_test=y_test[\"vocabulary\"]\ny4_test=y_test[\"phraseology\"]\ny5_test=y_test[\"grammar\"]\ny6_test=y_test[\"conventions\"]\n","metadata":{"execution":{"iopub.status.busy":"2022-11-26T09:23:44.226310Z","iopub.execute_input":"2022-11-26T09:23:44.226707Z","iopub.status.idle":"2022-11-26T09:23:44.237666Z","shell.execute_reply.started":"2022-11-26T09:23:44.226675Z","shell.execute_reply":"2022-11-26T09:23:44.236688Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"print(tfidf_train.shape)\nprint(y1_train.shape)\nprint(tfidf_val.shape)\nprint(y1_val.shape)\nprint(tfidf_test.shape)\nprint(y1_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-11-26T09:23:45.234199Z","iopub.execute_input":"2022-11-26T09:23:45.234574Z","iopub.status.idle":"2022-11-26T09:23:45.241627Z","shell.execute_reply.started":"2022-11-26T09:23:45.234543Z","shell.execute_reply":"2022-11-26T09:23:45.240369Z"},"trusted":true},"execution_count":89,"outputs":[{"name":"stdout","text":"(3129, 21370)\n(3129,)\n(391, 21370)\n(391,)\n(391, 21370)\n(391,)\n","output_type":"stream"}]},{"cell_type":"code","source":"y1_train = np.asarray(y1_train)\ny1_val = np.asarray(y1_val)  \ny1_test = np.asarray(y1_test)\n\ny2_train = np.asarray(y2_train)\ny2_val = np.asarray(y2_val)  \ny2_test = np.asarray(y2_test)\n\ny3_train = np.asarray(y3_train)\ny3_val = np.asarray(y3_val)\ny3_test = np.asarray(y3_test)\n\ny4_train = np.asarray(y4_train)\ny4_val = np.asarray(y4_val)  \ny4_test = np.asarray(y4_test)  \n\ny5_train = np.asarray(y5_train)\ny5_val = np.asarray(y5_val)\ny5_test = np.asarray(y5_test)\n\ny6_train = np.asarray(y6_train)\ny6_val = np.asarray(y6_val)  \ny6_test = np.asarray(y6_test)","metadata":{"execution":{"iopub.status.busy":"2022-11-26T09:23:46.163500Z","iopub.execute_input":"2022-11-26T09:23:46.163916Z","iopub.status.idle":"2022-11-26T09:23:46.173043Z","shell.execute_reply.started":"2022-11-26T09:23:46.163881Z","shell.execute_reply":"2022-11-26T09:23:46.171576Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"markdown","source":"# Liner Regression :","metadata":{}},{"cell_type":"code","source":"lr1 = LinearRegression()\nlr2 = LinearRegression()\nlr3 = LinearRegression()\nlr4 = LinearRegression()\nlr5 = LinearRegression()\nlr6 = LinearRegression()","metadata":{"execution":{"iopub.status.busy":"2022-11-26T07:07:11.563673Z","iopub.execute_input":"2022-11-26T07:07:11.564580Z","iopub.status.idle":"2022-11-26T07:07:11.570788Z","shell.execute_reply.started":"2022-11-26T07:07:11.564532Z","shell.execute_reply":"2022-11-26T07:07:11.569309Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"lr1.fit(tfidf_train, y1_train)\nlr2.fit(tfidf_train, y2_train)\nlr3.fit(tfidf_train, y3_train)\nlr4.fit(tfidf_train, y4_train)\nlr5.fit(tfidf_train, y5_train)\nlr6.fit(tfidf_train, y6_train)","metadata":{"execution":{"iopub.status.busy":"2022-11-26T07:07:11.759911Z","iopub.execute_input":"2022-11-26T07:07:11.761022Z","iopub.status.idle":"2022-11-26T07:09:45.189676Z","shell.execute_reply.started":"2022-11-26T07:07:11.760978Z","shell.execute_reply":"2022-11-26T07:09:45.187573Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"LinearRegression()"},"metadata":{}}]},{"cell_type":"code","source":"y1_pred = lr1.predict(tfidf_test)\ny2_pred = lr2.predict(tfidf_test)\ny3_pred = lr3.predict(tfidf_test)\ny4_pred = lr4.predict(tfidf_test)\ny5_pred = lr5.predict(tfidf_test)\ny6_pred = lr6.predict(tfidf_test)","metadata":{"execution":{"iopub.status.busy":"2022-11-26T07:09:45.195509Z","iopub.execute_input":"2022-11-26T07:09:45.198040Z","iopub.status.idle":"2022-11-26T07:09:45.348523Z","shell.execute_reply.started":"2022-11-26T07:09:45.197967Z","shell.execute_reply":"2022-11-26T07:09:45.346914Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"y1_pred = [round(r,1) for r in y1_pred]\ny2_pred = [round(r,1) for r in y2_pred]\ny3_pred = [round(r,1) for r in y3_pred]\ny4_pred = [round(r,1) for r in y4_pred]\ny5_pred = [round(r,1) for r in y5_pred]\ny6_pred = [round(r,1) for r in y6_pred]","metadata":{"execution":{"iopub.status.busy":"2022-11-26T07:09:45.380540Z","iopub.execute_input":"2022-11-26T07:09:45.388390Z","iopub.status.idle":"2022-11-26T07:09:45.438148Z","shell.execute_reply.started":"2022-11-26T07:09:45.388287Z","shell.execute_reply":"2022-11-26T07:09:45.436526Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"values1 = mean_squared_error(y1_pred, y1_test)\nvalues2 = mean_squared_error(y2_pred, y2_test)\nvalues3 = mean_squared_error(y3_pred, y3_test)\nvalues4 = mean_squared_error(y4_pred, y4_test)\nvalues5 = mean_squared_error(y5_pred, y5_test)\nvalues6 = mean_squared_error(y6_pred, y6_test)","metadata":{"execution":{"iopub.status.busy":"2022-11-26T07:09:45.447497Z","iopub.execute_input":"2022-11-26T07:09:45.448632Z","iopub.status.idle":"2022-11-26T07:09:45.471286Z","shell.execute_reply.started":"2022-11-26T07:09:45.448566Z","shell.execute_reply":"2022-11-26T07:09:45.470221Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"Test error for Linear Regression: ","metadata":{}},{"cell_type":"code","source":"test_error=values1+values2+values3+values4+values5+values6\ntest_mcrmse= test_error/6\ntest_mcrmse","metadata":{"execution":{"iopub.status.busy":"2022-11-26T07:09:45.474052Z","iopub.execute_input":"2022-11-26T07:09:45.475480Z","iopub.status.idle":"2022-11-26T07:09:45.485744Z","shell.execute_reply.started":"2022-11-26T07:09:45.475428Z","shell.execute_reply":"2022-11-26T07:09:45.484571Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"0.5202514919011082"},"metadata":{}}]},{"cell_type":"markdown","source":"# SVR :","metadata":{}},{"cell_type":"code","source":"clf1 = SVR(C=10.0, epsilon=0.01)\nclf2 = SVR(C=10.0, epsilon=0.01)\nclf3 = SVR(C=10.0, epsilon=0.01)\nclf4 = SVR(C=10.0, epsilon=0.01)\nclf5 = SVR(C=10.0, epsilon=0.01)\nclf6 = SVR(C=10.0, epsilon=0.01)","metadata":{"execution":{"iopub.status.busy":"2022-11-26T07:09:45.489422Z","iopub.execute_input":"2022-11-26T07:09:45.490038Z","iopub.status.idle":"2022-11-26T07:09:45.499867Z","shell.execute_reply.started":"2022-11-26T07:09:45.490004Z","shell.execute_reply":"2022-11-26T07:09:45.498225Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"clf1.fit(tfidf_train, y1_train)\nclf2.fit(tfidf_train, y2_train)\nclf3.fit(tfidf_train, y3_train)\nclf4.fit(tfidf_train, y4_train)\nclf5.fit(tfidf_train, y5_train)\nclf6.fit(tfidf_train, y6_train)","metadata":{"execution":{"iopub.status.busy":"2022-11-26T07:09:45.503088Z","iopub.execute_input":"2022-11-26T07:09:45.503685Z","iopub.status.idle":"2022-11-26T07:21:01.618276Z","shell.execute_reply.started":"2022-11-26T07:09:45.503648Z","shell.execute_reply":"2022-11-26T07:21:01.617022Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"SVR(C=10.0, epsilon=0.01)"},"metadata":{}}]},{"cell_type":"code","source":"y1_pred = clf1.predict(tfidf_test)\ny2_pred = clf2.predict(tfidf_test)\ny3_pred = clf3.predict(tfidf_test)\ny4_pred = clf4.predict(tfidf_test)\ny5_pred = clf5.predict(tfidf_test)\ny6_pred = clf6.predict(tfidf_test)","metadata":{"execution":{"iopub.status.busy":"2022-11-26T07:21:01.620408Z","iopub.execute_input":"2022-11-26T07:21:01.620892Z","iopub.status.idle":"2022-11-26T07:26:56.674034Z","shell.execute_reply.started":"2022-11-26T07:21:01.620814Z","shell.execute_reply":"2022-11-26T07:26:56.672333Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"values1 = mean_squared_error(y1_pred, y1_test)\nvalues2 = mean_squared_error(y2_pred, y2_test)\nvalues3 = mean_squared_error(y3_pred, y3_test)\nvalues4 = mean_squared_error(y4_pred, y4_test)\nvalues5 = mean_squared_error(y5_pred, y5_test)\nvalues6 = mean_squared_error(y6_pred, y6_test)","metadata":{"execution":{"iopub.status.busy":"2022-11-26T07:26:56.676673Z","iopub.execute_input":"2022-11-26T07:26:56.677977Z","iopub.status.idle":"2022-11-26T07:26:56.691456Z","shell.execute_reply.started":"2022-11-26T07:26:56.677906Z","shell.execute_reply":"2022-11-26T07:26:56.689924Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"Test error for SVR:","metadata":{}},{"cell_type":"code","source":"test_error=values1+values2+values3+values4+values5+values6\ntest_mcrmse= test_error/6\ntest_mcrmse","metadata":{"execution":{"iopub.status.busy":"2022-11-26T07:26:56.698536Z","iopub.execute_input":"2022-11-26T07:26:56.699945Z","iopub.status.idle":"2022-11-26T07:26:56.712598Z","shell.execute_reply.started":"2022-11-26T07:26:56.699872Z","shell.execute_reply":"2022-11-26T07:26:56.711076Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"0.29236973563330615"},"metadata":{}}]},{"cell_type":"markdown","source":"# Feedforward Neural Net","metadata":{}},{"cell_type":"code","source":"def get_model_nn():\n    model = tf.keras.Sequential()\n    model.add(tf.keras.layers.Dense(input_dim=IP,units=100, activation='tanh'))\n    model.add(Dropout(0.2))\n    model.add(tf.keras.layers.Dense(75, activation='tanh'))\n    model.add(Dropout(0.2))\n    model.add(tf.keras.layers.Dense(10, activation='tanh'))\n    model.add(Dropout(0.2))\n    model.add(tf.keras.layers.Dense(1, activation='relu'))\n    print(model.summary())\n    model.compile(optimizer='rmsprop', loss='mean_squared_error', metrics=['accuracy'])\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-11-26T09:23:54.765019Z","iopub.execute_input":"2022-11-26T09:23:54.765589Z","iopub.status.idle":"2022-11-26T09:23:54.774825Z","shell.execute_reply.started":"2022-11-26T09:23:54.765546Z","shell.execute_reply":"2022-11-26T09:23:54.773431Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"embedding_model1 = get_model_nn()\nembedding_model2 = get_model_nn()\nembedding_model3 = get_model_nn()\nembedding_model4= get_model_nn()\nembedding_model5 = get_model_nn()\nembedding_model6 = get_model_nn()","metadata":{"execution":{"iopub.status.busy":"2022-11-26T07:36:45.806968Z","iopub.execute_input":"2022-11-26T07:36:45.807668Z","iopub.status.idle":"2022-11-26T07:36:46.293708Z","shell.execute_reply.started":"2022-11-26T07:36:45.807634Z","shell.execute_reply":"2022-11-26T07:36:46.292520Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stderr","text":"2022-11-26 07:36:45.847482: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n","output_type":"stream"},{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 100)               2137100   \n_________________________________________________________________\ndropout (Dropout)            (None, 100)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 75)                7575      \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 75)                0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 10)                760       \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 10)                0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 1)                 11        \n=================================================================\nTotal params: 2,145,446\nTrainable params: 2,145,446\nNon-trainable params: 0\n_________________________________________________________________\nNone\nModel: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_4 (Dense)              (None, 100)               2137100   \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 100)               0         \n_________________________________________________________________\ndense_5 (Dense)              (None, 75)                7575      \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 75)                0         \n_________________________________________________________________\ndense_6 (Dense)              (None, 10)                760       \n_________________________________________________________________\ndropout_5 (Dropout)          (None, 10)                0         \n_________________________________________________________________\ndense_7 (Dense)              (None, 1)                 11        \n=================================================================\nTotal params: 2,145,446\nTrainable params: 2,145,446\nNon-trainable params: 0\n_________________________________________________________________\nNone\nModel: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_8 (Dense)              (None, 100)               2137100   \n_________________________________________________________________\ndropout_6 (Dropout)          (None, 100)               0         \n_________________________________________________________________\ndense_9 (Dense)              (None, 75)                7575      \n_________________________________________________________________\ndropout_7 (Dropout)          (None, 75)                0         \n_________________________________________________________________\ndense_10 (Dense)             (None, 10)                760       \n_________________________________________________________________\ndropout_8 (Dropout)          (None, 10)                0         \n_________________________________________________________________\ndense_11 (Dense)             (None, 1)                 11        \n=================================================================\nTotal params: 2,145,446\nTrainable params: 2,145,446\nNon-trainable params: 0\n_________________________________________________________________\nNone\nModel: \"sequential_3\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_12 (Dense)             (None, 100)               2137100   \n_________________________________________________________________\ndropout_9 (Dropout)          (None, 100)               0         \n_________________________________________________________________\ndense_13 (Dense)             (None, 75)                7575      \n_________________________________________________________________\ndropout_10 (Dropout)         (None, 75)                0         \n_________________________________________________________________\ndense_14 (Dense)             (None, 10)                760       \n_________________________________________________________________\ndropout_11 (Dropout)         (None, 10)                0         \n_________________________________________________________________\ndense_15 (Dense)             (None, 1)                 11        \n=================================================================\nTotal params: 2,145,446\nTrainable params: 2,145,446\nNon-trainable params: 0\n_________________________________________________________________\nNone\nModel: \"sequential_4\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_16 (Dense)             (None, 100)               2137100   \n_________________________________________________________________\ndropout_12 (Dropout)         (None, 100)               0         \n_________________________________________________________________\ndense_17 (Dense)             (None, 75)                7575      \n_________________________________________________________________\ndropout_13 (Dropout)         (None, 75)                0         \n_________________________________________________________________\ndense_18 (Dense)             (None, 10)                760       \n_________________________________________________________________\ndropout_14 (Dropout)         (None, 10)                0         \n_________________________________________________________________\ndense_19 (Dense)             (None, 1)                 11        \n=================================================================\nTotal params: 2,145,446\nTrainable params: 2,145,446\nNon-trainable params: 0\n_________________________________________________________________\nNone\nModel: \"sequential_5\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_20 (Dense)             (None, 100)               2137100   \n_________________________________________________________________\ndropout_15 (Dropout)         (None, 100)               0         \n_________________________________________________________________\ndense_21 (Dense)             (None, 75)                7575      \n_________________________________________________________________\ndropout_16 (Dropout)         (None, 75)                0         \n_________________________________________________________________\ndense_22 (Dense)             (None, 10)                760       \n_________________________________________________________________\ndropout_17 (Dropout)         (None, 10)                0         \n_________________________________________________________________\ndense_23 (Dense)             (None, 1)                 11        \n=================================================================\nTotal params: 2,145,446\nTrainable params: 2,145,446\nNon-trainable params: 0\n_________________________________________________________________\nNone\n","output_type":"stream"}]},{"cell_type":"code","source":"h1=embedding_model1.fit(tfidf_train, y1_train, epochs=100,validation_data=(tfidf_val,y1_val))","metadata":{"execution":{"iopub.status.busy":"2022-11-26T09:24:16.885623Z","iopub.execute_input":"2022-11-26T09:24:16.886088Z","iopub.status.idle":"2022-11-26T09:26:53.633607Z","shell.execute_reply.started":"2022-11-26T09:24:16.886051Z","shell.execute_reply":"2022-11-26T09:26:53.632330Z"},"trusted":true},"execution_count":93,"outputs":[{"name":"stdout","text":"Epoch 1/100\n98/98 [==============================] - 3s 18ms/step - loss: 0.8532 - accuracy: 0.0029 - val_loss: 0.3248 - val_accuracy: 0.0026\nEpoch 2/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.5023 - accuracy: 0.0029 - val_loss: 0.3339 - val_accuracy: 0.0026\nEpoch 3/100\n98/98 [==============================] - 2s 23ms/step - loss: 0.4523 - accuracy: 0.0026 - val_loss: 0.3772 - val_accuracy: 0.0026\nEpoch 4/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.4160 - accuracy: 0.0026 - val_loss: 0.3319 - val_accuracy: 0.0026\nEpoch 5/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.3879 - accuracy: 0.0029 - val_loss: 0.3698 - val_accuracy: 0.0026\nEpoch 6/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.3664 - accuracy: 0.0029 - val_loss: 0.3578 - val_accuracy: 0.0026\nEpoch 7/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.3360 - accuracy: 0.0029 - val_loss: 0.3662 - val_accuracy: 0.0026\nEpoch 8/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.3263 - accuracy: 0.0029 - val_loss: 0.3580 - val_accuracy: 0.0026\nEpoch 9/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.3181 - accuracy: 0.0026 - val_loss: 0.3956 - val_accuracy: 0.0026\nEpoch 10/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.2993 - accuracy: 0.0029 - val_loss: 0.3934 - val_accuracy: 0.0026\nEpoch 11/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.2821 - accuracy: 0.0026 - val_loss: 0.3939 - val_accuracy: 0.0026\nEpoch 12/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.2657 - accuracy: 0.0029 - val_loss: 0.4336 - val_accuracy: 0.0026\nEpoch 13/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.2798 - accuracy: 0.0026 - val_loss: 0.3981 - val_accuracy: 0.0026\nEpoch 14/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.2475 - accuracy: 0.0029 - val_loss: 0.3972 - val_accuracy: 0.0026\nEpoch 15/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.2440 - accuracy: 0.0026 - val_loss: 0.4053 - val_accuracy: 0.0026\nEpoch 16/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.2345 - accuracy: 0.0029 - val_loss: 0.3991 - val_accuracy: 0.0026\nEpoch 17/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.2120 - accuracy: 0.0029 - val_loss: 0.4023 - val_accuracy: 0.0026\nEpoch 18/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.2199 - accuracy: 0.0029 - val_loss: 0.4057 - val_accuracy: 0.0026\nEpoch 19/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.2088 - accuracy: 0.0026 - val_loss: 0.4428 - val_accuracy: 0.0026\nEpoch 20/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.2064 - accuracy: 0.0029 - val_loss: 0.3980 - val_accuracy: 0.0026\nEpoch 21/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.1972 - accuracy: 0.0029 - val_loss: 0.4113 - val_accuracy: 0.0026\nEpoch 22/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.1900 - accuracy: 0.0029 - val_loss: 0.4205 - val_accuracy: 0.0026\nEpoch 23/100\n98/98 [==============================] - 2s 23ms/step - loss: 0.1838 - accuracy: 0.0029 - val_loss: 0.4191 - val_accuracy: 0.0026\nEpoch 24/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.1740 - accuracy: 0.0029 - val_loss: 0.4171 - val_accuracy: 0.0026\nEpoch 25/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.1631 - accuracy: 0.0029 - val_loss: 0.4255 - val_accuracy: 0.0026\nEpoch 26/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.1641 - accuracy: 0.0029 - val_loss: 0.4154 - val_accuracy: 0.0026\nEpoch 27/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.1464 - accuracy: 0.0026 - val_loss: 0.4092 - val_accuracy: 0.0026\nEpoch 28/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.1482 - accuracy: 0.0029 - val_loss: 0.3970 - val_accuracy: 0.0026\nEpoch 29/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.1374 - accuracy: 0.0029 - val_loss: 0.4111 - val_accuracy: 0.0026\nEpoch 30/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.1402 - accuracy: 0.0029 - val_loss: 0.4269 - val_accuracy: 0.0026\nEpoch 31/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.1341 - accuracy: 0.0029 - val_loss: 0.4558 - val_accuracy: 0.0026\nEpoch 32/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.1211 - accuracy: 0.0029 - val_loss: 0.4115 - val_accuracy: 0.0026\nEpoch 33/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.1252 - accuracy: 0.0026 - val_loss: 0.4308 - val_accuracy: 0.0026\nEpoch 34/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.1135 - accuracy: 0.0029 - val_loss: 0.4295 - val_accuracy: 0.0026\nEpoch 35/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.1139 - accuracy: 0.0026 - val_loss: 0.4386 - val_accuracy: 0.0026\nEpoch 36/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.1091 - accuracy: 0.0029 - val_loss: 0.3972 - val_accuracy: 0.0026\nEpoch 37/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.1003 - accuracy: 0.0029 - val_loss: 0.4285 - val_accuracy: 0.0026\nEpoch 38/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0986 - accuracy: 0.0029 - val_loss: 0.4335 - val_accuracy: 0.0026\nEpoch 39/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0903 - accuracy: 0.0029 - val_loss: 0.4541 - val_accuracy: 0.0026\nEpoch 40/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0955 - accuracy: 0.0026 - val_loss: 0.4096 - val_accuracy: 0.0026\nEpoch 41/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0910 - accuracy: 0.0029 - val_loss: 0.4394 - val_accuracy: 0.0026\nEpoch 42/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0851 - accuracy: 0.0029 - val_loss: 0.4444 - val_accuracy: 0.0026\nEpoch 43/100\n98/98 [==============================] - 2s 20ms/step - loss: 0.0802 - accuracy: 0.0029 - val_loss: 0.4480 - val_accuracy: 0.0026\nEpoch 44/100\n98/98 [==============================] - 2s 19ms/step - loss: 0.0740 - accuracy: 0.0029 - val_loss: 0.4222 - val_accuracy: 0.0026\nEpoch 45/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0746 - accuracy: 0.0026 - val_loss: 0.4357 - val_accuracy: 0.0026\nEpoch 46/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0700 - accuracy: 0.0029 - val_loss: 0.4338 - val_accuracy: 0.0026\nEpoch 47/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0697 - accuracy: 0.0029 - val_loss: 0.4317 - val_accuracy: 0.0026\nEpoch 48/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0687 - accuracy: 0.0029 - val_loss: 0.4368 - val_accuracy: 0.0026\nEpoch 49/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0643 - accuracy: 0.0029 - val_loss: 0.4537 - val_accuracy: 0.0026\nEpoch 50/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0602 - accuracy: 0.0029 - val_loss: 0.4525 - val_accuracy: 0.0026\nEpoch 51/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0601 - accuracy: 0.0029 - val_loss: 0.4490 - val_accuracy: 0.0026\nEpoch 52/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0580 - accuracy: 0.0029 - val_loss: 0.4067 - val_accuracy: 0.0026\nEpoch 53/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0581 - accuracy: 0.0026 - val_loss: 0.4529 - val_accuracy: 0.0026\nEpoch 54/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0528 - accuracy: 0.0029 - val_loss: 0.4494 - val_accuracy: 0.0026\nEpoch 55/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0524 - accuracy: 0.0029 - val_loss: 0.4300 - val_accuracy: 0.0026\nEpoch 56/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0495 - accuracy: 0.0029 - val_loss: 0.4068 - val_accuracy: 0.0026\nEpoch 57/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0490 - accuracy: 0.0029 - val_loss: 0.4448 - val_accuracy: 0.0026\nEpoch 58/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0477 - accuracy: 0.0029 - val_loss: 0.4440 - val_accuracy: 0.0026\nEpoch 59/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0480 - accuracy: 0.0026 - val_loss: 0.4410 - val_accuracy: 0.0026\nEpoch 60/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0427 - accuracy: 0.0029 - val_loss: 0.4365 - val_accuracy: 0.0026\nEpoch 61/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0413 - accuracy: 0.0029 - val_loss: 0.4515 - val_accuracy: 0.0026\nEpoch 62/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0411 - accuracy: 0.0029 - val_loss: 0.4182 - val_accuracy: 0.0026\nEpoch 63/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0399 - accuracy: 0.0029 - val_loss: 0.4243 - val_accuracy: 0.0026\nEpoch 64/100\n98/98 [==============================] - 2s 23ms/step - loss: 0.0403 - accuracy: 0.0026 - val_loss: 0.4361 - val_accuracy: 0.0026\nEpoch 65/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0392 - accuracy: 0.0029 - val_loss: 0.4498 - val_accuracy: 0.0026\nEpoch 66/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0374 - accuracy: 0.0026 - val_loss: 0.4527 - val_accuracy: 0.0026\nEpoch 67/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0343 - accuracy: 0.0029 - val_loss: 0.4405 - val_accuracy: 0.0026\nEpoch 68/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0352 - accuracy: 0.0029 - val_loss: 0.4731 - val_accuracy: 0.0026\nEpoch 69/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0320 - accuracy: 0.0029 - val_loss: 0.4406 - val_accuracy: 0.0026\nEpoch 70/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0327 - accuracy: 0.0026 - val_loss: 0.4380 - val_accuracy: 0.0026\nEpoch 71/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0322 - accuracy: 0.0029 - val_loss: 0.4254 - val_accuracy: 0.0026\nEpoch 72/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0334 - accuracy: 0.0029 - val_loss: 0.4354 - val_accuracy: 0.0026\nEpoch 73/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0299 - accuracy: 0.0029 - val_loss: 0.4217 - val_accuracy: 0.0026\nEpoch 74/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0307 - accuracy: 0.0026 - val_loss: 0.4515 - val_accuracy: 0.0026\nEpoch 75/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0323 - accuracy: 0.0029 - val_loss: 0.4692 - val_accuracy: 0.0026\nEpoch 76/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0297 - accuracy: 0.0029 - val_loss: 0.4432 - val_accuracy: 0.0026\nEpoch 77/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0271 - accuracy: 0.0026 - val_loss: 0.4429 - val_accuracy: 0.0026\nEpoch 78/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0272 - accuracy: 0.0029 - val_loss: 0.4621 - val_accuracy: 0.0026\nEpoch 79/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0298 - accuracy: 0.0029 - val_loss: 0.4327 - val_accuracy: 0.0026\nEpoch 80/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0267 - accuracy: 0.0026 - val_loss: 0.4136 - val_accuracy: 0.0026\nEpoch 81/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0264 - accuracy: 0.0029 - val_loss: 0.4475 - val_accuracy: 0.0026\nEpoch 82/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0247 - accuracy: 0.0029 - val_loss: 0.4537 - val_accuracy: 0.0026\nEpoch 83/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0249 - accuracy: 0.0029 - val_loss: 0.4345 - val_accuracy: 0.0026\nEpoch 84/100\n98/98 [==============================] - 2s 23ms/step - loss: 0.0244 - accuracy: 0.0026 - val_loss: 0.4181 - val_accuracy: 0.0026\nEpoch 85/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0263 - accuracy: 0.0029 - val_loss: 0.4531 - val_accuracy: 0.0026\nEpoch 86/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0249 - accuracy: 0.0029 - val_loss: 0.4418 - val_accuracy: 0.0026\nEpoch 87/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0241 - accuracy: 0.0029 - val_loss: 0.4571 - val_accuracy: 0.0026\nEpoch 88/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0241 - accuracy: 0.0029 - val_loss: 0.4626 - val_accuracy: 0.0026\nEpoch 89/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0238 - accuracy: 0.0029 - val_loss: 0.4703 - val_accuracy: 0.0026\nEpoch 90/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0232 - accuracy: 0.0029 - val_loss: 0.4499 - val_accuracy: 0.0026\nEpoch 91/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0223 - accuracy: 0.0029 - val_loss: 0.4285 - val_accuracy: 0.0026\nEpoch 92/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0240 - accuracy: 0.0029 - val_loss: 0.4672 - val_accuracy: 0.0026\nEpoch 93/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0224 - accuracy: 0.0029 - val_loss: 0.4526 - val_accuracy: 0.0026\nEpoch 94/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0218 - accuracy: 0.0029 - val_loss: 0.4904 - val_accuracy: 0.0026\nEpoch 95/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0228 - accuracy: 0.0029 - val_loss: 0.4483 - val_accuracy: 0.0026\nEpoch 96/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0226 - accuracy: 0.0022 - val_loss: 0.4650 - val_accuracy: 0.0026\nEpoch 97/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0229 - accuracy: 0.0029 - val_loss: 0.4588 - val_accuracy: 0.0026\nEpoch 98/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0214 - accuracy: 0.0029 - val_loss: 0.4479 - val_accuracy: 0.0026\nEpoch 99/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0212 - accuracy: 0.0029 - val_loss: 0.4407 - val_accuracy: 0.0026\nEpoch 100/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0224 - accuracy: 0.0029 - val_loss: 0.4663 - val_accuracy: 0.0026\n","output_type":"stream"}]},{"cell_type":"code","source":"h2=embedding_model2.fit(tfidf_train, y2_train, epochs=100,validation_data=(tfidf_val,y2_val))\nh3=embedding_model3.fit(tfidf_train, y3_train, epochs=100,validation_data=(tfidf_val,y3_val))\nh4=embedding_model4.fit(tfidf_train, y4_train, epochs=100,validation_data=(tfidf_val,y4_val))\nh5=embedding_model5.fit(tfidf_train, y5_train, epochs=100,validation_data=(tfidf_val,y5_val))\nh6=embedding_model6.fit(tfidf_train, y6_train, epochs=100,validation_data=(tfidf_val,y6_val))","metadata":{"execution":{"iopub.status.busy":"2022-11-26T07:39:24.277005Z","iopub.execute_input":"2022-11-26T07:39:24.277466Z","iopub.status.idle":"2022-11-26T07:53:11.033332Z","shell.execute_reply.started":"2022-11-26T07:39:24.277430Z","shell.execute_reply":"2022-11-26T07:53:11.031782Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"Epoch 1/100\n98/98 [==============================] - 3s 18ms/step - loss: 0.9945 - accuracy: 0.0022 - val_loss: 0.3980 - val_accuracy: 0.0026\nEpoch 2/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.5451 - accuracy: 0.0022 - val_loss: 0.3302 - val_accuracy: 0.0026\nEpoch 3/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.4917 - accuracy: 0.0019 - val_loss: 0.3325 - val_accuracy: 0.0026\nEpoch 4/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.4626 - accuracy: 0.0019 - val_loss: 0.3430 - val_accuracy: 0.0026\nEpoch 5/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.4228 - accuracy: 0.0013 - val_loss: 0.3420 - val_accuracy: 0.0026\nEpoch 6/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.4137 - accuracy: 0.0019 - val_loss: 0.3896 - val_accuracy: 0.0026\nEpoch 7/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.3676 - accuracy: 0.0013 - val_loss: 0.3710 - val_accuracy: 0.0026\nEpoch 8/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.3414 - accuracy: 0.0019 - val_loss: 0.3713 - val_accuracy: 0.0026\nEpoch 9/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.3170 - accuracy: 0.0022 - val_loss: 0.3537 - val_accuracy: 0.0026\nEpoch 10/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.3262 - accuracy: 0.0022 - val_loss: 0.4003 - val_accuracy: 0.0026\nEpoch 11/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.3109 - accuracy: 0.0019 - val_loss: 0.3807 - val_accuracy: 0.0026\nEpoch 12/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.2953 - accuracy: 0.0022 - val_loss: 0.3768 - val_accuracy: 0.0026\nEpoch 13/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.3014 - accuracy: 0.0019 - val_loss: 0.3891 - val_accuracy: 0.0026\nEpoch 14/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.2678 - accuracy: 0.0022 - val_loss: 0.3954 - val_accuracy: 0.0026\nEpoch 15/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.2619 - accuracy: 0.0022 - val_loss: 0.4034 - val_accuracy: 0.0026\nEpoch 16/100\n98/98 [==============================] - 2s 23ms/step - loss: 0.2570 - accuracy: 0.0022 - val_loss: 0.3976 - val_accuracy: 0.0026\nEpoch 17/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.2478 - accuracy: 0.0016 - val_loss: 0.4204 - val_accuracy: 0.0026\nEpoch 18/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.2306 - accuracy: 0.0022 - val_loss: 0.4003 - val_accuracy: 0.0026\nEpoch 19/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.2202 - accuracy: 0.0016 - val_loss: 0.4150 - val_accuracy: 0.0026\nEpoch 20/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.2190 - accuracy: 0.0022 - val_loss: 0.4172 - val_accuracy: 0.0026\nEpoch 21/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.2130 - accuracy: 0.0022 - val_loss: 0.4052 - val_accuracy: 0.0026\nEpoch 22/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.2057 - accuracy: 0.0022 - val_loss: 0.4365 - val_accuracy: 0.0026\nEpoch 23/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.2035 - accuracy: 0.0022 - val_loss: 0.4276 - val_accuracy: 0.0026\nEpoch 24/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.1815 - accuracy: 0.0022 - val_loss: 0.4271 - val_accuracy: 0.0026\nEpoch 25/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.1823 - accuracy: 0.0022 - val_loss: 0.4424 - val_accuracy: 0.0026\nEpoch 26/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.1763 - accuracy: 0.0019 - val_loss: 0.4149 - val_accuracy: 0.0026\nEpoch 27/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.1662 - accuracy: 0.0022 - val_loss: 0.4131 - val_accuracy: 0.0026\nEpoch 28/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.1708 - accuracy: 0.0019 - val_loss: 0.4241 - val_accuracy: 0.0026\nEpoch 29/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.1563 - accuracy: 0.0022 - val_loss: 0.4303 - val_accuracy: 0.0026\nEpoch 30/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.1475 - accuracy: 0.0022 - val_loss: 0.4314 - val_accuracy: 0.0026\nEpoch 31/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.1443 - accuracy: 0.0022 - val_loss: 0.4801 - val_accuracy: 0.0026\nEpoch 32/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.1384 - accuracy: 0.0022 - val_loss: 0.4175 - val_accuracy: 0.0026\nEpoch 33/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.1332 - accuracy: 0.0016 - val_loss: 0.4726 - val_accuracy: 0.0026\nEpoch 34/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.1319 - accuracy: 0.0022 - val_loss: 0.4615 - val_accuracy: 0.0026\nEpoch 35/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.1254 - accuracy: 0.0019 - val_loss: 0.4406 - val_accuracy: 0.0026\nEpoch 36/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.1185 - accuracy: 0.0019 - val_loss: 0.4608 - val_accuracy: 0.0026\nEpoch 37/100\n98/98 [==============================] - 2s 23ms/step - loss: 0.1149 - accuracy: 0.0019 - val_loss: 0.4542 - val_accuracy: 0.0026\nEpoch 38/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.1109 - accuracy: 0.0019 - val_loss: 0.4762 - val_accuracy: 0.0026\nEpoch 39/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.1110 - accuracy: 0.0022 - val_loss: 0.4504 - val_accuracy: 0.0026\nEpoch 40/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0983 - accuracy: 0.0022 - val_loss: 0.4626 - val_accuracy: 0.0026\nEpoch 41/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0985 - accuracy: 0.0022 - val_loss: 0.4673 - val_accuracy: 0.0026\nEpoch 42/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0954 - accuracy: 0.0022 - val_loss: 0.4677 - val_accuracy: 0.0026\nEpoch 43/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0916 - accuracy: 0.0019 - val_loss: 0.4314 - val_accuracy: 0.0026\nEpoch 44/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0871 - accuracy: 0.0022 - val_loss: 0.4764 - val_accuracy: 0.0026\nEpoch 45/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0836 - accuracy: 0.0022 - val_loss: 0.4575 - val_accuracy: 0.0026\nEpoch 46/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0805 - accuracy: 0.0022 - val_loss: 0.4707 - val_accuracy: 0.0026\nEpoch 47/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0791 - accuracy: 0.0022 - val_loss: 0.4645 - val_accuracy: 0.0026\nEpoch 48/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0757 - accuracy: 0.0019 - val_loss: 0.4509 - val_accuracy: 0.0026\nEpoch 49/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0679 - accuracy: 0.0022 - val_loss: 0.5073 - val_accuracy: 0.0026\nEpoch 50/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0663 - accuracy: 0.0019 - val_loss: 0.4529 - val_accuracy: 0.0026\nEpoch 51/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0668 - accuracy: 0.0022 - val_loss: 0.4671 - val_accuracy: 0.0026\nEpoch 52/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0630 - accuracy: 0.0022 - val_loss: 0.4857 - val_accuracy: 0.0026\nEpoch 53/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0619 - accuracy: 0.0022 - val_loss: 0.4740 - val_accuracy: 0.0026\nEpoch 54/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0598 - accuracy: 0.0022 - val_loss: 0.5165 - val_accuracy: 0.0026\nEpoch 55/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0581 - accuracy: 0.0022 - val_loss: 0.4993 - val_accuracy: 0.0026\nEpoch 56/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0548 - accuracy: 0.0022 - val_loss: 0.4971 - val_accuracy: 0.0026\nEpoch 57/100\n98/98 [==============================] - 2s 23ms/step - loss: 0.0522 - accuracy: 0.0019 - val_loss: 0.4815 - val_accuracy: 0.0026\nEpoch 58/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0533 - accuracy: 0.0022 - val_loss: 0.5061 - val_accuracy: 0.0026\nEpoch 59/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0495 - accuracy: 0.0022 - val_loss: 0.4754 - val_accuracy: 0.0026\nEpoch 60/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0494 - accuracy: 0.0022 - val_loss: 0.4731 - val_accuracy: 0.0026\nEpoch 61/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0469 - accuracy: 0.0019 - val_loss: 0.5039 - val_accuracy: 0.0026\nEpoch 62/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0454 - accuracy: 0.0022 - val_loss: 0.4845 - val_accuracy: 0.0026\nEpoch 63/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0454 - accuracy: 0.0022 - val_loss: 0.4751 - val_accuracy: 0.0026\nEpoch 64/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0426 - accuracy: 0.0022 - val_loss: 0.5152 - val_accuracy: 0.0026\nEpoch 65/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0430 - accuracy: 0.0022 - val_loss: 0.4830 - val_accuracy: 0.0026\nEpoch 66/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0396 - accuracy: 0.0022 - val_loss: 0.5528 - val_accuracy: 0.0026\nEpoch 67/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0371 - accuracy: 0.0022 - val_loss: 0.4776 - val_accuracy: 0.0026\nEpoch 68/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0378 - accuracy: 0.0022 - val_loss: 0.5138 - val_accuracy: 0.0026\nEpoch 69/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0359 - accuracy: 0.0022 - val_loss: 0.5222 - val_accuracy: 0.0026\nEpoch 70/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0372 - accuracy: 0.0022 - val_loss: 0.5476 - val_accuracy: 0.0026\nEpoch 71/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0351 - accuracy: 0.0022 - val_loss: 0.4996 - val_accuracy: 0.0026\nEpoch 72/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0344 - accuracy: 0.0022 - val_loss: 0.4873 - val_accuracy: 0.0026\nEpoch 73/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0323 - accuracy: 0.0022 - val_loss: 0.5018 - val_accuracy: 0.0026\nEpoch 74/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0326 - accuracy: 0.0019 - val_loss: 0.4872 - val_accuracy: 0.0026\nEpoch 75/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0309 - accuracy: 0.0022 - val_loss: 0.4827 - val_accuracy: 0.0026\nEpoch 76/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0307 - accuracy: 0.0022 - val_loss: 0.5007 - val_accuracy: 0.0026\nEpoch 77/100\n98/98 [==============================] - 2s 24ms/step - loss: 0.0310 - accuracy: 0.0022 - val_loss: 0.4868 - val_accuracy: 0.0026\nEpoch 78/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0304 - accuracy: 0.0022 - val_loss: 0.5214 - val_accuracy: 0.0026\nEpoch 79/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0307 - accuracy: 0.0022 - val_loss: 0.4845 - val_accuracy: 0.0026\nEpoch 80/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0297 - accuracy: 0.0019 - val_loss: 0.4851 - val_accuracy: 0.0026\nEpoch 81/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0283 - accuracy: 0.0019 - val_loss: 0.4916 - val_accuracy: 0.0026\nEpoch 82/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0271 - accuracy: 0.0022 - val_loss: 0.4955 - val_accuracy: 0.0026\nEpoch 83/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0281 - accuracy: 0.0022 - val_loss: 0.4947 - val_accuracy: 0.0026\nEpoch 84/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0268 - accuracy: 0.0022 - val_loss: 0.4793 - val_accuracy: 0.0026\nEpoch 85/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0254 - accuracy: 0.0022 - val_loss: 0.4989 - val_accuracy: 0.0026\nEpoch 86/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0270 - accuracy: 0.0022 - val_loss: 0.4985 - val_accuracy: 0.0026\nEpoch 87/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0265 - accuracy: 0.0022 - val_loss: 0.4947 - val_accuracy: 0.0026\nEpoch 88/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0255 - accuracy: 0.0022 - val_loss: 0.5247 - val_accuracy: 0.0026\nEpoch 89/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0241 - accuracy: 0.0022 - val_loss: 0.5325 - val_accuracy: 0.0026\nEpoch 90/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0249 - accuracy: 0.0022 - val_loss: 0.5056 - val_accuracy: 0.0026\nEpoch 91/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0236 - accuracy: 0.0022 - val_loss: 0.4942 - val_accuracy: 0.0026\nEpoch 92/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0236 - accuracy: 0.0022 - val_loss: 0.4926 - val_accuracy: 0.0026\nEpoch 93/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0237 - accuracy: 0.0022 - val_loss: 0.4900 - val_accuracy: 0.0026\nEpoch 94/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0241 - accuracy: 0.0022 - val_loss: 0.5242 - val_accuracy: 0.0026\nEpoch 95/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0234 - accuracy: 0.0022 - val_loss: 0.4896 - val_accuracy: 0.0026\nEpoch 96/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0229 - accuracy: 0.0022 - val_loss: 0.4939 - val_accuracy: 0.0026\nEpoch 97/100\n98/98 [==============================] - 2s 23ms/step - loss: 0.0227 - accuracy: 0.0022 - val_loss: 0.4984 - val_accuracy: 0.0026\nEpoch 98/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0222 - accuracy: 0.0022 - val_loss: 0.5106 - val_accuracy: 0.0026\nEpoch 99/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0226 - accuracy: 0.0022 - val_loss: 0.4900 - val_accuracy: 0.0026\nEpoch 100/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0228 - accuracy: 0.0022 - val_loss: 0.5265 - val_accuracy: 0.0026\nEpoch 1/100\n98/98 [==============================] - 2s 17ms/step - loss: 1.0278 - accuracy: 6.3918e-04 - val_loss: 0.2546 - val_accuracy: 0.0000e+00\nEpoch 2/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.5390 - accuracy: 6.3918e-04 - val_loss: 0.2337 - val_accuracy: 0.0000e+00\nEpoch 3/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.4647 - accuracy: 6.3918e-04 - val_loss: 0.2325 - val_accuracy: 0.0000e+00\nEpoch 4/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.4200 - accuracy: 3.1959e-04 - val_loss: 0.2314 - val_accuracy: 0.0000e+00\nEpoch 5/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.3998 - accuracy: 6.3918e-04 - val_loss: 0.2435 - val_accuracy: 0.0000e+00\nEpoch 6/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.3784 - accuracy: 6.3918e-04 - val_loss: 0.3226 - val_accuracy: 0.0000e+00\nEpoch 7/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.3690 - accuracy: 3.1959e-04 - val_loss: 0.2456 - val_accuracy: 0.0000e+00\nEpoch 8/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.3409 - accuracy: 6.3918e-04 - val_loss: 0.2689 - val_accuracy: 0.0000e+00\nEpoch 9/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.3199 - accuracy: 6.3918e-04 - val_loss: 0.2492 - val_accuracy: 0.0000e+00\nEpoch 10/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.3128 - accuracy: 6.3918e-04 - val_loss: 0.2652 - val_accuracy: 0.0000e+00\nEpoch 11/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.3031 - accuracy: 6.3918e-04 - val_loss: 0.2992 - val_accuracy: 0.0000e+00\nEpoch 12/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.2749 - accuracy: 6.3918e-04 - val_loss: 0.2624 - val_accuracy: 0.0000e+00\nEpoch 13/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.2649 - accuracy: 6.3918e-04 - val_loss: 0.2877 - val_accuracy: 0.0000e+00\nEpoch 14/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.2639 - accuracy: 6.3918e-04 - val_loss: 0.2652 - val_accuracy: 0.0000e+00\nEpoch 15/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.2492 - accuracy: 6.3918e-04 - val_loss: 0.2735 - val_accuracy: 0.0000e+00\nEpoch 16/100\n98/98 [==============================] - 2s 18ms/step - loss: 0.2400 - accuracy: 6.3918e-04 - val_loss: 0.2693 - val_accuracy: 0.0000e+00\nEpoch 17/100\n98/98 [==============================] - 2s 19ms/step - loss: 0.2377 - accuracy: 6.3918e-04 - val_loss: 0.2926 - val_accuracy: 0.0000e+00\nEpoch 18/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.2199 - accuracy: 6.3918e-04 - val_loss: 0.2759 - val_accuracy: 0.0000e+00\nEpoch 19/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.2115 - accuracy: 6.3918e-04 - val_loss: 0.2613 - val_accuracy: 0.0000e+00\nEpoch 20/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.2040 - accuracy: 6.3918e-04 - val_loss: 0.2747 - val_accuracy: 0.0000e+00\nEpoch 21/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.1955 - accuracy: 6.3918e-04 - val_loss: 0.2952 - val_accuracy: 0.0000e+00\nEpoch 22/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.1817 - accuracy: 6.3918e-04 - val_loss: 0.3159 - val_accuracy: 0.0000e+00\nEpoch 23/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.1821 - accuracy: 6.3918e-04 - val_loss: 0.3144 - val_accuracy: 0.0000e+00\nEpoch 24/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.1816 - accuracy: 3.1959e-04 - val_loss: 0.3058 - val_accuracy: 0.0000e+00\nEpoch 25/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.1672 - accuracy: 6.3918e-04 - val_loss: 0.3101 - val_accuracy: 0.0000e+00\nEpoch 26/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.1569 - accuracy: 6.3918e-04 - val_loss: 0.3027 - val_accuracy: 0.0000e+00\nEpoch 27/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.1540 - accuracy: 6.3918e-04 - val_loss: 0.2828 - val_accuracy: 0.0000e+00\nEpoch 28/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.1411 - accuracy: 6.3918e-04 - val_loss: 0.3227 - val_accuracy: 0.0000e+00\nEpoch 29/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.1417 - accuracy: 6.3918e-04 - val_loss: 0.2993 - val_accuracy: 0.0000e+00\nEpoch 30/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.1437 - accuracy: 6.3918e-04 - val_loss: 0.3121 - val_accuracy: 0.0000e+00\nEpoch 31/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.1288 - accuracy: 3.1959e-04 - val_loss: 0.2994 - val_accuracy: 0.0000e+00\nEpoch 32/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.1275 - accuracy: 6.3918e-04 - val_loss: 0.2953 - val_accuracy: 0.0000e+00\nEpoch 33/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.1209 - accuracy: 6.3918e-04 - val_loss: 0.3063 - val_accuracy: 0.0000e+00\nEpoch 34/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.1140 - accuracy: 6.3918e-04 - val_loss: 0.3173 - val_accuracy: 0.0000e+00\nEpoch 35/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.1036 - accuracy: 6.3918e-04 - val_loss: 0.2988 - val_accuracy: 0.0000e+00\nEpoch 36/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.1106 - accuracy: 6.3918e-04 - val_loss: 0.3027 - val_accuracy: 0.0000e+00\nEpoch 37/100\n98/98 [==============================] - 2s 23ms/step - loss: 0.1004 - accuracy: 6.3918e-04 - val_loss: 0.3194 - val_accuracy: 0.0000e+00\nEpoch 38/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0969 - accuracy: 6.3918e-04 - val_loss: 0.3068 - val_accuracy: 0.0000e+00\nEpoch 39/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0920 - accuracy: 6.3918e-04 - val_loss: 0.3320 - val_accuracy: 0.0000e+00\nEpoch 40/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0902 - accuracy: 6.3918e-04 - val_loss: 0.3181 - val_accuracy: 0.0000e+00\nEpoch 41/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0785 - accuracy: 6.3918e-04 - val_loss: 0.3043 - val_accuracy: 0.0000e+00\nEpoch 42/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0816 - accuracy: 6.3918e-04 - val_loss: 0.2975 - val_accuracy: 0.0000e+00\nEpoch 43/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0758 - accuracy: 6.3918e-04 - val_loss: 0.3088 - val_accuracy: 0.0000e+00\nEpoch 44/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0728 - accuracy: 6.3918e-04 - val_loss: 0.3077 - val_accuracy: 0.0000e+00\nEpoch 45/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0703 - accuracy: 6.3918e-04 - val_loss: 0.3134 - val_accuracy: 0.0000e+00\nEpoch 46/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0677 - accuracy: 6.3918e-04 - val_loss: 0.3181 - val_accuracy: 0.0000e+00\nEpoch 47/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0620 - accuracy: 6.3918e-04 - val_loss: 0.3130 - val_accuracy: 0.0000e+00\nEpoch 48/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0614 - accuracy: 6.3918e-04 - val_loss: 0.3009 - val_accuracy: 0.0000e+00\nEpoch 49/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0594 - accuracy: 6.3918e-04 - val_loss: 0.3364 - val_accuracy: 0.0000e+00\nEpoch 50/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0577 - accuracy: 6.3918e-04 - val_loss: 0.3354 - val_accuracy: 0.0000e+00\nEpoch 51/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0538 - accuracy: 6.3918e-04 - val_loss: 0.3249 - val_accuracy: 0.0000e+00\nEpoch 52/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0554 - accuracy: 6.3918e-04 - val_loss: 0.3244 - val_accuracy: 0.0000e+00\nEpoch 53/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0513 - accuracy: 6.3918e-04 - val_loss: 0.3253 - val_accuracy: 0.0000e+00\nEpoch 54/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0478 - accuracy: 6.3918e-04 - val_loss: 0.3174 - val_accuracy: 0.0000e+00\nEpoch 55/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0448 - accuracy: 6.3918e-04 - val_loss: 0.3295 - val_accuracy: 0.0000e+00\nEpoch 56/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0427 - accuracy: 6.3918e-04 - val_loss: 0.3372 - val_accuracy: 0.0000e+00\nEpoch 57/100\n98/98 [==============================] - 2s 24ms/step - loss: 0.0455 - accuracy: 6.3918e-04 - val_loss: 0.3489 - val_accuracy: 0.0000e+00\nEpoch 58/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0404 - accuracy: 6.3918e-04 - val_loss: 0.3133 - val_accuracy: 0.0000e+00\nEpoch 59/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0400 - accuracy: 6.3918e-04 - val_loss: 0.3386 - val_accuracy: 0.0000e+00\nEpoch 60/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0384 - accuracy: 6.3918e-04 - val_loss: 0.3205 - val_accuracy: 0.0000e+00\nEpoch 61/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0375 - accuracy: 6.3918e-04 - val_loss: 0.3244 - val_accuracy: 0.0000e+00\nEpoch 62/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0343 - accuracy: 6.3918e-04 - val_loss: 0.3326 - val_accuracy: 0.0000e+00\nEpoch 63/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0337 - accuracy: 6.3918e-04 - val_loss: 0.3305 - val_accuracy: 0.0000e+00\nEpoch 64/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0324 - accuracy: 6.3918e-04 - val_loss: 0.3269 - val_accuracy: 0.0000e+00\nEpoch 65/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0323 - accuracy: 6.3918e-04 - val_loss: 0.3455 - val_accuracy: 0.0000e+00\nEpoch 66/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0319 - accuracy: 6.3918e-04 - val_loss: 0.3253 - val_accuracy: 0.0000e+00\nEpoch 67/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0300 - accuracy: 6.3918e-04 - val_loss: 0.3167 - val_accuracy: 0.0000e+00\nEpoch 68/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0290 - accuracy: 6.3918e-04 - val_loss: 0.3330 - val_accuracy: 0.0000e+00\nEpoch 69/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0301 - accuracy: 6.3918e-04 - val_loss: 0.3470 - val_accuracy: 0.0000e+00\nEpoch 70/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0287 - accuracy: 6.3918e-04 - val_loss: 0.3349 - val_accuracy: 0.0000e+00\nEpoch 71/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0277 - accuracy: 6.3918e-04 - val_loss: 0.3222 - val_accuracy: 0.0000e+00\nEpoch 72/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0271 - accuracy: 6.3918e-04 - val_loss: 0.3272 - val_accuracy: 0.0000e+00\nEpoch 73/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0255 - accuracy: 6.3918e-04 - val_loss: 0.3603 - val_accuracy: 0.0000e+00\nEpoch 74/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0235 - accuracy: 6.3918e-04 - val_loss: 0.3419 - val_accuracy: 0.0000e+00\nEpoch 75/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0243 - accuracy: 6.3918e-04 - val_loss: 0.3348 - val_accuracy: 0.0000e+00\nEpoch 76/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0231 - accuracy: 6.3918e-04 - val_loss: 0.3393 - val_accuracy: 0.0000e+00\nEpoch 77/100\n98/98 [==============================] - 2s 23ms/step - loss: 0.0231 - accuracy: 6.3918e-04 - val_loss: 0.3353 - val_accuracy: 0.0000e+00\nEpoch 78/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0232 - accuracy: 6.3918e-04 - val_loss: 0.3463 - val_accuracy: 0.0000e+00\nEpoch 79/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0225 - accuracy: 6.3918e-04 - val_loss: 0.3407 - val_accuracy: 0.0000e+00\nEpoch 80/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0219 - accuracy: 6.3918e-04 - val_loss: 0.3505 - val_accuracy: 0.0000e+00\nEpoch 81/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0225 - accuracy: 6.3918e-04 - val_loss: 0.3566 - val_accuracy: 0.0000e+00\nEpoch 82/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0217 - accuracy: 6.3918e-04 - val_loss: 0.3536 - val_accuracy: 0.0000e+00\nEpoch 83/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0200 - accuracy: 6.3918e-04 - val_loss: 0.3510 - val_accuracy: 0.0000e+00\nEpoch 84/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0213 - accuracy: 6.3918e-04 - val_loss: 0.3593 - val_accuracy: 0.0000e+00\nEpoch 85/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0215 - accuracy: 6.3918e-04 - val_loss: 0.3409 - val_accuracy: 0.0000e+00\nEpoch 86/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0199 - accuracy: 6.3918e-04 - val_loss: 0.3601 - val_accuracy: 0.0000e+00\nEpoch 87/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0192 - accuracy: 6.3918e-04 - val_loss: 0.3512 - val_accuracy: 0.0000e+00\nEpoch 88/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0199 - accuracy: 6.3918e-04 - val_loss: 0.3428 - val_accuracy: 0.0000e+00\nEpoch 89/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0187 - accuracy: 6.3918e-04 - val_loss: 0.3465 - val_accuracy: 0.0000e+00\nEpoch 90/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0198 - accuracy: 6.3918e-04 - val_loss: 0.3618 - val_accuracy: 0.0000e+00\nEpoch 91/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0191 - accuracy: 6.3918e-04 - val_loss: 0.3622 - val_accuracy: 0.0000e+00\nEpoch 92/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0196 - accuracy: 6.3918e-04 - val_loss: 0.3439 - val_accuracy: 0.0000e+00\nEpoch 93/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0181 - accuracy: 6.3918e-04 - val_loss: 0.3551 - val_accuracy: 0.0000e+00\nEpoch 94/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0183 - accuracy: 6.3918e-04 - val_loss: 0.3543 - val_accuracy: 0.0000e+00\nEpoch 95/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0192 - accuracy: 6.3918e-04 - val_loss: 0.3513 - val_accuracy: 0.0000e+00\nEpoch 96/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0188 - accuracy: 6.3918e-04 - val_loss: 0.3469 - val_accuracy: 0.0000e+00\nEpoch 97/100\n98/98 [==============================] - 2s 23ms/step - loss: 0.0181 - accuracy: 6.3918e-04 - val_loss: 0.3398 - val_accuracy: 0.0000e+00\nEpoch 98/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0185 - accuracy: 6.3918e-04 - val_loss: 0.3272 - val_accuracy: 0.0000e+00\nEpoch 99/100\n98/98 [==============================] - 2s 17ms/step - loss: 0.0193 - accuracy: 6.3918e-04 - val_loss: 0.3442 - val_accuracy: 0.0000e+00\nEpoch 100/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0185 - accuracy: 6.3918e-04 - val_loss: 0.3594 - val_accuracy: 0.0000e+00\nEpoch 1/100\n98/98 [==============================] - 2s 17ms/step - loss: 1.1447 - accuracy: 0.0029 - val_loss: 0.3439 - val_accuracy: 0.0000e+00\nEpoch 2/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.5502 - accuracy: 0.0029 - val_loss: 0.2949 - val_accuracy: 0.0000e+00\nEpoch 3/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.5126 - accuracy: 0.0022 - val_loss: 0.2778 - val_accuracy: 0.0000e+00\nEpoch 4/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.4599 - accuracy: 0.0029 - val_loss: 0.2839 - val_accuracy: 0.0000e+00\nEpoch 5/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.4044 - accuracy: 0.0022 - val_loss: 0.3320 - val_accuracy: 0.0000e+00\nEpoch 6/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.3773 - accuracy: 0.0026 - val_loss: 0.3073 - val_accuracy: 0.0000e+00\nEpoch 7/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.3446 - accuracy: 0.0026 - val_loss: 0.3426 - val_accuracy: 0.0000e+00\nEpoch 8/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.3424 - accuracy: 0.0029 - val_loss: 0.3059 - val_accuracy: 0.0000e+00\nEpoch 9/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.3258 - accuracy: 0.0026 - val_loss: 0.3764 - val_accuracy: 0.0000e+00\nEpoch 10/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.3024 - accuracy: 0.0029 - val_loss: 0.3297 - val_accuracy: 0.0000e+00\nEpoch 11/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.3092 - accuracy: 0.0029 - val_loss: 0.3344 - val_accuracy: 0.0000e+00\nEpoch 12/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.2749 - accuracy: 0.0029 - val_loss: 0.3472 - val_accuracy: 0.0000e+00\nEpoch 13/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.2742 - accuracy: 0.0029 - val_loss: 0.3337 - val_accuracy: 0.0000e+00\nEpoch 14/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.2523 - accuracy: 0.0029 - val_loss: 0.3578 - val_accuracy: 0.0000e+00\nEpoch 15/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.2607 - accuracy: 0.0026 - val_loss: 0.3635 - val_accuracy: 0.0000e+00\nEpoch 16/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.2357 - accuracy: 0.0029 - val_loss: 0.3418 - val_accuracy: 0.0000e+00\nEpoch 17/100\n98/98 [==============================] - 2s 23ms/step - loss: 0.2423 - accuracy: 0.0029 - val_loss: 0.3443 - val_accuracy: 0.0000e+00\nEpoch 18/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.2249 - accuracy: 0.0029 - val_loss: 0.3641 - val_accuracy: 0.0000e+00\nEpoch 19/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.2205 - accuracy: 0.0029 - val_loss: 0.4028 - val_accuracy: 0.0000e+00\nEpoch 20/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.2007 - accuracy: 0.0029 - val_loss: 0.4097 - val_accuracy: 0.0000e+00\nEpoch 21/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.1972 - accuracy: 0.0026 - val_loss: 0.3720 - val_accuracy: 0.0000e+00\nEpoch 22/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.1855 - accuracy: 0.0029 - val_loss: 0.3626 - val_accuracy: 0.0000e+00\nEpoch 23/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.1868 - accuracy: 0.0029 - val_loss: 0.3930 - val_accuracy: 0.0000e+00\nEpoch 24/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.1841 - accuracy: 0.0029 - val_loss: 0.3794 - val_accuracy: 0.0000e+00\nEpoch 25/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.1701 - accuracy: 0.0026 - val_loss: 0.3873 - val_accuracy: 0.0000e+00\nEpoch 26/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.1636 - accuracy: 0.0026 - val_loss: 0.3774 - val_accuracy: 0.0000e+00\nEpoch 27/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.1543 - accuracy: 0.0029 - val_loss: 0.3796 - val_accuracy: 0.0000e+00\nEpoch 28/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.1499 - accuracy: 0.0026 - val_loss: 0.3783 - val_accuracy: 0.0000e+00\nEpoch 29/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.1429 - accuracy: 0.0029 - val_loss: 0.3662 - val_accuracy: 0.0000e+00\nEpoch 30/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.1330 - accuracy: 0.0022 - val_loss: 0.3615 - val_accuracy: 0.0000e+00\nEpoch 31/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.1364 - accuracy: 0.0029 - val_loss: 0.3944 - val_accuracy: 0.0000e+00\nEpoch 32/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.1318 - accuracy: 0.0029 - val_loss: 0.4046 - val_accuracy: 0.0000e+00\nEpoch 33/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.1252 - accuracy: 0.0029 - val_loss: 0.4064 - val_accuracy: 0.0000e+00\nEpoch 34/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.1192 - accuracy: 0.0029 - val_loss: 0.4014 - val_accuracy: 0.0000e+00\nEpoch 35/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.1167 - accuracy: 0.0029 - val_loss: 0.4145 - val_accuracy: 0.0000e+00\nEpoch 36/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.1046 - accuracy: 0.0029 - val_loss: 0.3900 - val_accuracy: 0.0000e+00\nEpoch 37/100\n98/98 [==============================] - 2s 22ms/step - loss: 0.1086 - accuracy: 0.0029 - val_loss: 0.3945 - val_accuracy: 0.0000e+00\nEpoch 38/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0984 - accuracy: 0.0029 - val_loss: 0.4117 - val_accuracy: 0.0000e+00\nEpoch 39/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0986 - accuracy: 0.0029 - val_loss: 0.4015 - val_accuracy: 0.0000e+00\nEpoch 40/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0892 - accuracy: 0.0026 - val_loss: 0.3886 - val_accuracy: 0.0000e+00\nEpoch 41/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0892 - accuracy: 0.0029 - val_loss: 0.3887 - val_accuracy: 0.0000e+00\nEpoch 42/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0811 - accuracy: 0.0029 - val_loss: 0.4135 - val_accuracy: 0.0000e+00\nEpoch 43/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0838 - accuracy: 0.0029 - val_loss: 0.4019 - val_accuracy: 0.0000e+00\nEpoch 44/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0775 - accuracy: 0.0029 - val_loss: 0.4013 - val_accuracy: 0.0000e+00\nEpoch 45/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0735 - accuracy: 0.0029 - val_loss: 0.4085 - val_accuracy: 0.0000e+00\nEpoch 46/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0728 - accuracy: 0.0029 - val_loss: 0.4322 - val_accuracy: 0.0000e+00\nEpoch 47/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0668 - accuracy: 0.0029 - val_loss: 0.4207 - val_accuracy: 0.0000e+00\nEpoch 48/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0683 - accuracy: 0.0029 - val_loss: 0.3968 - val_accuracy: 0.0000e+00\nEpoch 49/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0650 - accuracy: 0.0029 - val_loss: 0.4094 - val_accuracy: 0.0000e+00\nEpoch 50/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0599 - accuracy: 0.0029 - val_loss: 0.4254 - val_accuracy: 0.0000e+00\nEpoch 51/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0586 - accuracy: 0.0029 - val_loss: 0.4050 - val_accuracy: 0.0000e+00\nEpoch 52/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0568 - accuracy: 0.0029 - val_loss: 0.4282 - val_accuracy: 0.0000e+00\nEpoch 53/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0549 - accuracy: 0.0029 - val_loss: 0.4488 - val_accuracy: 0.0000e+00\nEpoch 54/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0518 - accuracy: 0.0029 - val_loss: 0.4231 - val_accuracy: 0.0000e+00\nEpoch 55/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0528 - accuracy: 0.0029 - val_loss: 0.4191 - val_accuracy: 0.0000e+00\nEpoch 56/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0494 - accuracy: 0.0029 - val_loss: 0.4284 - val_accuracy: 0.0000e+00\nEpoch 57/100\n98/98 [==============================] - 2s 21ms/step - loss: 0.0490 - accuracy: 0.0029 - val_loss: 0.4438 - val_accuracy: 0.0000e+00\nEpoch 58/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0475 - accuracy: 0.0029 - val_loss: 0.4374 - val_accuracy: 0.0000e+00\nEpoch 59/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0430 - accuracy: 0.0029 - val_loss: 0.4015 - val_accuracy: 0.0000e+00\nEpoch 60/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0450 - accuracy: 0.0029 - val_loss: 0.4557 - val_accuracy: 0.0000e+00\nEpoch 61/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0411 - accuracy: 0.0029 - val_loss: 0.4500 - val_accuracy: 0.0000e+00\nEpoch 62/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0410 - accuracy: 0.0026 - val_loss: 0.4430 - val_accuracy: 0.0000e+00\nEpoch 63/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0391 - accuracy: 0.0029 - val_loss: 0.4450 - val_accuracy: 0.0000e+00\nEpoch 64/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0404 - accuracy: 0.0029 - val_loss: 0.4226 - val_accuracy: 0.0000e+00\nEpoch 65/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0387 - accuracy: 0.0029 - val_loss: 0.4330 - val_accuracy: 0.0000e+00\nEpoch 66/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0377 - accuracy: 0.0029 - val_loss: 0.4339 - val_accuracy: 0.0000e+00\nEpoch 67/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0340 - accuracy: 0.0029 - val_loss: 0.4563 - val_accuracy: 0.0000e+00\nEpoch 68/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0342 - accuracy: 0.0029 - val_loss: 0.4583 - val_accuracy: 0.0000e+00\nEpoch 69/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0324 - accuracy: 0.0029 - val_loss: 0.4267 - val_accuracy: 0.0000e+00\nEpoch 70/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0328 - accuracy: 0.0029 - val_loss: 0.4472 - val_accuracy: 0.0000e+00\nEpoch 71/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0316 - accuracy: 0.0029 - val_loss: 0.4472 - val_accuracy: 0.0000e+00\nEpoch 72/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0316 - accuracy: 0.0029 - val_loss: 0.4464 - val_accuracy: 0.0000e+00\nEpoch 73/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0278 - accuracy: 0.0029 - val_loss: 0.4341 - val_accuracy: 0.0000e+00\nEpoch 74/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0319 - accuracy: 0.0029 - val_loss: 0.4251 - val_accuracy: 0.0000e+00\nEpoch 75/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0280 - accuracy: 0.0029 - val_loss: 0.4394 - val_accuracy: 0.0000e+00\nEpoch 76/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0284 - accuracy: 0.0029 - val_loss: 0.4267 - val_accuracy: 0.0000e+00\nEpoch 77/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0286 - accuracy: 0.0029 - val_loss: 0.4286 - val_accuracy: 0.0000e+00\nEpoch 78/100\n98/98 [==============================] - 2s 23ms/step - loss: 0.0285 - accuracy: 0.0029 - val_loss: 0.4330 - val_accuracy: 0.0000e+00\nEpoch 79/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0275 - accuracy: 0.0029 - val_loss: 0.4402 - val_accuracy: 0.0000e+00\nEpoch 80/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0252 - accuracy: 0.0029 - val_loss: 0.4332 - val_accuracy: 0.0000e+00\nEpoch 81/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0261 - accuracy: 0.0029 - val_loss: 0.4356 - val_accuracy: 0.0000e+00\nEpoch 82/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0252 - accuracy: 0.0029 - val_loss: 0.4605 - val_accuracy: 0.0000e+00\nEpoch 83/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0261 - accuracy: 0.0029 - val_loss: 0.4464 - val_accuracy: 0.0000e+00\nEpoch 84/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0261 - accuracy: 0.0029 - val_loss: 0.4415 - val_accuracy: 0.0000e+00\nEpoch 85/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0259 - accuracy: 0.0029 - val_loss: 0.4438 - val_accuracy: 0.0000e+00\nEpoch 86/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0257 - accuracy: 0.0029 - val_loss: 0.4542 - val_accuracy: 0.0000e+00\nEpoch 87/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0248 - accuracy: 0.0029 - val_loss: 0.4463 - val_accuracy: 0.0000e+00\nEpoch 88/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0241 - accuracy: 0.0029 - val_loss: 0.4246 - val_accuracy: 0.0000e+00\nEpoch 89/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0234 - accuracy: 0.0029 - val_loss: 0.4412 - val_accuracy: 0.0000e+00\nEpoch 90/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0239 - accuracy: 0.0029 - val_loss: 0.4516 - val_accuracy: 0.0000e+00\nEpoch 91/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0251 - accuracy: 0.0029 - val_loss: 0.4428 - val_accuracy: 0.0000e+00\nEpoch 92/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0238 - accuracy: 0.0029 - val_loss: 0.4587 - val_accuracy: 0.0000e+00\nEpoch 93/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0254 - accuracy: 0.0029 - val_loss: 0.4846 - val_accuracy: 0.0000e+00\nEpoch 94/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0231 - accuracy: 0.0029 - val_loss: 0.4746 - val_accuracy: 0.0000e+00\nEpoch 95/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0236 - accuracy: 0.0029 - val_loss: 0.4612 - val_accuracy: 0.0000e+00\nEpoch 96/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0232 - accuracy: 0.0029 - val_loss: 0.4643 - val_accuracy: 0.0000e+00\nEpoch 97/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0231 - accuracy: 0.0029 - val_loss: 0.4624 - val_accuracy: 0.0000e+00\nEpoch 98/100\n98/98 [==============================] - 2s 23ms/step - loss: 0.0249 - accuracy: 0.0029 - val_loss: 0.4607 - val_accuracy: 0.0000e+00\nEpoch 99/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0211 - accuracy: 0.0029 - val_loss: 0.4611 - val_accuracy: 0.0000e+00\nEpoch 100/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0216 - accuracy: 0.0029 - val_loss: 0.4555 - val_accuracy: 0.0000e+00\nEpoch 1/100\n98/98 [==============================] - 2s 17ms/step - loss: 0.9819 - accuracy: 0.0022 - val_loss: 0.3914 - val_accuracy: 0.0000e+00\nEpoch 2/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.5551 - accuracy: 0.0022 - val_loss: 0.4318 - val_accuracy: 0.0000e+00\nEpoch 3/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.4958 - accuracy: 0.0022 - val_loss: 0.4579 - val_accuracy: 0.0000e+00\nEpoch 4/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.4563 - accuracy: 0.0022 - val_loss: 0.4117 - val_accuracy: 0.0000e+00\nEpoch 5/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.4345 - accuracy: 0.0019 - val_loss: 0.4186 - val_accuracy: 0.0000e+00\nEpoch 6/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.4049 - accuracy: 0.0019 - val_loss: 0.4181 - val_accuracy: 0.0000e+00\nEpoch 7/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.3716 - accuracy: 0.0022 - val_loss: 0.4380 - val_accuracy: 0.0000e+00\nEpoch 8/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.3456 - accuracy: 0.0022 - val_loss: 0.4618 - val_accuracy: 0.0000e+00\nEpoch 9/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.3198 - accuracy: 0.0022 - val_loss: 0.4649 - val_accuracy: 0.0000e+00\nEpoch 10/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.3224 - accuracy: 0.0022 - val_loss: 0.5079 - val_accuracy: 0.0000e+00\nEpoch 11/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.3039 - accuracy: 0.0022 - val_loss: 0.5157 - val_accuracy: 0.0000e+00\nEpoch 12/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.3119 - accuracy: 0.0019 - val_loss: 0.4771 - val_accuracy: 0.0000e+00\nEpoch 13/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.2900 - accuracy: 0.0022 - val_loss: 0.4764 - val_accuracy: 0.0000e+00\nEpoch 14/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.2597 - accuracy: 0.0022 - val_loss: 0.4839 - val_accuracy: 0.0000e+00\nEpoch 15/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.2579 - accuracy: 0.0022 - val_loss: 0.4819 - val_accuracy: 0.0000e+00\nEpoch 16/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.2428 - accuracy: 0.0022 - val_loss: 0.4901 - val_accuracy: 0.0000e+00\nEpoch 17/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.2405 - accuracy: 0.0022 - val_loss: 0.5158 - val_accuracy: 0.0000e+00\nEpoch 18/100\n98/98 [==============================] - 2s 24ms/step - loss: 0.2212 - accuracy: 0.0022 - val_loss: 0.5072 - val_accuracy: 0.0000e+00\nEpoch 19/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.2259 - accuracy: 0.0022 - val_loss: 0.5008 - val_accuracy: 0.0000e+00\nEpoch 20/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.2133 - accuracy: 0.0022 - val_loss: 0.5017 - val_accuracy: 0.0000e+00\nEpoch 21/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.2007 - accuracy: 0.0022 - val_loss: 0.5051 - val_accuracy: 0.0000e+00\nEpoch 22/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.1945 - accuracy: 0.0022 - val_loss: 0.5139 - val_accuracy: 0.0000e+00\nEpoch 23/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.1891 - accuracy: 0.0022 - val_loss: 0.5105 - val_accuracy: 0.0000e+00\nEpoch 24/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.1806 - accuracy: 0.0022 - val_loss: 0.5070 - val_accuracy: 0.0000e+00\nEpoch 25/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.1746 - accuracy: 0.0022 - val_loss: 0.5119 - val_accuracy: 0.0000e+00\nEpoch 26/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.1710 - accuracy: 0.0022 - val_loss: 0.5197 - val_accuracy: 0.0000e+00\nEpoch 27/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.1579 - accuracy: 0.0019 - val_loss: 0.5268 - val_accuracy: 0.0000e+00\nEpoch 28/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.1596 - accuracy: 0.0022 - val_loss: 0.5162 - val_accuracy: 0.0000e+00\nEpoch 29/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.1489 - accuracy: 0.0022 - val_loss: 0.5521 - val_accuracy: 0.0000e+00\nEpoch 30/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.1488 - accuracy: 0.0022 - val_loss: 0.5376 - val_accuracy: 0.0000e+00\nEpoch 31/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.1470 - accuracy: 0.0022 - val_loss: 0.5405 - val_accuracy: 0.0000e+00\nEpoch 32/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.1369 - accuracy: 0.0022 - val_loss: 0.5665 - val_accuracy: 0.0000e+00\nEpoch 33/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.1338 - accuracy: 0.0022 - val_loss: 0.5191 - val_accuracy: 0.0000e+00\nEpoch 34/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.1277 - accuracy: 0.0019 - val_loss: 0.5072 - val_accuracy: 0.0000e+00\nEpoch 35/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.1154 - accuracy: 0.0022 - val_loss: 0.5259 - val_accuracy: 0.0000e+00\nEpoch 36/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.1154 - accuracy: 0.0019 - val_loss: 0.5581 - val_accuracy: 0.0000e+00\nEpoch 37/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.1118 - accuracy: 0.0022 - val_loss: 0.5467 - val_accuracy: 0.0000e+00\nEpoch 38/100\n98/98 [==============================] - 2s 22ms/step - loss: 0.1046 - accuracy: 0.0022 - val_loss: 0.5614 - val_accuracy: 0.0000e+00\nEpoch 39/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.1058 - accuracy: 0.0022 - val_loss: 0.5003 - val_accuracy: 0.0000e+00\nEpoch 40/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0972 - accuracy: 0.0019 - val_loss: 0.5678 - val_accuracy: 0.0000e+00\nEpoch 41/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0980 - accuracy: 0.0022 - val_loss: 0.5561 - val_accuracy: 0.0000e+00\nEpoch 42/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0926 - accuracy: 0.0022 - val_loss: 0.5540 - val_accuracy: 0.0000e+00\nEpoch 43/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0876 - accuracy: 0.0019 - val_loss: 0.5337 - val_accuracy: 0.0000e+00\nEpoch 44/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0901 - accuracy: 0.0022 - val_loss: 0.5643 - val_accuracy: 0.0000e+00\nEpoch 45/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0785 - accuracy: 0.0022 - val_loss: 0.5383 - val_accuracy: 0.0000e+00\nEpoch 46/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0794 - accuracy: 0.0022 - val_loss: 0.5693 - val_accuracy: 0.0000e+00\nEpoch 47/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0790 - accuracy: 0.0022 - val_loss: 0.5551 - val_accuracy: 0.0000e+00\nEpoch 48/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0747 - accuracy: 0.0022 - val_loss: 0.5829 - val_accuracy: 0.0000e+00\nEpoch 49/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0703 - accuracy: 0.0022 - val_loss: 0.5642 - val_accuracy: 0.0000e+00\nEpoch 50/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0690 - accuracy: 0.0022 - val_loss: 0.5270 - val_accuracy: 0.0000e+00\nEpoch 51/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0691 - accuracy: 0.0019 - val_loss: 0.5590 - val_accuracy: 0.0000e+00\nEpoch 52/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0641 - accuracy: 0.0022 - val_loss: 0.5766 - val_accuracy: 0.0000e+00\nEpoch 53/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0636 - accuracy: 0.0022 - val_loss: 0.5515 - val_accuracy: 0.0000e+00\nEpoch 54/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0604 - accuracy: 0.0022 - val_loss: 0.5404 - val_accuracy: 0.0000e+00\nEpoch 55/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0545 - accuracy: 0.0022 - val_loss: 0.5471 - val_accuracy: 0.0000e+00\nEpoch 56/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0571 - accuracy: 0.0022 - val_loss: 0.5341 - val_accuracy: 0.0000e+00\nEpoch 57/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0556 - accuracy: 0.0022 - val_loss: 0.5858 - val_accuracy: 0.0000e+00\nEpoch 58/100\n98/98 [==============================] - 2s 23ms/step - loss: 0.0541 - accuracy: 0.0019 - val_loss: 0.5587 - val_accuracy: 0.0000e+00\nEpoch 59/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0517 - accuracy: 0.0019 - val_loss: 0.5522 - val_accuracy: 0.0000e+00\nEpoch 60/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0514 - accuracy: 0.0022 - val_loss: 0.5308 - val_accuracy: 0.0000e+00\nEpoch 61/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0490 - accuracy: 0.0022 - val_loss: 0.5570 - val_accuracy: 0.0000e+00\nEpoch 62/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0437 - accuracy: 0.0022 - val_loss: 0.5673 - val_accuracy: 0.0000e+00\nEpoch 63/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0465 - accuracy: 0.0022 - val_loss: 0.5603 - val_accuracy: 0.0000e+00\nEpoch 64/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0441 - accuracy: 0.0022 - val_loss: 0.5487 - val_accuracy: 0.0000e+00\nEpoch 65/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0464 - accuracy: 0.0022 - val_loss: 0.5742 - val_accuracy: 0.0000e+00\nEpoch 66/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0419 - accuracy: 0.0019 - val_loss: 0.5744 - val_accuracy: 0.0000e+00\nEpoch 67/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0407 - accuracy: 0.0022 - val_loss: 0.5740 - val_accuracy: 0.0000e+00\nEpoch 68/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0414 - accuracy: 0.0022 - val_loss: 0.5599 - val_accuracy: 0.0000e+00\nEpoch 69/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0398 - accuracy: 0.0022 - val_loss: 0.5537 - val_accuracy: 0.0000e+00\nEpoch 70/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0392 - accuracy: 0.0019 - val_loss: 0.6074 - val_accuracy: 0.0000e+00\nEpoch 71/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0391 - accuracy: 0.0019 - val_loss: 0.5642 - val_accuracy: 0.0000e+00\nEpoch 72/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0353 - accuracy: 0.0019 - val_loss: 0.5792 - val_accuracy: 0.0000e+00\nEpoch 73/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0333 - accuracy: 0.0022 - val_loss: 0.5706 - val_accuracy: 0.0000e+00\nEpoch 74/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0350 - accuracy: 0.0022 - val_loss: 0.5339 - val_accuracy: 0.0000e+00\nEpoch 75/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0341 - accuracy: 0.0022 - val_loss: 0.5552 - val_accuracy: 0.0000e+00\nEpoch 76/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0331 - accuracy: 0.0022 - val_loss: 0.5775 - val_accuracy: 0.0000e+00\nEpoch 77/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0345 - accuracy: 0.0022 - val_loss: 0.5763 - val_accuracy: 0.0000e+00\nEpoch 78/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0343 - accuracy: 0.0022 - val_loss: 0.5486 - val_accuracy: 0.0000e+00\nEpoch 79/100\n98/98 [==============================] - 2s 21ms/step - loss: 0.0323 - accuracy: 0.0022 - val_loss: 0.5654 - val_accuracy: 0.0000e+00\nEpoch 80/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0295 - accuracy: 0.0022 - val_loss: 0.5980 - val_accuracy: 0.0000e+00\nEpoch 81/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0310 - accuracy: 0.0022 - val_loss: 0.5682 - val_accuracy: 0.0000e+00\nEpoch 82/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0309 - accuracy: 0.0022 - val_loss: 0.5678 - val_accuracy: 0.0000e+00\nEpoch 83/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0301 - accuracy: 0.0022 - val_loss: 0.5948 - val_accuracy: 0.0000e+00\nEpoch 84/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0293 - accuracy: 0.0022 - val_loss: 0.6064 - val_accuracy: 0.0000e+00\nEpoch 85/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0292 - accuracy: 0.0022 - val_loss: 0.5979 - val_accuracy: 0.0000e+00\nEpoch 86/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0283 - accuracy: 0.0022 - val_loss: 0.5717 - val_accuracy: 0.0000e+00\nEpoch 87/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0291 - accuracy: 0.0022 - val_loss: 0.5628 - val_accuracy: 0.0000e+00\nEpoch 88/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0278 - accuracy: 0.0022 - val_loss: 0.5726 - val_accuracy: 0.0000e+00\nEpoch 89/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0273 - accuracy: 0.0022 - val_loss: 0.5770 - val_accuracy: 0.0000e+00\nEpoch 90/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0284 - accuracy: 0.0022 - val_loss: 0.5705 - val_accuracy: 0.0000e+00\nEpoch 91/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0257 - accuracy: 0.0022 - val_loss: 0.5681 - val_accuracy: 0.0000e+00\nEpoch 92/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0261 - accuracy: 0.0022 - val_loss: 0.5523 - val_accuracy: 0.0000e+00\nEpoch 93/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0275 - accuracy: 0.0019 - val_loss: 0.5860 - val_accuracy: 0.0000e+00\nEpoch 94/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0270 - accuracy: 0.0022 - val_loss: 0.5665 - val_accuracy: 0.0000e+00\nEpoch 95/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0266 - accuracy: 0.0022 - val_loss: 0.5974 - val_accuracy: 0.0000e+00\nEpoch 96/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0268 - accuracy: 0.0022 - val_loss: 0.6032 - val_accuracy: 0.0000e+00\nEpoch 97/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0255 - accuracy: 0.0022 - val_loss: 0.6142 - val_accuracy: 0.0000e+00\nEpoch 98/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0245 - accuracy: 0.0022 - val_loss: 0.5583 - val_accuracy: 0.0000e+00\nEpoch 99/100\n98/98 [==============================] - 2s 23ms/step - loss: 0.0250 - accuracy: 0.0022 - val_loss: 0.5658 - val_accuracy: 0.0000e+00\nEpoch 100/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0247 - accuracy: 0.0022 - val_loss: 0.5807 - val_accuracy: 0.0000e+00\nEpoch 1/100\n98/98 [==============================] - 3s 17ms/step - loss: 0.9440 - accuracy: 0.0038 - val_loss: 0.3267 - val_accuracy: 0.0051\nEpoch 2/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.5796 - accuracy: 0.0042 - val_loss: 0.3221 - val_accuracy: 0.0051\nEpoch 3/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.4840 - accuracy: 0.0035 - val_loss: 0.3099 - val_accuracy: 0.0051\nEpoch 4/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.4657 - accuracy: 0.0042 - val_loss: 0.3319 - val_accuracy: 0.0051\nEpoch 5/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.4078 - accuracy: 0.0038 - val_loss: 0.3303 - val_accuracy: 0.0051\nEpoch 6/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.3822 - accuracy: 0.0042 - val_loss: 0.3410 - val_accuracy: 0.0051\nEpoch 7/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.3784 - accuracy: 0.0038 - val_loss: 0.3947 - val_accuracy: 0.0051\nEpoch 8/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.3457 - accuracy: 0.0038 - val_loss: 0.3915 - val_accuracy: 0.0051\nEpoch 9/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.3221 - accuracy: 0.0035 - val_loss: 0.3574 - val_accuracy: 0.0051\nEpoch 10/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.3173 - accuracy: 0.0035 - val_loss: 0.3711 - val_accuracy: 0.0051\nEpoch 11/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.3124 - accuracy: 0.0038 - val_loss: 0.3781 - val_accuracy: 0.0051\nEpoch 12/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.2714 - accuracy: 0.0038 - val_loss: 0.3993 - val_accuracy: 0.0051\nEpoch 13/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.2898 - accuracy: 0.0042 - val_loss: 0.3836 - val_accuracy: 0.0051\nEpoch 14/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.2789 - accuracy: 0.0038 - val_loss: 0.3904 - val_accuracy: 0.0051\nEpoch 15/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.2725 - accuracy: 0.0038 - val_loss: 0.4182 - val_accuracy: 0.0051\nEpoch 16/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.2482 - accuracy: 0.0032 - val_loss: 0.4172 - val_accuracy: 0.0051\nEpoch 17/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.2403 - accuracy: 0.0038 - val_loss: 0.4529 - val_accuracy: 0.0051\nEpoch 18/100\n98/98 [==============================] - 2s 23ms/step - loss: 0.2331 - accuracy: 0.0038 - val_loss: 0.4060 - val_accuracy: 0.0051\nEpoch 19/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.2087 - accuracy: 0.0035 - val_loss: 0.4050 - val_accuracy: 0.0051\nEpoch 20/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.2086 - accuracy: 0.0042 - val_loss: 0.4161 - val_accuracy: 0.0051\nEpoch 21/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.2011 - accuracy: 0.0038 - val_loss: 0.4085 - val_accuracy: 0.0051\nEpoch 22/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.2024 - accuracy: 0.0042 - val_loss: 0.4114 - val_accuracy: 0.0051\nEpoch 23/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.1932 - accuracy: 0.0038 - val_loss: 0.4058 - val_accuracy: 0.0051\nEpoch 24/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.1874 - accuracy: 0.0038 - val_loss: 0.4361 - val_accuracy: 0.0051\nEpoch 25/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.1760 - accuracy: 0.0038 - val_loss: 0.4427 - val_accuracy: 0.0051\nEpoch 26/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.1679 - accuracy: 0.0042 - val_loss: 0.4361 - val_accuracy: 0.0051\nEpoch 27/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.1659 - accuracy: 0.0038 - val_loss: 0.4671 - val_accuracy: 0.0051\nEpoch 28/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.1588 - accuracy: 0.0038 - val_loss: 0.5109 - val_accuracy: 0.0051\nEpoch 29/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.1511 - accuracy: 0.0042 - val_loss: 0.4512 - val_accuracy: 0.0051\nEpoch 30/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.1518 - accuracy: 0.0038 - val_loss: 0.4425 - val_accuracy: 0.0051\nEpoch 31/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.1496 - accuracy: 0.0038 - val_loss: 0.4440 - val_accuracy: 0.0051\nEpoch 32/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.1393 - accuracy: 0.0042 - val_loss: 0.4399 - val_accuracy: 0.0051\nEpoch 33/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.1363 - accuracy: 0.0035 - val_loss: 0.4508 - val_accuracy: 0.0051\nEpoch 34/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.1274 - accuracy: 0.0035 - val_loss: 0.4395 - val_accuracy: 0.0051\nEpoch 35/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.1237 - accuracy: 0.0042 - val_loss: 0.4647 - val_accuracy: 0.0051\nEpoch 36/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.1189 - accuracy: 0.0038 - val_loss: 0.4483 - val_accuracy: 0.0051\nEpoch 37/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.1142 - accuracy: 0.0042 - val_loss: 0.4520 - val_accuracy: 0.0051\nEpoch 38/100\n98/98 [==============================] - 2s 22ms/step - loss: 0.1048 - accuracy: 0.0042 - val_loss: 0.4581 - val_accuracy: 0.0051\nEpoch 39/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.1042 - accuracy: 0.0042 - val_loss: 0.4581 - val_accuracy: 0.0051\nEpoch 40/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.1017 - accuracy: 0.0035 - val_loss: 0.4751 - val_accuracy: 0.0051\nEpoch 41/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.1009 - accuracy: 0.0042 - val_loss: 0.4585 - val_accuracy: 0.0051\nEpoch 42/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0928 - accuracy: 0.0042 - val_loss: 0.5066 - val_accuracy: 0.0051\nEpoch 43/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0900 - accuracy: 0.0042 - val_loss: 0.4507 - val_accuracy: 0.0051\nEpoch 44/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0859 - accuracy: 0.0042 - val_loss: 0.4569 - val_accuracy: 0.0051\nEpoch 45/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0785 - accuracy: 0.0042 - val_loss: 0.4542 - val_accuracy: 0.0051\nEpoch 46/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0809 - accuracy: 0.0042 - val_loss: 0.4571 - val_accuracy: 0.0051\nEpoch 47/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0806 - accuracy: 0.0035 - val_loss: 0.4900 - val_accuracy: 0.0051\nEpoch 48/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0739 - accuracy: 0.0035 - val_loss: 0.4532 - val_accuracy: 0.0051\nEpoch 49/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0684 - accuracy: 0.0038 - val_loss: 0.4696 - val_accuracy: 0.0051\nEpoch 50/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0745 - accuracy: 0.0042 - val_loss: 0.5217 - val_accuracy: 0.0051\nEpoch 51/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0683 - accuracy: 0.0042 - val_loss: 0.5122 - val_accuracy: 0.0051\nEpoch 52/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0632 - accuracy: 0.0042 - val_loss: 0.4783 - val_accuracy: 0.0051\nEpoch 53/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0597 - accuracy: 0.0042 - val_loss: 0.4796 - val_accuracy: 0.0051\nEpoch 54/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0635 - accuracy: 0.0035 - val_loss: 0.4977 - val_accuracy: 0.0051\nEpoch 55/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0603 - accuracy: 0.0042 - val_loss: 0.5072 - val_accuracy: 0.0051\nEpoch 56/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0582 - accuracy: 0.0042 - val_loss: 0.5276 - val_accuracy: 0.0051\nEpoch 57/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0571 - accuracy: 0.0035 - val_loss: 0.4948 - val_accuracy: 0.0051\nEpoch 58/100\n98/98 [==============================] - 1s 15ms/step - loss: 0.0559 - accuracy: 0.0035 - val_loss: 0.4884 - val_accuracy: 0.0051\nEpoch 59/100\n98/98 [==============================] - 2s 22ms/step - loss: 0.0513 - accuracy: 0.0035 - val_loss: 0.4799 - val_accuracy: 0.0051\nEpoch 60/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0463 - accuracy: 0.0042 - val_loss: 0.5083 - val_accuracy: 0.0051\nEpoch 61/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0463 - accuracy: 0.0038 - val_loss: 0.5156 - val_accuracy: 0.0051\nEpoch 62/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0471 - accuracy: 0.0042 - val_loss: 0.4884 - val_accuracy: 0.0051\nEpoch 63/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0444 - accuracy: 0.0042 - val_loss: 0.5163 - val_accuracy: 0.0051\nEpoch 64/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0459 - accuracy: 0.0042 - val_loss: 0.4923 - val_accuracy: 0.0051\nEpoch 65/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0420 - accuracy: 0.0042 - val_loss: 0.4778 - val_accuracy: 0.0051\nEpoch 66/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0416 - accuracy: 0.0042 - val_loss: 0.5596 - val_accuracy: 0.0051\nEpoch 67/100\n98/98 [==============================] - 2s 17ms/step - loss: 0.0419 - accuracy: 0.0042 - val_loss: 0.4705 - val_accuracy: 0.0051\nEpoch 68/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0379 - accuracy: 0.0042 - val_loss: 0.4881 - val_accuracy: 0.0051\nEpoch 69/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0372 - accuracy: 0.0035 - val_loss: 0.4633 - val_accuracy: 0.0051\nEpoch 70/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0373 - accuracy: 0.0042 - val_loss: 0.5327 - val_accuracy: 0.0051\nEpoch 71/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0362 - accuracy: 0.0042 - val_loss: 0.4853 - val_accuracy: 0.0051\nEpoch 72/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0342 - accuracy: 0.0042 - val_loss: 0.5128 - val_accuracy: 0.0051\nEpoch 73/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0345 - accuracy: 0.0042 - val_loss: 0.5225 - val_accuracy: 0.0051\nEpoch 74/100\n98/98 [==============================] - 2s 17ms/step - loss: 0.0330 - accuracy: 0.0042 - val_loss: 0.4739 - val_accuracy: 0.0051\nEpoch 75/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0345 - accuracy: 0.0038 - val_loss: 0.5108 - val_accuracy: 0.0051\nEpoch 76/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0336 - accuracy: 0.0038 - val_loss: 0.5228 - val_accuracy: 0.0051\nEpoch 77/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0318 - accuracy: 0.0032 - val_loss: 0.5159 - val_accuracy: 0.0051\nEpoch 78/100\n98/98 [==============================] - 2s 23ms/step - loss: 0.0315 - accuracy: 0.0042 - val_loss: 0.4997 - val_accuracy: 0.0051\nEpoch 79/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0306 - accuracy: 0.0038 - val_loss: 0.5393 - val_accuracy: 0.0051\nEpoch 80/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0280 - accuracy: 0.0042 - val_loss: 0.5119 - val_accuracy: 0.0051\nEpoch 81/100\n98/98 [==============================] - 2s 17ms/step - loss: 0.0293 - accuracy: 0.0042 - val_loss: 0.5179 - val_accuracy: 0.0051\nEpoch 82/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0297 - accuracy: 0.0042 - val_loss: 0.4973 - val_accuracy: 0.0051\nEpoch 83/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0269 - accuracy: 0.0042 - val_loss: 0.5401 - val_accuracy: 0.0051\nEpoch 84/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0276 - accuracy: 0.0042 - val_loss: 0.5328 - val_accuracy: 0.0051\nEpoch 85/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0266 - accuracy: 0.0042 - val_loss: 0.5746 - val_accuracy: 0.0051\nEpoch 86/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0279 - accuracy: 0.0042 - val_loss: 0.5162 - val_accuracy: 0.0051\nEpoch 87/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0251 - accuracy: 0.0042 - val_loss: 0.4894 - val_accuracy: 0.0051\nEpoch 88/100\n98/98 [==============================] - 2s 17ms/step - loss: 0.0268 - accuracy: 0.0038 - val_loss: 0.5371 - val_accuracy: 0.0051\nEpoch 89/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0253 - accuracy: 0.0042 - val_loss: 0.5157 - val_accuracy: 0.0051\nEpoch 90/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0262 - accuracy: 0.0042 - val_loss: 0.5102 - val_accuracy: 0.0051\nEpoch 91/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0264 - accuracy: 0.0042 - val_loss: 0.5288 - val_accuracy: 0.0051\nEpoch 92/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0255 - accuracy: 0.0042 - val_loss: 0.5110 - val_accuracy: 0.0051\nEpoch 93/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0256 - accuracy: 0.0042 - val_loss: 0.4979 - val_accuracy: 0.0051\nEpoch 94/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0240 - accuracy: 0.0042 - val_loss: 0.4875 - val_accuracy: 0.0051\nEpoch 95/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0248 - accuracy: 0.0042 - val_loss: 0.5259 - val_accuracy: 0.0051\nEpoch 96/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0235 - accuracy: 0.0042 - val_loss: 0.5416 - val_accuracy: 0.0051\nEpoch 97/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0241 - accuracy: 0.0042 - val_loss: 0.5254 - val_accuracy: 0.0051\nEpoch 98/100\n98/98 [==============================] - 2s 23ms/step - loss: 0.0225 - accuracy: 0.0042 - val_loss: 0.5292 - val_accuracy: 0.0051\nEpoch 99/100\n98/98 [==============================] - 2s 15ms/step - loss: 0.0229 - accuracy: 0.0042 - val_loss: 0.5308 - val_accuracy: 0.0051\nEpoch 100/100\n98/98 [==============================] - 2s 16ms/step - loss: 0.0239 - accuracy: 0.0042 - val_loss: 0.5082 - val_accuracy: 0.0051\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results1 = embedding_model1.predict(tfidf_test).flatten()\nresults1= [round(r,1) for r in results1]  \n\nresults2 = embedding_model2.predict(tfidf_test).flatten()\nresults2 = [round(r,1) for r in results2]  \n\nresults3 = embedding_model3.predict(tfidf_test).flatten()\nresults3 = [round(r,1) for r in results3]  \n\nresults4 = embedding_model4.predict(tfidf_test).flatten()\nresults4 = [round(r,1) for r in results4]  \n\nresults5 = embedding_model5.predict(tfidf_test).flatten()\nresults5 = [round(r,1) for r in results5]  \n\nresults6 = embedding_model6.predict(tfidf_test).flatten()\nresults6 = [round(r,1) for r in results6] ","metadata":{"execution":{"iopub.status.busy":"2022-11-26T09:27:18.450759Z","iopub.execute_input":"2022-11-26T09:27:18.451799Z","iopub.status.idle":"2022-11-26T09:27:19.213677Z","shell.execute_reply.started":"2022-11-26T09:27:18.451751Z","shell.execute_reply":"2022-11-26T09:27:19.212599Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"code","source":"y1_test= list(y1_test)\ny2_test= list(y2_test)\ny3_test= list(y3_test)\ny4_test= list(y4_test)\ny5_test= list(y5_test)\ny6_test= list(y6_test)","metadata":{"execution":{"iopub.status.busy":"2022-11-26T09:27:20.429381Z","iopub.execute_input":"2022-11-26T09:27:20.429760Z","iopub.status.idle":"2022-11-26T09:27:20.435798Z","shell.execute_reply.started":"2022-11-26T09:27:20.429729Z","shell.execute_reply":"2022-11-26T09:27:20.434609Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"code","source":"values1 = mean_squared_error(results1,y1_test)\nvalues2 = mean_squared_error(results2,y2_test)\nvalues3 = mean_squared_error(results3,y3_test)\nvalues4 = mean_squared_error(results4,y4_test)\nvalues5 = mean_squared_error(results5,y5_test)\nvalues6 = mean_squared_error(results6,y6_test)","metadata":{"execution":{"iopub.status.busy":"2022-11-26T09:27:21.186772Z","iopub.execute_input":"2022-11-26T09:27:21.187747Z","iopub.status.idle":"2022-11-26T09:27:21.198795Z","shell.execute_reply.started":"2022-11-26T09:27:21.187665Z","shell.execute_reply":"2022-11-26T09:27:21.197394Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"markdown","source":"Test error for Neural Net","metadata":{}},{"cell_type":"code","source":"test_error=values1+values2+values3+values4+values5+values6\ntest_mcrmse= test_error/6\ntest_mcrmse","metadata":{"execution":{"iopub.status.busy":"2022-11-26T09:27:23.886776Z","iopub.execute_input":"2022-11-26T09:27:23.887219Z","iopub.status.idle":"2022-11-26T09:27:23.895999Z","shell.execute_reply.started":"2022-11-26T09:27:23.887185Z","shell.execute_reply":"2022-11-26T09:27:23.894381Z"},"trusted":true},"execution_count":97,"outputs":[{"execution_count":97,"output_type":"execute_result","data":{"text/plain":"0.4695609508207134"},"metadata":{}}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.reset_orig()\n\nfig = plt.figure(figsize=(10, 6))\n\nplt.plot(h1.history['loss'])\nplt.plot(h2.history['loss'])\nplt.plot(h3.history['loss'])\nplt.plot(h4.history['loss'])\nplt.plot(h5.history['loss'])\nplt.plot(h6.history['loss'])\n\nplt.title('TF-IDF FeedForward NN')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['syntax','cohesion','vocabulary','phraseology','grammar','conventions'], loc='upper left')","metadata":{"execution":{"iopub.status.busy":"2022-11-26T09:27:24.695301Z","iopub.execute_input":"2022-11-26T09:27:24.696493Z","iopub.status.idle":"2022-11-26T09:27:24.932259Z","shell.execute_reply.started":"2022-11-26T09:27:24.696447Z","shell.execute_reply":"2022-11-26T09:27:24.931047Z"},"trusted":true},"execution_count":98,"outputs":[{"execution_count":98,"output_type":"execute_result","data":{"text/plain":"<matplotlib.legend.Legend at 0x7fa8c001fe50>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 720x432 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":"# LSTM","metadata":{}},{"cell_type":"code","source":"lstm_embed_train = []\nfor i in range(0,len(tfidf_train)):\n    lstm_embed_train.append(np.asarray([tfidf_train[i]]))\n\nlstm_embed_test = []\nfor i in range(0,len(tfidf_test)):\n    lstm_embed_test.append(np.asarray([tfidf_test[i]]))\n\nlstm_embed_val = []\nfor i in range(0,len(tfidf_val)):\n    lstm_embed_val.append(np.asarray([tfidf_val[i]]))\n\nlstm_embed_test = np.asarray(lstm_embed_test)\nlstm_embed_train = np.asarray(lstm_embed_train)\nlstm_embed_val = np.asarray(lstm_embed_val)\nprint(lstm_embed_train.shape)\nprint(lstm_embed_val.shape)\nprint(lstm_embed_test.shape)\n","metadata":{"execution":{"iopub.status.busy":"2022-11-26T07:57:17.726097Z","iopub.execute_input":"2022-11-26T07:57:17.726530Z","iopub.status.idle":"2022-11-26T07:57:18.815798Z","shell.execute_reply.started":"2022-11-26T07:57:17.726487Z","shell.execute_reply":"2022-11-26T07:57:18.814911Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"(3129, 1, 21370)\n(391, 1, 21370)\n(391, 1, 21370)\n","output_type":"stream"}]},{"cell_type":"code","source":"print(tfidf_train.shape)\nprint(tfidf_val.shape)\nprint(tfidf_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-11-26T07:57:18.817020Z","iopub.execute_input":"2022-11-26T07:57:18.817331Z","iopub.status.idle":"2022-11-26T07:57:18.824825Z","shell.execute_reply.started":"2022-11-26T07:57:18.817302Z","shell.execute_reply":"2022-11-26T07:57:18.823504Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"(3129, 21370)\n(391, 21370)\n(391, 21370)\n","output_type":"stream"}]},{"cell_type":"code","source":"lstm_embed_train_final = []\nfor i in range(0,len(test)):\n    lstm_embed_train_final.append(np.asarray([test[i]]))\nlstm_embed_test_final = np.asarray(lstm_embed_train_final)\nlstm_embed_test_final.shape","metadata":{"execution":{"iopub.status.busy":"2022-11-26T07:57:20.322310Z","iopub.execute_input":"2022-11-26T07:57:20.322814Z","iopub.status.idle":"2022-11-26T07:57:20.333576Z","shell.execute_reply.started":"2022-11-26T07:57:20.322774Z","shell.execute_reply":"2022-11-26T07:57:20.332263Z"},"trusted":true},"execution_count":50,"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"(3, 1, 21370)"},"metadata":{}}]},{"cell_type":"code","source":"def get_model_lstm():\n    \"\"\"Define the model.\"\"\"\n    \n    model = Sequential()\n    model.add(LSTM(128, input_shape=[1,IP], activation = 'tanh',return_sequences=True))\n    model.add(Dropout(0.4))\n    model.add(Dense(32, activation='tanh'))\n    model.add(Dropout(0.4))\n    model.add(Dense(1, activation='relu'))\n\n    model.summary()\n    model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['accuracy'])\n\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2022-11-26T07:57:26.865300Z","iopub.execute_input":"2022-11-26T07:57:26.865679Z","iopub.status.idle":"2022-11-26T07:57:26.874003Z","shell.execute_reply.started":"2022-11-26T07:57:26.865647Z","shell.execute_reply":"2022-11-26T07:57:26.872477Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"lstm_model1 = get_model_lstm()\nlstm_model1.fit(lstm_embed_train, y1_train, epochs=100,validation_data=(lstm_embed_val,y1_val))\nlstm_result_1 = lstm_model1.predict(lstm_embed_test_final).flatten()\nlstm_result_1 = [int(r) for r in lstm_result_1]\nlen(lstm_result_1)","metadata":{"execution":{"iopub.status.busy":"2022-11-26T07:57:27.756029Z","iopub.execute_input":"2022-11-26T07:57:27.756433Z","iopub.status.idle":"2022-11-26T08:07:20.551401Z","shell.execute_reply.started":"2022-11-26T07:57:27.756399Z","shell.execute_reply":"2022-11-26T08:07:20.550157Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"Model: \"sequential_6\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nlstm (LSTM)                  (None, 1, 128)            11007488  \n_________________________________________________________________\ndropout_18 (Dropout)         (None, 1, 128)            0         \n_________________________________________________________________\ndense_24 (Dense)             (None, 1, 32)             4128      \n_________________________________________________________________\ndropout_19 (Dropout)         (None, 1, 32)             0         \n_________________________________________________________________\ndense_25 (Dense)             (None, 1, 1)              33        \n=================================================================\nTotal params: 11,011,649\nTrainable params: 11,011,649\nNon-trainable params: 0\n_________________________________________________________________\nEpoch 1/100\n98/98 [==============================] - 10s 73ms/step - loss: 1.4144 - accuracy: 0.0029 - val_loss: 0.3851 - val_accuracy: 0.0026\nEpoch 2/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.5424 - accuracy: 0.0029 - val_loss: 0.3424 - val_accuracy: 0.0026\nEpoch 3/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.4481 - accuracy: 0.0029 - val_loss: 0.3250 - val_accuracy: 0.0026\nEpoch 4/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.4173 - accuracy: 0.0029 - val_loss: 0.3302 - val_accuracy: 0.0026\nEpoch 5/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.3553 - accuracy: 0.0029 - val_loss: 0.3300 - val_accuracy: 0.0026\nEpoch 6/100\n98/98 [==============================] - 6s 63ms/step - loss: 0.3416 - accuracy: 0.0029 - val_loss: 0.3368 - val_accuracy: 0.0026\nEpoch 7/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.3233 - accuracy: 0.0029 - val_loss: 0.3365 - val_accuracy: 0.0026\nEpoch 8/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.2979 - accuracy: 0.0029 - val_loss: 0.3336 - val_accuracy: 0.0026\nEpoch 9/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.2792 - accuracy: 0.0029 - val_loss: 0.3551 - val_accuracy: 0.0026\nEpoch 10/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.2746 - accuracy: 0.0029 - val_loss: 0.3509 - val_accuracy: 0.0026\nEpoch 11/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.2715 - accuracy: 0.0029 - val_loss: 0.3642 - val_accuracy: 0.0026\nEpoch 12/100\n98/98 [==============================] - 6s 65ms/step - loss: 0.2416 - accuracy: 0.0029 - val_loss: 0.3530 - val_accuracy: 0.0026\nEpoch 13/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.2319 - accuracy: 0.0029 - val_loss: 0.3765 - val_accuracy: 0.0026\nEpoch 14/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.2227 - accuracy: 0.0029 - val_loss: 0.3736 - val_accuracy: 0.0026\nEpoch 15/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.2188 - accuracy: 0.0029 - val_loss: 0.3684 - val_accuracy: 0.0026\nEpoch 16/100\n98/98 [==============================] - 6s 60ms/step - loss: 0.2036 - accuracy: 0.0029 - val_loss: 0.3735 - val_accuracy: 0.0026\nEpoch 17/100\n98/98 [==============================] - 6s 65ms/step - loss: 0.2009 - accuracy: 0.0029 - val_loss: 0.3661 - val_accuracy: 0.0026\nEpoch 18/100\n98/98 [==============================] - 6s 60ms/step - loss: 0.1834 - accuracy: 0.0029 - val_loss: 0.3800 - val_accuracy: 0.0026\nEpoch 19/100\n98/98 [==============================] - 6s 60ms/step - loss: 0.1873 - accuracy: 0.0029 - val_loss: 0.3709 - val_accuracy: 0.0026\nEpoch 20/100\n98/98 [==============================] - 6s 60ms/step - loss: 0.1789 - accuracy: 0.0029 - val_loss: 0.3796 - val_accuracy: 0.0026\nEpoch 21/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.1766 - accuracy: 0.0029 - val_loss: 0.3845 - val_accuracy: 0.0026\nEpoch 22/100\n98/98 [==============================] - 6s 65ms/step - loss: 0.1626 - accuracy: 0.0029 - val_loss: 0.3883 - val_accuracy: 0.0026\nEpoch 23/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.1580 - accuracy: 0.0029 - val_loss: 0.3939 - val_accuracy: 0.0026\nEpoch 24/100\n98/98 [==============================] - 6s 60ms/step - loss: 0.1516 - accuracy: 0.0029 - val_loss: 0.3971 - val_accuracy: 0.0026\nEpoch 25/100\n98/98 [==============================] - 6s 61ms/step - loss: 0.1457 - accuracy: 0.0029 - val_loss: 0.4133 - val_accuracy: 0.0026\nEpoch 26/100\n98/98 [==============================] - 6s 60ms/step - loss: 0.1436 - accuracy: 0.0029 - val_loss: 0.4020 - val_accuracy: 0.0026\nEpoch 27/100\n98/98 [==============================] - 6s 61ms/step - loss: 0.1354 - accuracy: 0.0029 - val_loss: 0.4039 - val_accuracy: 0.0026\nEpoch 28/100\n98/98 [==============================] - 6s 65ms/step - loss: 0.1317 - accuracy: 0.0029 - val_loss: 0.4123 - val_accuracy: 0.0026\nEpoch 29/100\n98/98 [==============================] - 6s 60ms/step - loss: 0.1232 - accuracy: 0.0029 - val_loss: 0.4043 - val_accuracy: 0.0026\nEpoch 30/100\n98/98 [==============================] - 6s 61ms/step - loss: 0.1190 - accuracy: 0.0029 - val_loss: 0.4028 - val_accuracy: 0.0026\nEpoch 31/100\n98/98 [==============================] - 6s 60ms/step - loss: 0.1098 - accuracy: 0.0029 - val_loss: 0.4018 - val_accuracy: 0.0026\nEpoch 32/100\n98/98 [==============================] - 6s 61ms/step - loss: 0.1054 - accuracy: 0.0029 - val_loss: 0.4067 - val_accuracy: 0.0026\nEpoch 33/100\n98/98 [==============================] - 6s 66ms/step - loss: 0.1063 - accuracy: 0.0029 - val_loss: 0.4125 - val_accuracy: 0.0026\nEpoch 34/100\n98/98 [==============================] - 6s 60ms/step - loss: 0.0996 - accuracy: 0.0029 - val_loss: 0.4167 - val_accuracy: 0.0026\nEpoch 35/100\n98/98 [==============================] - 6s 61ms/step - loss: 0.0941 - accuracy: 0.0026 - val_loss: 0.4219 - val_accuracy: 0.0026\nEpoch 36/100\n98/98 [==============================] - 6s 61ms/step - loss: 0.0945 - accuracy: 0.0029 - val_loss: 0.4020 - val_accuracy: 0.0026\nEpoch 37/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.0908 - accuracy: 0.0029 - val_loss: 0.4189 - val_accuracy: 0.0026\nEpoch 38/100\n98/98 [==============================] - 6s 65ms/step - loss: 0.0890 - accuracy: 0.0029 - val_loss: 0.4394 - val_accuracy: 0.0026\nEpoch 39/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.0863 - accuracy: 0.0026 - val_loss: 0.4179 - val_accuracy: 0.0026\nEpoch 40/100\n98/98 [==============================] - 6s 60ms/step - loss: 0.0786 - accuracy: 0.0029 - val_loss: 0.4208 - val_accuracy: 0.0026\nEpoch 41/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.0787 - accuracy: 0.0029 - val_loss: 0.4148 - val_accuracy: 0.0026\nEpoch 42/100\n98/98 [==============================] - 6s 60ms/step - loss: 0.0732 - accuracy: 0.0029 - val_loss: 0.4266 - val_accuracy: 0.0026\nEpoch 43/100\n98/98 [==============================] - 6s 65ms/step - loss: 0.0697 - accuracy: 0.0029 - val_loss: 0.4185 - val_accuracy: 0.0026\nEpoch 44/100\n98/98 [==============================] - 6s 60ms/step - loss: 0.0678 - accuracy: 0.0029 - val_loss: 0.4263 - val_accuracy: 0.0026\nEpoch 45/100\n98/98 [==============================] - 6s 60ms/step - loss: 0.0686 - accuracy: 0.0029 - val_loss: 0.4321 - val_accuracy: 0.0026\nEpoch 46/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.0621 - accuracy: 0.0026 - val_loss: 0.4344 - val_accuracy: 0.0026\nEpoch 47/100\n98/98 [==============================] - 6s 60ms/step - loss: 0.0620 - accuracy: 0.0029 - val_loss: 0.4272 - val_accuracy: 0.0026\nEpoch 48/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.0621 - accuracy: 0.0029 - val_loss: 0.4294 - val_accuracy: 0.0026\nEpoch 49/100\n98/98 [==============================] - 6s 66ms/step - loss: 0.0560 - accuracy: 0.0029 - val_loss: 0.4287 - val_accuracy: 0.0026\nEpoch 50/100\n98/98 [==============================] - 6s 60ms/step - loss: 0.0549 - accuracy: 0.0029 - val_loss: 0.4162 - val_accuracy: 0.0026\nEpoch 51/100\n98/98 [==============================] - 6s 60ms/step - loss: 0.0524 - accuracy: 0.0029 - val_loss: 0.4212 - val_accuracy: 0.0026\nEpoch 52/100\n98/98 [==============================] - 6s 60ms/step - loss: 0.0513 - accuracy: 0.0029 - val_loss: 0.4470 - val_accuracy: 0.0026\nEpoch 53/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.0503 - accuracy: 0.0029 - val_loss: 0.4325 - val_accuracy: 0.0026\nEpoch 54/100\n98/98 [==============================] - 6s 65ms/step - loss: 0.0481 - accuracy: 0.0029 - val_loss: 0.4236 - val_accuracy: 0.0026\nEpoch 55/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.0464 - accuracy: 0.0029 - val_loss: 0.4320 - val_accuracy: 0.0026\nEpoch 56/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.0439 - accuracy: 0.0029 - val_loss: 0.4220 - val_accuracy: 0.0026\nEpoch 57/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0435 - accuracy: 0.0029 - val_loss: 0.4370 - val_accuracy: 0.0026\nEpoch 58/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0417 - accuracy: 0.0029 - val_loss: 0.4255 - val_accuracy: 0.0026\nEpoch 59/100\n98/98 [==============================] - 6s 63ms/step - loss: 0.0417 - accuracy: 0.0029 - val_loss: 0.4324 - val_accuracy: 0.0026\nEpoch 60/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0406 - accuracy: 0.0026 - val_loss: 0.4256 - val_accuracy: 0.0026\nEpoch 61/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.0374 - accuracy: 0.0029 - val_loss: 0.4249 - val_accuracy: 0.0026\nEpoch 62/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.0347 - accuracy: 0.0029 - val_loss: 0.4296 - val_accuracy: 0.0026\nEpoch 63/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0349 - accuracy: 0.0026 - val_loss: 0.4444 - val_accuracy: 0.0026\nEpoch 64/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0322 - accuracy: 0.0029 - val_loss: 0.4295 - val_accuracy: 0.0026\nEpoch 65/100\n98/98 [==============================] - 6s 63ms/step - loss: 0.0310 - accuracy: 0.0029 - val_loss: 0.4321 - val_accuracy: 0.0026\nEpoch 66/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0338 - accuracy: 0.0026 - val_loss: 0.4315 - val_accuracy: 0.0026\nEpoch 67/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0325 - accuracy: 0.0029 - val_loss: 0.4300 - val_accuracy: 0.0026\nEpoch 68/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0314 - accuracy: 0.0029 - val_loss: 0.4276 - val_accuracy: 0.0026\nEpoch 69/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0287 - accuracy: 0.0029 - val_loss: 0.4399 - val_accuracy: 0.0026\nEpoch 70/100\n98/98 [==============================] - 6s 64ms/step - loss: 0.0305 - accuracy: 0.0026 - val_loss: 0.4442 - val_accuracy: 0.0026\nEpoch 71/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0270 - accuracy: 0.0026 - val_loss: 0.4282 - val_accuracy: 0.0026\nEpoch 72/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0286 - accuracy: 0.0026 - val_loss: 0.4348 - val_accuracy: 0.0026\nEpoch 73/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0262 - accuracy: 0.0026 - val_loss: 0.4401 - val_accuracy: 0.0026\nEpoch 74/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0255 - accuracy: 0.0029 - val_loss: 0.4437 - val_accuracy: 0.0026\nEpoch 75/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0254 - accuracy: 0.0029 - val_loss: 0.4439 - val_accuracy: 0.0026\nEpoch 76/100\n98/98 [==============================] - 6s 63ms/step - loss: 0.0239 - accuracy: 0.0029 - val_loss: 0.4322 - val_accuracy: 0.0026\nEpoch 77/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0251 - accuracy: 0.0026 - val_loss: 0.4395 - val_accuracy: 0.0026\nEpoch 78/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0238 - accuracy: 0.0029 - val_loss: 0.4395 - val_accuracy: 0.0026\nEpoch 79/100\n98/98 [==============================] - 6s 61ms/step - loss: 0.0229 - accuracy: 0.0026 - val_loss: 0.4434 - val_accuracy: 0.0026\nEpoch 80/100\n98/98 [==============================] - 6s 61ms/step - loss: 0.0235 - accuracy: 0.0029 - val_loss: 0.4440 - val_accuracy: 0.0026\nEpoch 81/100\n98/98 [==============================] - 7s 67ms/step - loss: 0.0225 - accuracy: 0.0029 - val_loss: 0.4516 - val_accuracy: 0.0026\nEpoch 82/100\n98/98 [==============================] - 6s 60ms/step - loss: 0.0221 - accuracy: 0.0029 - val_loss: 0.4387 - val_accuracy: 0.0026\nEpoch 83/100\n98/98 [==============================] - 6s 61ms/step - loss: 0.0216 - accuracy: 0.0029 - val_loss: 0.4377 - val_accuracy: 0.0026\nEpoch 84/100\n98/98 [==============================] - 6s 61ms/step - loss: 0.0208 - accuracy: 0.0029 - val_loss: 0.4377 - val_accuracy: 0.0026\nEpoch 85/100\n98/98 [==============================] - 6s 60ms/step - loss: 0.0203 - accuracy: 0.0029 - val_loss: 0.4459 - val_accuracy: 0.0026\nEpoch 86/100\n98/98 [==============================] - 6s 66ms/step - loss: 0.0212 - accuracy: 0.0029 - val_loss: 0.4487 - val_accuracy: 0.0026\nEpoch 87/100\n98/98 [==============================] - 6s 61ms/step - loss: 0.0199 - accuracy: 0.0029 - val_loss: 0.4386 - val_accuracy: 0.0026\nEpoch 88/100\n98/98 [==============================] - 6s 60ms/step - loss: 0.0203 - accuracy: 0.0029 - val_loss: 0.4351 - val_accuracy: 0.0026\nEpoch 89/100\n98/98 [==============================] - 6s 60ms/step - loss: 0.0212 - accuracy: 0.0029 - val_loss: 0.4423 - val_accuracy: 0.0026\nEpoch 90/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0196 - accuracy: 0.0029 - val_loss: 0.4459 - val_accuracy: 0.0026\nEpoch 91/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0201 - accuracy: 0.0029 - val_loss: 0.4340 - val_accuracy: 0.0026\nEpoch 92/100\n98/98 [==============================] - 6s 63ms/step - loss: 0.0187 - accuracy: 0.0029 - val_loss: 0.4420 - val_accuracy: 0.0026\nEpoch 93/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0193 - accuracy: 0.0026 - val_loss: 0.4405 - val_accuracy: 0.0026\nEpoch 94/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0189 - accuracy: 0.0026 - val_loss: 0.4526 - val_accuracy: 0.0026\nEpoch 95/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0188 - accuracy: 0.0026 - val_loss: 0.4468 - val_accuracy: 0.0026\nEpoch 96/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0180 - accuracy: 0.0029 - val_loss: 0.4307 - val_accuracy: 0.0026\nEpoch 97/100\n98/98 [==============================] - 6s 62ms/step - loss: 0.0183 - accuracy: 0.0029 - val_loss: 0.4385 - val_accuracy: 0.0026\nEpoch 98/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0188 - accuracy: 0.0029 - val_loss: 0.4367 - val_accuracy: 0.0026\nEpoch 99/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0180 - accuracy: 0.0029 - val_loss: 0.4406 - val_accuracy: 0.0026\nEpoch 100/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0188 - accuracy: 0.0026 - val_loss: 0.4343 - val_accuracy: 0.0026\n","output_type":"stream"},{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"3"},"metadata":{}}]},{"cell_type":"code","source":"lstm_model2 = get_model_lstm()\nlstm_model2.fit(lstm_embed_train, y2_train, epochs=100,validation_data=(lstm_embed_val,y2_val))\nlstm_result_2 = lstm_model2.predict(lstm_embed_test_final).flatten()\nlstm_result_2 = [int(r) for r in lstm_result_2]\nlen(lstm_result_2)","metadata":{"execution":{"iopub.status.busy":"2022-11-26T08:07:20.553346Z","iopub.execute_input":"2022-11-26T08:07:20.553823Z","iopub.status.idle":"2022-11-26T08:16:57.784810Z","shell.execute_reply.started":"2022-11-26T08:07:20.553789Z","shell.execute_reply":"2022-11-26T08:16:57.783629Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"Model: \"sequential_7\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nlstm_1 (LSTM)                (None, 1, 128)            11007488  \n_________________________________________________________________\ndropout_20 (Dropout)         (None, 1, 128)            0         \n_________________________________________________________________\ndense_26 (Dense)             (None, 1, 32)             4128      \n_________________________________________________________________\ndropout_21 (Dropout)         (None, 1, 32)             0         \n_________________________________________________________________\ndense_27 (Dense)             (None, 1, 1)              33        \n=================================================================\nTotal params: 11,011,649\nTrainable params: 11,011,649\nNon-trainable params: 0\n_________________________________________________________________\nEpoch 1/100\n98/98 [==============================] - 9s 65ms/step - loss: 1.4824 - accuracy: 0.0019 - val_loss: 0.4310 - val_accuracy: 0.0026\nEpoch 2/100\n98/98 [==============================] - 6s 62ms/step - loss: 0.5484 - accuracy: 0.0022 - val_loss: 0.3440 - val_accuracy: 0.0026\nEpoch 3/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.5029 - accuracy: 0.0022 - val_loss: 0.3314 - val_accuracy: 0.0026\nEpoch 4/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.4443 - accuracy: 0.0022 - val_loss: 0.3311 - val_accuracy: 0.0026\nEpoch 5/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.3998 - accuracy: 0.0022 - val_loss: 0.3250 - val_accuracy: 0.0026\nEpoch 6/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.3650 - accuracy: 0.0022 - val_loss: 0.3301 - val_accuracy: 0.0026\nEpoch 7/100\n98/98 [==============================] - 6s 63ms/step - loss: 0.3405 - accuracy: 0.0022 - val_loss: 0.3567 - val_accuracy: 0.0026\nEpoch 8/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.3204 - accuracy: 0.0022 - val_loss: 0.3357 - val_accuracy: 0.0026\nEpoch 9/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.3122 - accuracy: 0.0022 - val_loss: 0.3465 - val_accuracy: 0.0026\nEpoch 10/100\n98/98 [==============================] - 6s 56ms/step - loss: 0.2946 - accuracy: 0.0022 - val_loss: 0.3467 - val_accuracy: 0.0026\nEpoch 11/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.2849 - accuracy: 0.0022 - val_loss: 0.3639 - val_accuracy: 0.0026\nEpoch 12/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.2743 - accuracy: 0.0022 - val_loss: 0.3543 - val_accuracy: 0.0026\nEpoch 13/100\n98/98 [==============================] - 6s 63ms/step - loss: 0.2536 - accuracy: 0.0022 - val_loss: 0.3546 - val_accuracy: 0.0026\nEpoch 14/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.2445 - accuracy: 0.0022 - val_loss: 0.3548 - val_accuracy: 0.0026\nEpoch 15/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.2245 - accuracy: 0.0022 - val_loss: 0.3916 - val_accuracy: 0.0026\nEpoch 16/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.2317 - accuracy: 0.0022 - val_loss: 0.3713 - val_accuracy: 0.0026\nEpoch 17/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.2207 - accuracy: 0.0022 - val_loss: 0.3729 - val_accuracy: 0.0026\nEpoch 18/100\n98/98 [==============================] - 6s 63ms/step - loss: 0.2080 - accuracy: 0.0022 - val_loss: 0.3930 - val_accuracy: 0.0026\nEpoch 19/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.1997 - accuracy: 0.0022 - val_loss: 0.3935 - val_accuracy: 0.0026\nEpoch 20/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.1988 - accuracy: 0.0022 - val_loss: 0.3964 - val_accuracy: 0.0026\nEpoch 21/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.1846 - accuracy: 0.0022 - val_loss: 0.4134 - val_accuracy: 0.0026\nEpoch 22/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.1765 - accuracy: 0.0022 - val_loss: 0.3975 - val_accuracy: 0.0026\nEpoch 23/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.1758 - accuracy: 0.0022 - val_loss: 0.4126 - val_accuracy: 0.0026\nEpoch 24/100\n98/98 [==============================] - 6s 63ms/step - loss: 0.1734 - accuracy: 0.0022 - val_loss: 0.4121 - val_accuracy: 0.0026\nEpoch 25/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.1565 - accuracy: 0.0022 - val_loss: 0.4168 - val_accuracy: 0.0026\nEpoch 26/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.1536 - accuracy: 0.0022 - val_loss: 0.4449 - val_accuracy: 0.0026\nEpoch 27/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.1477 - accuracy: 0.0022 - val_loss: 0.4189 - val_accuracy: 0.0026\nEpoch 28/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.1522 - accuracy: 0.0022 - val_loss: 0.4416 - val_accuracy: 0.0026\nEpoch 29/100\n98/98 [==============================] - 6s 63ms/step - loss: 0.1319 - accuracy: 0.0022 - val_loss: 0.4198 - val_accuracy: 0.0026\nEpoch 30/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.1370 - accuracy: 0.0022 - val_loss: 0.4223 - val_accuracy: 0.0026\nEpoch 31/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.1255 - accuracy: 0.0022 - val_loss: 0.4241 - val_accuracy: 0.0026\nEpoch 32/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.1265 - accuracy: 0.0022 - val_loss: 0.4180 - val_accuracy: 0.0026\nEpoch 33/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.1111 - accuracy: 0.0022 - val_loss: 0.4283 - val_accuracy: 0.0026\nEpoch 34/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.1059 - accuracy: 0.0022 - val_loss: 0.4360 - val_accuracy: 0.0026\nEpoch 35/100\n98/98 [==============================] - 6s 62ms/step - loss: 0.1109 - accuracy: 0.0022 - val_loss: 0.4320 - val_accuracy: 0.0026\nEpoch 36/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.1050 - accuracy: 0.0022 - val_loss: 0.4432 - val_accuracy: 0.0026\nEpoch 37/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.1040 - accuracy: 0.0022 - val_loss: 0.4313 - val_accuracy: 0.0026\nEpoch 38/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0956 - accuracy: 0.0022 - val_loss: 0.4299 - val_accuracy: 0.0026\nEpoch 39/100\n98/98 [==============================] - 6s 60ms/step - loss: 0.0971 - accuracy: 0.0022 - val_loss: 0.4433 - val_accuracy: 0.0026\nEpoch 40/100\n98/98 [==============================] - 6s 65ms/step - loss: 0.0919 - accuracy: 0.0022 - val_loss: 0.4391 - val_accuracy: 0.0026\nEpoch 41/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.0922 - accuracy: 0.0022 - val_loss: 0.4472 - val_accuracy: 0.0026\nEpoch 42/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0852 - accuracy: 0.0022 - val_loss: 0.4489 - val_accuracy: 0.0026\nEpoch 43/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0824 - accuracy: 0.0019 - val_loss: 0.4501 - val_accuracy: 0.0026\nEpoch 44/100\n98/98 [==============================] - 6s 60ms/step - loss: 0.0781 - accuracy: 0.0022 - val_loss: 0.4527 - val_accuracy: 0.0026\nEpoch 45/100\n98/98 [==============================] - 6s 61ms/step - loss: 0.0751 - accuracy: 0.0019 - val_loss: 0.4577 - val_accuracy: 0.0026\nEpoch 46/100\n98/98 [==============================] - 6s 65ms/step - loss: 0.0719 - accuracy: 0.0022 - val_loss: 0.4471 - val_accuracy: 0.0026\nEpoch 47/100\n98/98 [==============================] - 6s 60ms/step - loss: 0.0693 - accuracy: 0.0022 - val_loss: 0.4494 - val_accuracy: 0.0026\nEpoch 48/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0678 - accuracy: 0.0022 - val_loss: 0.4505 - val_accuracy: 0.0026\nEpoch 49/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0634 - accuracy: 0.0022 - val_loss: 0.4542 - val_accuracy: 0.0026\nEpoch 50/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0603 - accuracy: 0.0022 - val_loss: 0.4798 - val_accuracy: 0.0026\nEpoch 51/100\n98/98 [==============================] - 6s 62ms/step - loss: 0.0617 - accuracy: 0.0022 - val_loss: 0.4559 - val_accuracy: 0.0026\nEpoch 52/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0633 - accuracy: 0.0022 - val_loss: 0.4643 - val_accuracy: 0.0026\nEpoch 53/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.0581 - accuracy: 0.0022 - val_loss: 0.4652 - val_accuracy: 0.0026\nEpoch 54/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0547 - accuracy: 0.0022 - val_loss: 0.4704 - val_accuracy: 0.0026\nEpoch 55/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0522 - accuracy: 0.0022 - val_loss: 0.4597 - val_accuracy: 0.0026\nEpoch 56/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0499 - accuracy: 0.0022 - val_loss: 0.4631 - val_accuracy: 0.0026\nEpoch 57/100\n98/98 [==============================] - 6s 63ms/step - loss: 0.0488 - accuracy: 0.0022 - val_loss: 0.4625 - val_accuracy: 0.0026\nEpoch 58/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0489 - accuracy: 0.0022 - val_loss: 0.4628 - val_accuracy: 0.0026\nEpoch 59/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0464 - accuracy: 0.0022 - val_loss: 0.4814 - val_accuracy: 0.0026\nEpoch 60/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0431 - accuracy: 0.0022 - val_loss: 0.4667 - val_accuracy: 0.0026\nEpoch 61/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0394 - accuracy: 0.0022 - val_loss: 0.4621 - val_accuracy: 0.0026\nEpoch 62/100\n98/98 [==============================] - 6s 63ms/step - loss: 0.0394 - accuracy: 0.0022 - val_loss: 0.4715 - val_accuracy: 0.0026\nEpoch 63/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0401 - accuracy: 0.0022 - val_loss: 0.4788 - val_accuracy: 0.0026\nEpoch 64/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0392 - accuracy: 0.0022 - val_loss: 0.4730 - val_accuracy: 0.0026\nEpoch 65/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0375 - accuracy: 0.0022 - val_loss: 0.4692 - val_accuracy: 0.0026\nEpoch 66/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0369 - accuracy: 0.0019 - val_loss: 0.4855 - val_accuracy: 0.0026\nEpoch 67/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0361 - accuracy: 0.0022 - val_loss: 0.4658 - val_accuracy: 0.0026\nEpoch 68/100\n98/98 [==============================] - 6s 62ms/step - loss: 0.0340 - accuracy: 0.0019 - val_loss: 0.4699 - val_accuracy: 0.0026\nEpoch 69/100\n98/98 [==============================] - 6s 56ms/step - loss: 0.0343 - accuracy: 0.0019 - val_loss: 0.4725 - val_accuracy: 0.0026\nEpoch 70/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0329 - accuracy: 0.0019 - val_loss: 0.4941 - val_accuracy: 0.0026\nEpoch 71/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0317 - accuracy: 0.0022 - val_loss: 0.4624 - val_accuracy: 0.0026\nEpoch 72/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0290 - accuracy: 0.0022 - val_loss: 0.4902 - val_accuracy: 0.0026\nEpoch 73/100\n98/98 [==============================] - 6s 63ms/step - loss: 0.0294 - accuracy: 0.0019 - val_loss: 0.4852 - val_accuracy: 0.0026\nEpoch 74/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0273 - accuracy: 0.0022 - val_loss: 0.4813 - val_accuracy: 0.0026\nEpoch 75/100\n98/98 [==============================] - 6s 56ms/step - loss: 0.0279 - accuracy: 0.0019 - val_loss: 0.4856 - val_accuracy: 0.0026\nEpoch 76/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0271 - accuracy: 0.0022 - val_loss: 0.4753 - val_accuracy: 0.0026\nEpoch 77/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0259 - accuracy: 0.0022 - val_loss: 0.4780 - val_accuracy: 0.0026\nEpoch 78/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0273 - accuracy: 0.0022 - val_loss: 0.5014 - val_accuracy: 0.0026\nEpoch 79/100\n98/98 [==============================] - 6s 62ms/step - loss: 0.0259 - accuracy: 0.0022 - val_loss: 0.4714 - val_accuracy: 0.0026\nEpoch 80/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0257 - accuracy: 0.0022 - val_loss: 0.4925 - val_accuracy: 0.0026\nEpoch 81/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0247 - accuracy: 0.0022 - val_loss: 0.4741 - val_accuracy: 0.0026\nEpoch 82/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0244 - accuracy: 0.0019 - val_loss: 0.4801 - val_accuracy: 0.0026\nEpoch 83/100\n98/98 [==============================] - 6s 56ms/step - loss: 0.0226 - accuracy: 0.0019 - val_loss: 0.4684 - val_accuracy: 0.0026\nEpoch 84/100\n98/98 [==============================] - 6s 63ms/step - loss: 0.0244 - accuracy: 0.0022 - val_loss: 0.4844 - val_accuracy: 0.0026\nEpoch 85/100\n98/98 [==============================] - 6s 60ms/step - loss: 0.0234 - accuracy: 0.0022 - val_loss: 0.4827 - val_accuracy: 0.0026\nEpoch 86/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.0228 - accuracy: 0.0022 - val_loss: 0.4841 - val_accuracy: 0.0026\nEpoch 87/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0214 - accuracy: 0.0022 - val_loss: 0.4808 - val_accuracy: 0.0026\nEpoch 88/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0211 - accuracy: 0.0019 - val_loss: 0.4789 - val_accuracy: 0.0026\nEpoch 89/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0209 - accuracy: 0.0022 - val_loss: 0.4969 - val_accuracy: 0.0026\nEpoch 90/100\n98/98 [==============================] - 6s 63ms/step - loss: 0.0203 - accuracy: 0.0022 - val_loss: 0.5056 - val_accuracy: 0.0026\nEpoch 91/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0208 - accuracy: 0.0022 - val_loss: 0.4859 - val_accuracy: 0.0026\nEpoch 92/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0218 - accuracy: 0.0022 - val_loss: 0.4775 - val_accuracy: 0.0026\nEpoch 93/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0192 - accuracy: 0.0022 - val_loss: 0.4847 - val_accuracy: 0.0026\nEpoch 94/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0207 - accuracy: 0.0022 - val_loss: 0.4893 - val_accuracy: 0.0026\nEpoch 95/100\n98/98 [==============================] - 6s 63ms/step - loss: 0.0208 - accuracy: 0.0022 - val_loss: 0.4829 - val_accuracy: 0.0026\nEpoch 96/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0192 - accuracy: 0.0022 - val_loss: 0.4869 - val_accuracy: 0.0026\nEpoch 97/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0192 - accuracy: 0.0022 - val_loss: 0.4797 - val_accuracy: 0.0026\nEpoch 98/100\n98/98 [==============================] - 6s 56ms/step - loss: 0.0204 - accuracy: 0.0022 - val_loss: 0.4938 - val_accuracy: 0.0026\nEpoch 99/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0182 - accuracy: 0.0022 - val_loss: 0.4787 - val_accuracy: 0.0026\nEpoch 100/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0190 - accuracy: 0.0022 - val_loss: 0.4908 - val_accuracy: 0.0026\n","output_type":"stream"},{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"3"},"metadata":{}}]},{"cell_type":"code","source":"lstm_model3 = get_model_lstm()\nlstm_model3.fit(lstm_embed_train, y3_train, epochs=100,validation_data=(lstm_embed_val,y3_val))\nlstm_result_3 = lstm_model3.predict(lstm_embed_test_final).flatten()\nlstm_result_3 = [int(r) for r in lstm_result_3]\nlen(lstm_result_3)","metadata":{"execution":{"iopub.status.busy":"2022-11-26T08:16:57.786500Z","iopub.execute_input":"2022-11-26T08:16:57.787708Z","iopub.status.idle":"2022-11-26T08:26:37.219482Z","shell.execute_reply.started":"2022-11-26T08:16:57.787661Z","shell.execute_reply":"2022-11-26T08:26:37.218511Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"Model: \"sequential_8\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nlstm_2 (LSTM)                (None, 1, 128)            11007488  \n_________________________________________________________________\ndropout_22 (Dropout)         (None, 1, 128)            0         \n_________________________________________________________________\ndense_28 (Dense)             (None, 1, 32)             4128      \n_________________________________________________________________\ndropout_23 (Dropout)         (None, 1, 32)             0         \n_________________________________________________________________\ndense_29 (Dense)             (None, 1, 1)              33        \n=================================================================\nTotal params: 11,011,649\nTrainable params: 11,011,649\nNon-trainable params: 0\n_________________________________________________________________\nEpoch 1/100\n98/98 [==============================] - 9s 65ms/step - loss: 1.4676 - accuracy: 3.1959e-04 - val_loss: 0.3066 - val_accuracy: 0.0000e+00\nEpoch 2/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.5139 - accuracy: 6.3918e-04 - val_loss: 0.2580 - val_accuracy: 0.0000e+00\nEpoch 3/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.4380 - accuracy: 6.3918e-04 - val_loss: 0.2441 - val_accuracy: 0.0000e+00\nEpoch 4/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.4007 - accuracy: 6.3918e-04 - val_loss: 0.2365 - val_accuracy: 0.0000e+00\nEpoch 5/100\n98/98 [==============================] - 6s 63ms/step - loss: 0.3565 - accuracy: 6.3918e-04 - val_loss: 0.3007 - val_accuracy: 0.0000e+00\nEpoch 6/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.3534 - accuracy: 6.3918e-04 - val_loss: 0.2500 - val_accuracy: 0.0000e+00\nEpoch 7/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.3263 - accuracy: 6.3918e-04 - val_loss: 0.2479 - val_accuracy: 0.0000e+00\nEpoch 8/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.3122 - accuracy: 6.3918e-04 - val_loss: 0.2498 - val_accuracy: 0.0000e+00\nEpoch 9/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.2899 - accuracy: 6.3918e-04 - val_loss: 0.2674 - val_accuracy: 0.0000e+00\nEpoch 10/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.2848 - accuracy: 6.3918e-04 - val_loss: 0.2528 - val_accuracy: 0.0000e+00\nEpoch 11/100\n98/98 [==============================] - 6s 62ms/step - loss: 0.2613 - accuracy: 6.3918e-04 - val_loss: 0.2577 - val_accuracy: 0.0000e+00\nEpoch 12/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.2665 - accuracy: 6.3918e-04 - val_loss: 0.2550 - val_accuracy: 0.0000e+00\nEpoch 13/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.2513 - accuracy: 6.3918e-04 - val_loss: 0.2568 - val_accuracy: 0.0000e+00\nEpoch 14/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.2235 - accuracy: 6.3918e-04 - val_loss: 0.2642 - val_accuracy: 0.0000e+00\nEpoch 15/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.2220 - accuracy: 6.3918e-04 - val_loss: 0.2536 - val_accuracy: 0.0000e+00\nEpoch 16/100\n98/98 [==============================] - 6s 63ms/step - loss: 0.2152 - accuracy: 6.3918e-04 - val_loss: 0.2812 - val_accuracy: 0.0000e+00\nEpoch 17/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.2053 - accuracy: 6.3918e-04 - val_loss: 0.2615 - val_accuracy: 0.0000e+00\nEpoch 18/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.1953 - accuracy: 6.3918e-04 - val_loss: 0.2599 - val_accuracy: 0.0000e+00\nEpoch 19/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.1968 - accuracy: 6.3918e-04 - val_loss: 0.2602 - val_accuracy: 0.0000e+00\nEpoch 20/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.1837 - accuracy: 6.3918e-04 - val_loss: 0.2659 - val_accuracy: 0.0000e+00\nEpoch 21/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.1723 - accuracy: 6.3918e-04 - val_loss: 0.2726 - val_accuracy: 0.0000e+00\nEpoch 22/100\n98/98 [==============================] - 6s 63ms/step - loss: 0.1746 - accuracy: 6.3918e-04 - val_loss: 0.2882 - val_accuracy: 0.0000e+00\nEpoch 23/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.1681 - accuracy: 6.3918e-04 - val_loss: 0.2698 - val_accuracy: 0.0000e+00\nEpoch 24/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.1578 - accuracy: 6.3918e-04 - val_loss: 0.2935 - val_accuracy: 0.0000e+00\nEpoch 25/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.1501 - accuracy: 6.3918e-04 - val_loss: 0.2808 - val_accuracy: 0.0000e+00\nEpoch 26/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.1481 - accuracy: 6.3918e-04 - val_loss: 0.2795 - val_accuracy: 0.0000e+00\nEpoch 27/100\n98/98 [==============================] - 6s 63ms/step - loss: 0.1423 - accuracy: 6.3918e-04 - val_loss: 0.2780 - val_accuracy: 0.0000e+00\nEpoch 28/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.1404 - accuracy: 6.3918e-04 - val_loss: 0.2805 - val_accuracy: 0.0000e+00\nEpoch 29/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.1329 - accuracy: 6.3918e-04 - val_loss: 0.2875 - val_accuracy: 0.0000e+00\nEpoch 30/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.1269 - accuracy: 6.3918e-04 - val_loss: 0.2885 - val_accuracy: 0.0000e+00\nEpoch 31/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.1185 - accuracy: 6.3918e-04 - val_loss: 0.2821 - val_accuracy: 0.0000e+00\nEpoch 32/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.1162 - accuracy: 6.3918e-04 - val_loss: 0.2850 - val_accuracy: 0.0000e+00\nEpoch 33/100\n98/98 [==============================] - 6s 63ms/step - loss: 0.1118 - accuracy: 6.3918e-04 - val_loss: 0.2813 - val_accuracy: 0.0000e+00\nEpoch 34/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.1120 - accuracy: 6.3918e-04 - val_loss: 0.2931 - val_accuracy: 0.0000e+00\nEpoch 35/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.1032 - accuracy: 6.3918e-04 - val_loss: 0.2922 - val_accuracy: 0.0000e+00\nEpoch 36/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0983 - accuracy: 6.3918e-04 - val_loss: 0.2968 - val_accuracy: 0.0000e+00\nEpoch 37/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0898 - accuracy: 6.3918e-04 - val_loss: 0.2962 - val_accuracy: 0.0000e+00\nEpoch 38/100\n98/98 [==============================] - 6s 63ms/step - loss: 0.0919 - accuracy: 6.3918e-04 - val_loss: 0.3032 - val_accuracy: 0.0000e+00\nEpoch 39/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.0918 - accuracy: 6.3918e-04 - val_loss: 0.2978 - val_accuracy: 0.0000e+00\nEpoch 40/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0842 - accuracy: 6.3918e-04 - val_loss: 0.3047 - val_accuracy: 0.0000e+00\nEpoch 41/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0799 - accuracy: 6.3918e-04 - val_loss: 0.3076 - val_accuracy: 0.0000e+00\nEpoch 42/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0784 - accuracy: 6.3918e-04 - val_loss: 0.3005 - val_accuracy: 0.0000e+00\nEpoch 43/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0742 - accuracy: 6.3918e-04 - val_loss: 0.3092 - val_accuracy: 0.0000e+00\nEpoch 44/100\n98/98 [==============================] - 6s 63ms/step - loss: 0.0716 - accuracy: 6.3918e-04 - val_loss: 0.3011 - val_accuracy: 0.0000e+00\nEpoch 45/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0690 - accuracy: 6.3918e-04 - val_loss: 0.2979 - val_accuracy: 0.0000e+00\nEpoch 46/100\n98/98 [==============================] - 6s 60ms/step - loss: 0.0652 - accuracy: 6.3918e-04 - val_loss: 0.3114 - val_accuracy: 0.0000e+00\nEpoch 47/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0642 - accuracy: 6.3918e-04 - val_loss: 0.3135 - val_accuracy: 0.0000e+00\nEpoch 48/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0609 - accuracy: 6.3918e-04 - val_loss: 0.3008 - val_accuracy: 0.0000e+00\nEpoch 49/100\n98/98 [==============================] - 6s 63ms/step - loss: 0.0573 - accuracy: 6.3918e-04 - val_loss: 0.3202 - val_accuracy: 0.0000e+00\nEpoch 50/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0560 - accuracy: 3.1959e-04 - val_loss: 0.3071 - val_accuracy: 0.0000e+00\nEpoch 51/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0544 - accuracy: 6.3918e-04 - val_loss: 0.3154 - val_accuracy: 0.0000e+00\nEpoch 52/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0518 - accuracy: 6.3918e-04 - val_loss: 0.3087 - val_accuracy: 0.0000e+00\nEpoch 53/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0499 - accuracy: 6.3918e-04 - val_loss: 0.3102 - val_accuracy: 0.0000e+00\nEpoch 54/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.0495 - accuracy: 6.3918e-04 - val_loss: 0.3083 - val_accuracy: 0.0000e+00\nEpoch 55/100\n98/98 [==============================] - 6s 62ms/step - loss: 0.0464 - accuracy: 6.3918e-04 - val_loss: 0.3167 - val_accuracy: 0.0000e+00\nEpoch 56/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0419 - accuracy: 6.3918e-04 - val_loss: 0.3245 - val_accuracy: 0.0000e+00\nEpoch 57/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0418 - accuracy: 6.3918e-04 - val_loss: 0.3190 - val_accuracy: 0.0000e+00\nEpoch 58/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0394 - accuracy: 6.3918e-04 - val_loss: 0.3229 - val_accuracy: 0.0000e+00\nEpoch 59/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0405 - accuracy: 6.3918e-04 - val_loss: 0.3159 - val_accuracy: 0.0000e+00\nEpoch 60/100\n98/98 [==============================] - 6s 63ms/step - loss: 0.0351 - accuracy: 6.3918e-04 - val_loss: 0.3183 - val_accuracy: 0.0000e+00\nEpoch 61/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0353 - accuracy: 6.3918e-04 - val_loss: 0.3196 - val_accuracy: 0.0000e+00\nEpoch 62/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0322 - accuracy: 6.3918e-04 - val_loss: 0.3241 - val_accuracy: 0.0000e+00\nEpoch 63/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0353 - accuracy: 3.1959e-04 - val_loss: 0.3299 - val_accuracy: 0.0000e+00\nEpoch 64/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0310 - accuracy: 6.3918e-04 - val_loss: 0.3298 - val_accuracy: 0.0000e+00\nEpoch 65/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.0304 - accuracy: 6.3918e-04 - val_loss: 0.3314 - val_accuracy: 0.0000e+00\nEpoch 66/100\n98/98 [==============================] - 6s 65ms/step - loss: 0.0302 - accuracy: 6.3918e-04 - val_loss: 0.3334 - val_accuracy: 0.0000e+00\nEpoch 67/100\n98/98 [==============================] - 6s 60ms/step - loss: 0.0289 - accuracy: 6.3918e-04 - val_loss: 0.3267 - val_accuracy: 0.0000e+00\nEpoch 68/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0275 - accuracy: 3.1959e-04 - val_loss: 0.3335 - val_accuracy: 0.0000e+00\nEpoch 69/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0266 - accuracy: 6.3918e-04 - val_loss: 0.3287 - val_accuracy: 0.0000e+00\nEpoch 70/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0252 - accuracy: 6.3918e-04 - val_loss: 0.3234 - val_accuracy: 0.0000e+00\nEpoch 71/100\n98/98 [==============================] - 6s 64ms/step - loss: 0.0254 - accuracy: 6.3918e-04 - val_loss: 0.3247 - val_accuracy: 0.0000e+00\nEpoch 72/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0249 - accuracy: 6.3918e-04 - val_loss: 0.3268 - val_accuracy: 0.0000e+00\nEpoch 73/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0230 - accuracy: 6.3918e-04 - val_loss: 0.3291 - val_accuracy: 0.0000e+00\nEpoch 74/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0238 - accuracy: 6.3918e-04 - val_loss: 0.3244 - val_accuracy: 0.0000e+00\nEpoch 75/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0241 - accuracy: 6.3918e-04 - val_loss: 0.3357 - val_accuracy: 0.0000e+00\nEpoch 76/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0208 - accuracy: 6.3918e-04 - val_loss: 0.3340 - val_accuracy: 0.0000e+00\nEpoch 77/100\n98/98 [==============================] - 6s 64ms/step - loss: 0.0227 - accuracy: 6.3918e-04 - val_loss: 0.3369 - val_accuracy: 0.0000e+00\nEpoch 78/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0216 - accuracy: 6.3918e-04 - val_loss: 0.3292 - val_accuracy: 0.0000e+00\nEpoch 79/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0202 - accuracy: 6.3918e-04 - val_loss: 0.3302 - val_accuracy: 0.0000e+00\nEpoch 80/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0192 - accuracy: 6.3918e-04 - val_loss: 0.3496 - val_accuracy: 0.0000e+00\nEpoch 81/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0187 - accuracy: 6.3918e-04 - val_loss: 0.3305 - val_accuracy: 0.0000e+00\nEpoch 82/100\n98/98 [==============================] - 6s 62ms/step - loss: 0.0192 - accuracy: 6.3918e-04 - val_loss: 0.3409 - val_accuracy: 0.0000e+00\nEpoch 83/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0182 - accuracy: 6.3918e-04 - val_loss: 0.3268 - val_accuracy: 0.0000e+00\nEpoch 84/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0180 - accuracy: 6.3918e-04 - val_loss: 0.3231 - val_accuracy: 0.0000e+00\nEpoch 85/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0176 - accuracy: 6.3918e-04 - val_loss: 0.3317 - val_accuracy: 0.0000e+00\nEpoch 86/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0183 - accuracy: 6.3918e-04 - val_loss: 0.3529 - val_accuracy: 0.0000e+00\nEpoch 87/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0178 - accuracy: 6.3918e-04 - val_loss: 0.3414 - val_accuracy: 0.0000e+00\nEpoch 88/100\n98/98 [==============================] - 6s 63ms/step - loss: 0.0169 - accuracy: 6.3918e-04 - val_loss: 0.3416 - val_accuracy: 0.0000e+00\nEpoch 89/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.0177 - accuracy: 6.3918e-04 - val_loss: 0.3429 - val_accuracy: 0.0000e+00\nEpoch 90/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.0163 - accuracy: 6.3918e-04 - val_loss: 0.3348 - val_accuracy: 0.0000e+00\nEpoch 91/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0155 - accuracy: 6.3918e-04 - val_loss: 0.3320 - val_accuracy: 0.0000e+00\nEpoch 92/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0171 - accuracy: 6.3918e-04 - val_loss: 0.3436 - val_accuracy: 0.0000e+00\nEpoch 93/100\n98/98 [==============================] - 6s 63ms/step - loss: 0.0163 - accuracy: 6.3918e-04 - val_loss: 0.3304 - val_accuracy: 0.0000e+00\nEpoch 94/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.0149 - accuracy: 6.3918e-04 - val_loss: 0.3403 - val_accuracy: 0.0000e+00\nEpoch 95/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0165 - accuracy: 6.3918e-04 - val_loss: 0.3425 - val_accuracy: 0.0000e+00\nEpoch 96/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0154 - accuracy: 6.3918e-04 - val_loss: 0.3380 - val_accuracy: 0.0000e+00\nEpoch 97/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0154 - accuracy: 6.3918e-04 - val_loss: 0.3369 - val_accuracy: 0.0000e+00\nEpoch 98/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.0150 - accuracy: 6.3918e-04 - val_loss: 0.3410 - val_accuracy: 0.0000e+00\nEpoch 99/100\n98/98 [==============================] - 6s 63ms/step - loss: 0.0149 - accuracy: 6.3918e-04 - val_loss: 0.3318 - val_accuracy: 0.0000e+00\nEpoch 100/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0150 - accuracy: 6.3918e-04 - val_loss: 0.3351 - val_accuracy: 0.0000e+00\n","output_type":"stream"},{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"3"},"metadata":{}}]},{"cell_type":"code","source":"lstm_model4 = get_model_lstm()\nlstm_model4.fit(lstm_embed_train, y4_train, epochs=100,validation_data=(lstm_embed_val,y4_val))\nlstm_result_4 = lstm_model4.predict(lstm_embed_test_final).flatten()\nlstm_result_4 = [int(r) for r in lstm_result_4]\nlen(lstm_result_4)","metadata":{"execution":{"iopub.status.busy":"2022-11-26T08:26:37.221958Z","iopub.execute_input":"2022-11-26T08:26:37.226362Z","iopub.status.idle":"2022-11-26T08:36:15.351055Z","shell.execute_reply.started":"2022-11-26T08:26:37.226312Z","shell.execute_reply":"2022-11-26T08:36:15.349890Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"Model: \"sequential_9\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nlstm_3 (LSTM)                (None, 1, 128)            11007488  \n_________________________________________________________________\ndropout_24 (Dropout)         (None, 1, 128)            0         \n_________________________________________________________________\ndense_30 (Dense)             (None, 1, 32)             4128      \n_________________________________________________________________\ndropout_25 (Dropout)         (None, 1, 32)             0         \n_________________________________________________________________\ndense_31 (Dense)             (None, 1, 1)              33        \n=================================================================\nTotal params: 11,011,649\nTrainable params: 11,011,649\nNon-trainable params: 0\n_________________________________________________________________\nEpoch 1/100\n98/98 [==============================] - 9s 63ms/step - loss: 1.4812 - accuracy: 0.0026 - val_loss: 0.3377 - val_accuracy: 0.0000e+00\nEpoch 2/100\n98/98 [==============================] - 6s 56ms/step - loss: 0.5388 - accuracy: 0.0029 - val_loss: 0.3351 - val_accuracy: 0.0000e+00\nEpoch 3/100\n98/98 [==============================] - 6s 63ms/step - loss: 0.4595 - accuracy: 0.0029 - val_loss: 0.2915 - val_accuracy: 0.0000e+00\nEpoch 4/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.4253 - accuracy: 0.0029 - val_loss: 0.2943 - val_accuracy: 0.0000e+00\nEpoch 5/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.3730 - accuracy: 0.0029 - val_loss: 0.2932 - val_accuracy: 0.0000e+00\nEpoch 6/100\n98/98 [==============================] - 6s 56ms/step - loss: 0.3500 - accuracy: 0.0029 - val_loss: 0.3121 - val_accuracy: 0.0000e+00\nEpoch 7/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.3352 - accuracy: 0.0029 - val_loss: 0.3323 - val_accuracy: 0.0000e+00\nEpoch 8/100\n98/98 [==============================] - 6s 56ms/step - loss: 0.3168 - accuracy: 0.0029 - val_loss: 0.3208 - val_accuracy: 0.0000e+00\nEpoch 9/100\n98/98 [==============================] - 6s 63ms/step - loss: 0.3100 - accuracy: 0.0029 - val_loss: 0.3441 - val_accuracy: 0.0000e+00\nEpoch 10/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.2833 - accuracy: 0.0029 - val_loss: 0.3301 - val_accuracy: 0.0000e+00\nEpoch 11/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.2776 - accuracy: 0.0029 - val_loss: 0.3292 - val_accuracy: 0.0000e+00\nEpoch 12/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.2668 - accuracy: 0.0029 - val_loss: 0.3314 - val_accuracy: 0.0000e+00\nEpoch 13/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.2569 - accuracy: 0.0029 - val_loss: 0.3410 - val_accuracy: 0.0000e+00\nEpoch 14/100\n98/98 [==============================] - 6s 63ms/step - loss: 0.2330 - accuracy: 0.0029 - val_loss: 0.3788 - val_accuracy: 0.0000e+00\nEpoch 15/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.2348 - accuracy: 0.0029 - val_loss: 0.3728 - val_accuracy: 0.0000e+00\nEpoch 16/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.2235 - accuracy: 0.0029 - val_loss: 0.3578 - val_accuracy: 0.0000e+00\nEpoch 17/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.2094 - accuracy: 0.0029 - val_loss: 0.3430 - val_accuracy: 0.0000e+00\nEpoch 18/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.1988 - accuracy: 0.0029 - val_loss: 0.3633 - val_accuracy: 0.0000e+00\nEpoch 19/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.2018 - accuracy: 0.0029 - val_loss: 0.3616 - val_accuracy: 0.0000e+00\nEpoch 20/100\n98/98 [==============================] - 6s 63ms/step - loss: 0.1828 - accuracy: 0.0029 - val_loss: 0.3649 - val_accuracy: 0.0000e+00\nEpoch 21/100\n98/98 [==============================] - 6s 56ms/step - loss: 0.1845 - accuracy: 0.0029 - val_loss: 0.3672 - val_accuracy: 0.0000e+00\nEpoch 22/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.1770 - accuracy: 0.0029 - val_loss: 0.4083 - val_accuracy: 0.0000e+00\nEpoch 23/100\n98/98 [==============================] - 6s 56ms/step - loss: 0.1711 - accuracy: 0.0029 - val_loss: 0.3937 - val_accuracy: 0.0000e+00\nEpoch 24/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.1618 - accuracy: 0.0029 - val_loss: 0.3843 - val_accuracy: 0.0000e+00\nEpoch 25/100\n98/98 [==============================] - 6s 62ms/step - loss: 0.1610 - accuracy: 0.0029 - val_loss: 0.3828 - val_accuracy: 0.0000e+00\nEpoch 26/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.1565 - accuracy: 0.0029 - val_loss: 0.3791 - val_accuracy: 0.0000e+00\nEpoch 27/100\n98/98 [==============================] - 6s 56ms/step - loss: 0.1459 - accuracy: 0.0029 - val_loss: 0.3991 - val_accuracy: 0.0000e+00\nEpoch 28/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.1417 - accuracy: 0.0029 - val_loss: 0.3861 - val_accuracy: 0.0000e+00\nEpoch 29/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.1320 - accuracy: 0.0029 - val_loss: 0.3758 - val_accuracy: 0.0000e+00\nEpoch 30/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.1286 - accuracy: 0.0029 - val_loss: 0.3872 - val_accuracy: 0.0000e+00\nEpoch 31/100\n98/98 [==============================] - 6s 62ms/step - loss: 0.1262 - accuracy: 0.0029 - val_loss: 0.3821 - val_accuracy: 0.0000e+00\nEpoch 32/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.1198 - accuracy: 0.0029 - val_loss: 0.3939 - val_accuracy: 0.0000e+00\nEpoch 33/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.1200 - accuracy: 0.0029 - val_loss: 0.3886 - val_accuracy: 0.0000e+00\nEpoch 34/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.1147 - accuracy: 0.0029 - val_loss: 0.3885 - val_accuracy: 0.0000e+00\nEpoch 35/100\n98/98 [==============================] - 6s 56ms/step - loss: 0.1062 - accuracy: 0.0029 - val_loss: 0.4037 - val_accuracy: 0.0000e+00\nEpoch 36/100\n98/98 [==============================] - 6s 63ms/step - loss: 0.1060 - accuracy: 0.0029 - val_loss: 0.4019 - val_accuracy: 0.0000e+00\nEpoch 37/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.1011 - accuracy: 0.0029 - val_loss: 0.4181 - val_accuracy: 0.0000e+00\nEpoch 38/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0952 - accuracy: 0.0029 - val_loss: 0.4103 - val_accuracy: 0.0000e+00\nEpoch 39/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0916 - accuracy: 0.0026 - val_loss: 0.4162 - val_accuracy: 0.0000e+00\nEpoch 40/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0892 - accuracy: 0.0029 - val_loss: 0.4023 - val_accuracy: 0.0000e+00\nEpoch 41/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0838 - accuracy: 0.0029 - val_loss: 0.4111 - val_accuracy: 0.0000e+00\nEpoch 42/100\n98/98 [==============================] - 6s 64ms/step - loss: 0.0842 - accuracy: 0.0029 - val_loss: 0.4085 - val_accuracy: 0.0000e+00\nEpoch 43/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0788 - accuracy: 0.0029 - val_loss: 0.4109 - val_accuracy: 0.0000e+00\nEpoch 44/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0765 - accuracy: 0.0029 - val_loss: 0.4118 - val_accuracy: 0.0000e+00\nEpoch 45/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0775 - accuracy: 0.0029 - val_loss: 0.4020 - val_accuracy: 0.0000e+00\nEpoch 46/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0727 - accuracy: 0.0026 - val_loss: 0.4149 - val_accuracy: 0.0000e+00\nEpoch 47/100\n98/98 [==============================] - 6s 63ms/step - loss: 0.0687 - accuracy: 0.0029 - val_loss: 0.4041 - val_accuracy: 0.0000e+00\nEpoch 48/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0639 - accuracy: 0.0029 - val_loss: 0.4336 - val_accuracy: 0.0000e+00\nEpoch 49/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0634 - accuracy: 0.0029 - val_loss: 0.4169 - val_accuracy: 0.0000e+00\nEpoch 50/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0634 - accuracy: 0.0029 - val_loss: 0.4398 - val_accuracy: 0.0000e+00\nEpoch 51/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0554 - accuracy: 0.0026 - val_loss: 0.4271 - val_accuracy: 0.0000e+00\nEpoch 52/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.0545 - accuracy: 0.0029 - val_loss: 0.4341 - val_accuracy: 0.0000e+00\nEpoch 53/100\n98/98 [==============================] - 6s 65ms/step - loss: 0.0546 - accuracy: 0.0029 - val_loss: 0.4286 - val_accuracy: 0.0000e+00\nEpoch 54/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.0493 - accuracy: 0.0029 - val_loss: 0.4292 - val_accuracy: 0.0000e+00\nEpoch 55/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.0502 - accuracy: 0.0029 - val_loss: 0.4439 - val_accuracy: 0.0000e+00\nEpoch 56/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0508 - accuracy: 0.0029 - val_loss: 0.4314 - val_accuracy: 0.0000e+00\nEpoch 57/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0463 - accuracy: 0.0029 - val_loss: 0.4364 - val_accuracy: 0.0000e+00\nEpoch 58/100\n98/98 [==============================] - 6s 64ms/step - loss: 0.0425 - accuracy: 0.0029 - val_loss: 0.4242 - val_accuracy: 0.0000e+00\nEpoch 59/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.0418 - accuracy: 0.0029 - val_loss: 0.4509 - val_accuracy: 0.0000e+00\nEpoch 60/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0416 - accuracy: 0.0029 - val_loss: 0.4401 - val_accuracy: 0.0000e+00\nEpoch 61/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0394 - accuracy: 0.0029 - val_loss: 0.4514 - val_accuracy: 0.0000e+00\nEpoch 62/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0388 - accuracy: 0.0029 - val_loss: 0.4394 - val_accuracy: 0.0000e+00\nEpoch 63/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0401 - accuracy: 0.0029 - val_loss: 0.4427 - val_accuracy: 0.0000e+00\nEpoch 64/100\n98/98 [==============================] - 6s 64ms/step - loss: 0.0362 - accuracy: 0.0029 - val_loss: 0.4467 - val_accuracy: 0.0000e+00\nEpoch 65/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.0375 - accuracy: 0.0029 - val_loss: 0.4470 - val_accuracy: 0.0000e+00\nEpoch 66/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0328 - accuracy: 0.0029 - val_loss: 0.4454 - val_accuracy: 0.0000e+00\nEpoch 67/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0319 - accuracy: 0.0029 - val_loss: 0.4520 - val_accuracy: 0.0000e+00\nEpoch 68/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0337 - accuracy: 0.0029 - val_loss: 0.4725 - val_accuracy: 0.0000e+00\nEpoch 69/100\n98/98 [==============================] - 6s 63ms/step - loss: 0.0307 - accuracy: 0.0029 - val_loss: 0.4604 - val_accuracy: 0.0000e+00\nEpoch 70/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.0313 - accuracy: 0.0026 - val_loss: 0.4537 - val_accuracy: 0.0000e+00\nEpoch 71/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0296 - accuracy: 0.0029 - val_loss: 0.4325 - val_accuracy: 0.0000e+00\nEpoch 72/100\n98/98 [==============================] - 6s 60ms/step - loss: 0.0295 - accuracy: 0.0029 - val_loss: 0.4481 - val_accuracy: 0.0000e+00\nEpoch 73/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0284 - accuracy: 0.0026 - val_loss: 0.4602 - val_accuracy: 0.0000e+00\nEpoch 74/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.0261 - accuracy: 0.0026 - val_loss: 0.4504 - val_accuracy: 0.0000e+00\nEpoch 75/100\n98/98 [==============================] - 6s 60ms/step - loss: 0.0276 - accuracy: 0.0029 - val_loss: 0.4504 - val_accuracy: 0.0000e+00\nEpoch 76/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0271 - accuracy: 0.0029 - val_loss: 0.4383 - val_accuracy: 0.0000e+00\nEpoch 77/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0260 - accuracy: 0.0026 - val_loss: 0.4426 - val_accuracy: 0.0000e+00\nEpoch 78/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0245 - accuracy: 0.0026 - val_loss: 0.4682 - val_accuracy: 0.0000e+00\nEpoch 79/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0242 - accuracy: 0.0029 - val_loss: 0.4475 - val_accuracy: 0.0000e+00\nEpoch 80/100\n98/98 [==============================] - 6s 63ms/step - loss: 0.0249 - accuracy: 0.0029 - val_loss: 0.4538 - val_accuracy: 0.0000e+00\nEpoch 81/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0245 - accuracy: 0.0029 - val_loss: 0.4536 - val_accuracy: 0.0000e+00\nEpoch 82/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0227 - accuracy: 0.0026 - val_loss: 0.4379 - val_accuracy: 0.0000e+00\nEpoch 83/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0219 - accuracy: 0.0029 - val_loss: 0.4411 - val_accuracy: 0.0000e+00\nEpoch 84/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0211 - accuracy: 0.0026 - val_loss: 0.4356 - val_accuracy: 0.0000e+00\nEpoch 85/100\n98/98 [==============================] - 6s 56ms/step - loss: 0.0214 - accuracy: 0.0029 - val_loss: 0.4431 - val_accuracy: 0.0000e+00\nEpoch 86/100\n98/98 [==============================] - 6s 63ms/step - loss: 0.0221 - accuracy: 0.0029 - val_loss: 0.4473 - val_accuracy: 0.0000e+00\nEpoch 87/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0216 - accuracy: 0.0029 - val_loss: 0.4563 - val_accuracy: 0.0000e+00\nEpoch 88/100\n98/98 [==============================] - 6s 56ms/step - loss: 0.0202 - accuracy: 0.0029 - val_loss: 0.4467 - val_accuracy: 0.0000e+00\nEpoch 89/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0208 - accuracy: 0.0029 - val_loss: 0.4455 - val_accuracy: 0.0000e+00\nEpoch 90/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0213 - accuracy: 0.0029 - val_loss: 0.4398 - val_accuracy: 0.0000e+00\nEpoch 91/100\n98/98 [==============================] - 6s 63ms/step - loss: 0.0192 - accuracy: 0.0029 - val_loss: 0.4701 - val_accuracy: 0.0000e+00\nEpoch 92/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.0209 - accuracy: 0.0026 - val_loss: 0.4404 - val_accuracy: 0.0000e+00\nEpoch 93/100\n98/98 [==============================] - 6s 60ms/step - loss: 0.0211 - accuracy: 0.0026 - val_loss: 0.4605 - val_accuracy: 0.0000e+00\nEpoch 94/100\n98/98 [==============================] - 6s 60ms/step - loss: 0.0208 - accuracy: 0.0029 - val_loss: 0.4674 - val_accuracy: 0.0000e+00\nEpoch 95/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.0194 - accuracy: 0.0026 - val_loss: 0.4462 - val_accuracy: 0.0000e+00\nEpoch 96/100\n98/98 [==============================] - 6s 62ms/step - loss: 0.0192 - accuracy: 0.0029 - val_loss: 0.4535 - val_accuracy: 0.0000e+00\nEpoch 97/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0182 - accuracy: 0.0029 - val_loss: 0.4566 - val_accuracy: 0.0000e+00\nEpoch 98/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0188 - accuracy: 0.0029 - val_loss: 0.4556 - val_accuracy: 0.0000e+00\nEpoch 99/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0198 - accuracy: 0.0029 - val_loss: 0.4434 - val_accuracy: 0.0000e+00\nEpoch 100/100\n98/98 [==============================] - 6s 56ms/step - loss: 0.0178 - accuracy: 0.0029 - val_loss: 0.4480 - val_accuracy: 0.0000e+00\n","output_type":"stream"},{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"3"},"metadata":{}}]},{"cell_type":"code","source":"lstm_model5 = get_model_lstm()\nlstm_model5.fit(lstm_embed_train, y5_train, epochs=100,validation_data=(lstm_embed_val,y5_val))\nlstm_result_5 = lstm_model5.predict(lstm_embed_test_final).flatten()\nlstm_result_5 = [int(r) for r in lstm_result_5]\nlen(lstm_result_5)","metadata":{"execution":{"iopub.status.busy":"2022-11-26T08:36:15.352959Z","iopub.execute_input":"2022-11-26T08:36:15.353689Z","iopub.status.idle":"2022-11-26T08:46:08.465827Z","shell.execute_reply.started":"2022-11-26T08:36:15.353642Z","shell.execute_reply":"2022-11-26T08:46:08.464632Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"Model: \"sequential_10\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nlstm_4 (LSTM)                (None, 1, 128)            11007488  \n_________________________________________________________________\ndropout_26 (Dropout)         (None, 1, 128)            0         \n_________________________________________________________________\ndense_32 (Dense)             (None, 1, 32)             4128      \n_________________________________________________________________\ndropout_27 (Dropout)         (None, 1, 32)             0         \n_________________________________________________________________\ndense_33 (Dense)             (None, 1, 1)              33        \n=================================================================\nTotal params: 11,011,649\nTrainable params: 11,011,649\nNon-trainable params: 0\n_________________________________________________________________\nEpoch 1/100\n98/98 [==============================] - 9s 68ms/step - loss: 1.5009 - accuracy: 0.0019 - val_loss: 0.5438 - val_accuracy: 0.0000e+00\nEpoch 2/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.5935 - accuracy: 0.0022 - val_loss: 0.4110 - val_accuracy: 0.0000e+00\nEpoch 3/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.4894 - accuracy: 0.0022 - val_loss: 0.3949 - val_accuracy: 0.0000e+00\nEpoch 4/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.4212 - accuracy: 0.0022 - val_loss: 0.4644 - val_accuracy: 0.0000e+00\nEpoch 5/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.4059 - accuracy: 0.0022 - val_loss: 0.3985 - val_accuracy: 0.0000e+00\nEpoch 6/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.3565 - accuracy: 0.0022 - val_loss: 0.4106 - val_accuracy: 0.0000e+00\nEpoch 7/100\n98/98 [==============================] - 6s 62ms/step - loss: 0.3414 - accuracy: 0.0022 - val_loss: 0.4458 - val_accuracy: 0.0000e+00\nEpoch 8/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.3242 - accuracy: 0.0022 - val_loss: 0.4166 - val_accuracy: 0.0000e+00\nEpoch 9/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.3098 - accuracy: 0.0022 - val_loss: 0.4448 - val_accuracy: 0.0000e+00\nEpoch 10/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.2802 - accuracy: 0.0022 - val_loss: 0.4309 - val_accuracy: 0.0000e+00\nEpoch 11/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.2740 - accuracy: 0.0022 - val_loss: 0.4509 - val_accuracy: 0.0000e+00\nEpoch 12/100\n98/98 [==============================] - 6s 65ms/step - loss: 0.2682 - accuracy: 0.0022 - val_loss: 0.4536 - val_accuracy: 0.0000e+00\nEpoch 13/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.2500 - accuracy: 0.0022 - val_loss: 0.4524 - val_accuracy: 0.0000e+00\nEpoch 14/100\n98/98 [==============================] - 6s 60ms/step - loss: 0.2435 - accuracy: 0.0022 - val_loss: 0.4804 - val_accuracy: 0.0000e+00\nEpoch 15/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.2195 - accuracy: 0.0022 - val_loss: 0.4834 - val_accuracy: 0.0000e+00\nEpoch 16/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.2259 - accuracy: 0.0022 - val_loss: 0.4754 - val_accuracy: 0.0000e+00\nEpoch 17/100\n98/98 [==============================] - 6s 65ms/step - loss: 0.2170 - accuracy: 0.0022 - val_loss: 0.4730 - val_accuracy: 0.0000e+00\nEpoch 18/100\n98/98 [==============================] - 6s 60ms/step - loss: 0.2090 - accuracy: 0.0022 - val_loss: 0.5192 - val_accuracy: 0.0000e+00\nEpoch 19/100\n98/98 [==============================] - 6s 60ms/step - loss: 0.2048 - accuracy: 0.0022 - val_loss: 0.4835 - val_accuracy: 0.0000e+00\nEpoch 20/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.1829 - accuracy: 0.0022 - val_loss: 0.4856 - val_accuracy: 0.0000e+00\nEpoch 21/100\n98/98 [==============================] - 6s 60ms/step - loss: 0.1854 - accuracy: 0.0022 - val_loss: 0.4807 - val_accuracy: 0.0000e+00\nEpoch 22/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.1754 - accuracy: 0.0022 - val_loss: 0.5103 - val_accuracy: 0.0000e+00\nEpoch 23/100\n98/98 [==============================] - 6s 65ms/step - loss: 0.1743 - accuracy: 0.0022 - val_loss: 0.5145 - val_accuracy: 0.0000e+00\nEpoch 24/100\n98/98 [==============================] - 6s 60ms/step - loss: 0.1592 - accuracy: 0.0022 - val_loss: 0.4815 - val_accuracy: 0.0000e+00\nEpoch 25/100\n98/98 [==============================] - 6s 61ms/step - loss: 0.1679 - accuracy: 0.0022 - val_loss: 0.4827 - val_accuracy: 0.0000e+00\nEpoch 26/100\n98/98 [==============================] - 6s 60ms/step - loss: 0.1537 - accuracy: 0.0022 - val_loss: 0.4984 - val_accuracy: 0.0000e+00\nEpoch 27/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.1512 - accuracy: 0.0022 - val_loss: 0.5158 - val_accuracy: 0.0000e+00\nEpoch 28/100\n98/98 [==============================] - 6s 65ms/step - loss: 0.1474 - accuracy: 0.0019 - val_loss: 0.5067 - val_accuracy: 0.0000e+00\nEpoch 29/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.1330 - accuracy: 0.0022 - val_loss: 0.4996 - val_accuracy: 0.0000e+00\nEpoch 30/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.1309 - accuracy: 0.0022 - val_loss: 0.5363 - val_accuracy: 0.0000e+00\nEpoch 31/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.1320 - accuracy: 0.0022 - val_loss: 0.5164 - val_accuracy: 0.0000e+00\nEpoch 32/100\n98/98 [==============================] - 6s 60ms/step - loss: 0.1217 - accuracy: 0.0022 - val_loss: 0.5065 - val_accuracy: 0.0000e+00\nEpoch 33/100\n98/98 [==============================] - 6s 65ms/step - loss: 0.1172 - accuracy: 0.0022 - val_loss: 0.5372 - val_accuracy: 0.0000e+00\nEpoch 34/100\n98/98 [==============================] - 6s 60ms/step - loss: 0.1136 - accuracy: 0.0022 - val_loss: 0.5163 - val_accuracy: 0.0000e+00\nEpoch 35/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.1135 - accuracy: 0.0022 - val_loss: 0.5235 - val_accuracy: 0.0000e+00\nEpoch 36/100\n98/98 [==============================] - 6s 60ms/step - loss: 0.1073 - accuracy: 0.0022 - val_loss: 0.5068 - val_accuracy: 0.0000e+00\nEpoch 37/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.1028 - accuracy: 0.0022 - val_loss: 0.5204 - val_accuracy: 0.0000e+00\nEpoch 38/100\n98/98 [==============================] - 6s 60ms/step - loss: 0.1033 - accuracy: 0.0022 - val_loss: 0.5240 - val_accuracy: 0.0000e+00\nEpoch 39/100\n98/98 [==============================] - 6s 65ms/step - loss: 0.0967 - accuracy: 0.0022 - val_loss: 0.5276 - val_accuracy: 0.0000e+00\nEpoch 40/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0921 - accuracy: 0.0022 - val_loss: 0.5396 - val_accuracy: 0.0000e+00\nEpoch 41/100\n98/98 [==============================] - 6s 60ms/step - loss: 0.0842 - accuracy: 0.0022 - val_loss: 0.5268 - val_accuracy: 0.0000e+00\nEpoch 42/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.0847 - accuracy: 0.0022 - val_loss: 0.5491 - val_accuracy: 0.0000e+00\nEpoch 43/100\n98/98 [==============================] - 6s 60ms/step - loss: 0.0809 - accuracy: 0.0022 - val_loss: 0.5387 - val_accuracy: 0.0000e+00\nEpoch 44/100\n98/98 [==============================] - 6s 65ms/step - loss: 0.0802 - accuracy: 0.0022 - val_loss: 0.5437 - val_accuracy: 0.0000e+00\nEpoch 45/100\n98/98 [==============================] - 6s 61ms/step - loss: 0.0738 - accuracy: 0.0022 - val_loss: 0.5384 - val_accuracy: 0.0000e+00\nEpoch 46/100\n98/98 [==============================] - 6s 60ms/step - loss: 0.0783 - accuracy: 0.0022 - val_loss: 0.5372 - val_accuracy: 0.0000e+00\nEpoch 47/100\n98/98 [==============================] - 6s 61ms/step - loss: 0.0760 - accuracy: 0.0022 - val_loss: 0.5397 - val_accuracy: 0.0000e+00\nEpoch 48/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.0701 - accuracy: 0.0019 - val_loss: 0.5439 - val_accuracy: 0.0000e+00\nEpoch 49/100\n98/98 [==============================] - 6s 65ms/step - loss: 0.0660 - accuracy: 0.0022 - val_loss: 0.5376 - val_accuracy: 0.0000e+00\nEpoch 50/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.0697 - accuracy: 0.0022 - val_loss: 0.5365 - val_accuracy: 0.0000e+00\nEpoch 51/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.0632 - accuracy: 0.0022 - val_loss: 0.5519 - val_accuracy: 0.0000e+00\nEpoch 52/100\n98/98 [==============================] - 6s 60ms/step - loss: 0.0615 - accuracy: 0.0022 - val_loss: 0.5592 - val_accuracy: 0.0000e+00\nEpoch 53/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.0598 - accuracy: 0.0022 - val_loss: 0.5508 - val_accuracy: 0.0000e+00\nEpoch 54/100\n98/98 [==============================] - 6s 61ms/step - loss: 0.0585 - accuracy: 0.0022 - val_loss: 0.5450 - val_accuracy: 0.0000e+00\nEpoch 55/100\n98/98 [==============================] - 6s 65ms/step - loss: 0.0544 - accuracy: 0.0022 - val_loss: 0.5691 - val_accuracy: 0.0000e+00\nEpoch 56/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.0532 - accuracy: 0.0022 - val_loss: 0.5634 - val_accuracy: 0.0000e+00\nEpoch 57/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.0495 - accuracy: 0.0019 - val_loss: 0.5475 - val_accuracy: 0.0000e+00\nEpoch 58/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.0478 - accuracy: 0.0019 - val_loss: 0.5451 - val_accuracy: 0.0000e+00\nEpoch 59/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.0464 - accuracy: 0.0019 - val_loss: 0.5614 - val_accuracy: 0.0000e+00\nEpoch 60/100\n98/98 [==============================] - 6s 66ms/step - loss: 0.0488 - accuracy: 0.0022 - val_loss: 0.5517 - val_accuracy: 0.0000e+00\nEpoch 61/100\n98/98 [==============================] - 6s 60ms/step - loss: 0.0437 - accuracy: 0.0022 - val_loss: 0.5445 - val_accuracy: 0.0000e+00\nEpoch 62/100\n98/98 [==============================] - 6s 60ms/step - loss: 0.0426 - accuracy: 0.0022 - val_loss: 0.5570 - val_accuracy: 0.0000e+00\nEpoch 63/100\n98/98 [==============================] - 6s 60ms/step - loss: 0.0411 - accuracy: 0.0022 - val_loss: 0.5593 - val_accuracy: 0.0000e+00\nEpoch 64/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.0420 - accuracy: 0.0019 - val_loss: 0.5725 - val_accuracy: 0.0000e+00\nEpoch 65/100\n98/98 [==============================] - 6s 64ms/step - loss: 0.0405 - accuracy: 0.0019 - val_loss: 0.5468 - val_accuracy: 0.0000e+00\nEpoch 66/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.0384 - accuracy: 0.0022 - val_loss: 0.5570 - val_accuracy: 0.0000e+00\nEpoch 67/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.0358 - accuracy: 0.0022 - val_loss: 0.5622 - val_accuracy: 0.0000e+00\nEpoch 68/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0372 - accuracy: 0.0022 - val_loss: 0.5563 - val_accuracy: 0.0000e+00\nEpoch 69/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0375 - accuracy: 0.0022 - val_loss: 0.5596 - val_accuracy: 0.0000e+00\nEpoch 70/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.0363 - accuracy: 0.0022 - val_loss: 0.5624 - val_accuracy: 0.0000e+00\nEpoch 71/100\n98/98 [==============================] - 6s 64ms/step - loss: 0.0345 - accuracy: 0.0022 - val_loss: 0.5771 - val_accuracy: 0.0000e+00\nEpoch 72/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0334 - accuracy: 0.0016 - val_loss: 0.5500 - val_accuracy: 0.0000e+00\nEpoch 73/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.0335 - accuracy: 0.0019 - val_loss: 0.5711 - val_accuracy: 0.0000e+00\nEpoch 74/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0317 - accuracy: 0.0022 - val_loss: 0.5701 - val_accuracy: 0.0000e+00\nEpoch 75/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.0300 - accuracy: 0.0022 - val_loss: 0.5674 - val_accuracy: 0.0000e+00\nEpoch 76/100\n98/98 [==============================] - 6s 64ms/step - loss: 0.0292 - accuracy: 0.0022 - val_loss: 0.5664 - val_accuracy: 0.0000e+00\nEpoch 77/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0295 - accuracy: 0.0022 - val_loss: 0.5650 - val_accuracy: 0.0000e+00\nEpoch 78/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0292 - accuracy: 0.0022 - val_loss: 0.5768 - val_accuracy: 0.0000e+00\nEpoch 79/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.0277 - accuracy: 0.0022 - val_loss: 0.5723 - val_accuracy: 0.0000e+00\nEpoch 80/100\n98/98 [==============================] - 6s 60ms/step - loss: 0.0289 - accuracy: 0.0022 - val_loss: 0.5835 - val_accuracy: 0.0000e+00\nEpoch 81/100\n98/98 [==============================] - 6s 63ms/step - loss: 0.0272 - accuracy: 0.0022 - val_loss: 0.5884 - val_accuracy: 0.0000e+00\nEpoch 82/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.0275 - accuracy: 0.0022 - val_loss: 0.5880 - val_accuracy: 0.0000e+00\nEpoch 83/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.0267 - accuracy: 0.0022 - val_loss: 0.5683 - val_accuracy: 0.0000e+00\nEpoch 84/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0252 - accuracy: 0.0022 - val_loss: 0.5828 - val_accuracy: 0.0000e+00\nEpoch 85/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0261 - accuracy: 0.0022 - val_loss: 0.5781 - val_accuracy: 0.0000e+00\nEpoch 86/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0250 - accuracy: 0.0019 - val_loss: 0.5637 - val_accuracy: 0.0000e+00\nEpoch 87/100\n98/98 [==============================] - 6s 63ms/step - loss: 0.0251 - accuracy: 0.0022 - val_loss: 0.5574 - val_accuracy: 0.0000e+00\nEpoch 88/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0248 - accuracy: 0.0022 - val_loss: 0.5627 - val_accuracy: 0.0000e+00\nEpoch 89/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0244 - accuracy: 0.0022 - val_loss: 0.5736 - val_accuracy: 0.0000e+00\nEpoch 90/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0231 - accuracy: 0.0022 - val_loss: 0.5719 - val_accuracy: 0.0000e+00\nEpoch 91/100\n98/98 [==============================] - 6s 60ms/step - loss: 0.0244 - accuracy: 0.0022 - val_loss: 0.5523 - val_accuracy: 0.0000e+00\nEpoch 92/100\n98/98 [==============================] - 6s 66ms/step - loss: 0.0232 - accuracy: 0.0022 - val_loss: 0.5777 - val_accuracy: 0.0000e+00\nEpoch 93/100\n98/98 [==============================] - 6s 60ms/step - loss: 0.0229 - accuracy: 0.0022 - val_loss: 0.5751 - val_accuracy: 0.0000e+00\nEpoch 94/100\n98/98 [==============================] - 6s 60ms/step - loss: 0.0234 - accuracy: 0.0022 - val_loss: 0.5608 - val_accuracy: 0.0000e+00\nEpoch 95/100\n98/98 [==============================] - 6s 60ms/step - loss: 0.0207 - accuracy: 0.0022 - val_loss: 0.5465 - val_accuracy: 0.0000e+00\nEpoch 96/100\n98/98 [==============================] - 6s 60ms/step - loss: 0.0222 - accuracy: 0.0022 - val_loss: 0.5770 - val_accuracy: 0.0000e+00\nEpoch 97/100\n98/98 [==============================] - 6s 64ms/step - loss: 0.0214 - accuracy: 0.0022 - val_loss: 0.5854 - val_accuracy: 0.0000e+00\nEpoch 98/100\n98/98 [==============================] - 6s 60ms/step - loss: 0.0224 - accuracy: 0.0016 - val_loss: 0.5605 - val_accuracy: 0.0000e+00\nEpoch 99/100\n98/98 [==============================] - 6s 60ms/step - loss: 0.0225 - accuracy: 0.0019 - val_loss: 0.5744 - val_accuracy: 0.0000e+00\nEpoch 100/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0218 - accuracy: 0.0019 - val_loss: 0.5748 - val_accuracy: 0.0000e+00\n","output_type":"stream"},{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"3"},"metadata":{}}]},{"cell_type":"code","source":"lstm_model6 = get_model_lstm()\nlstm_model6.fit(lstm_embed_train, y6_train, epochs=100,validation_data=(lstm_embed_val,y6_val))\nlstm_result_6 = lstm_model6.predict(lstm_embed_test_final).flatten()\nlstm_result_6 = [int(r) for r in lstm_result_6]\nlen(lstm_result_6)","metadata":{"execution":{"iopub.status.busy":"2022-11-26T08:46:08.467456Z","iopub.execute_input":"2022-11-26T08:46:08.468643Z","iopub.status.idle":"2022-11-26T08:55:53.311462Z","shell.execute_reply.started":"2022-11-26T08:46:08.468595Z","shell.execute_reply":"2022-11-26T08:55:53.309934Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"Model: \"sequential_11\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nlstm_5 (LSTM)                (None, 1, 128)            11007488  \n_________________________________________________________________\ndropout_28 (Dropout)         (None, 1, 128)            0         \n_________________________________________________________________\ndense_34 (Dense)             (None, 1, 32)             4128      \n_________________________________________________________________\ndropout_29 (Dropout)         (None, 1, 32)             0         \n_________________________________________________________________\ndense_35 (Dense)             (None, 1, 1)              33        \n=================================================================\nTotal params: 11,011,649\nTrainable params: 11,011,649\nNon-trainable params: 0\n_________________________________________________________________\nEpoch 1/100\n98/98 [==============================] - 9s 63ms/step - loss: 1.6144 - accuracy: 0.0032 - val_loss: 0.4000 - val_accuracy: 0.0051\nEpoch 2/100\n98/98 [==============================] - 6s 63ms/step - loss: 0.5970 - accuracy: 0.0042 - val_loss: 0.3500 - val_accuracy: 0.0051\nEpoch 3/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.4721 - accuracy: 0.0042 - val_loss: 0.3249 - val_accuracy: 0.0051\nEpoch 4/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.4284 - accuracy: 0.0042 - val_loss: 0.3125 - val_accuracy: 0.0051\nEpoch 5/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.4070 - accuracy: 0.0042 - val_loss: 0.3181 - val_accuracy: 0.0051\nEpoch 6/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.3626 - accuracy: 0.0042 - val_loss: 0.3257 - val_accuracy: 0.0051\nEpoch 7/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.3439 - accuracy: 0.0042 - val_loss: 0.3350 - val_accuracy: 0.0051\nEpoch 8/100\n98/98 [==============================] - 6s 63ms/step - loss: 0.3393 - accuracy: 0.0042 - val_loss: 0.3368 - val_accuracy: 0.0051\nEpoch 9/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.3135 - accuracy: 0.0042 - val_loss: 0.3472 - val_accuracy: 0.0051\nEpoch 10/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.2831 - accuracy: 0.0042 - val_loss: 0.3554 - val_accuracy: 0.0051\nEpoch 11/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.2819 - accuracy: 0.0042 - val_loss: 0.3929 - val_accuracy: 0.0051\nEpoch 12/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.2681 - accuracy: 0.0042 - val_loss: 0.3763 - val_accuracy: 0.0051\nEpoch 13/100\n98/98 [==============================] - 6s 63ms/step - loss: 0.2730 - accuracy: 0.0042 - val_loss: 0.3803 - val_accuracy: 0.0051\nEpoch 14/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.2486 - accuracy: 0.0042 - val_loss: 0.4020 - val_accuracy: 0.0051\nEpoch 15/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.2399 - accuracy: 0.0042 - val_loss: 0.3871 - val_accuracy: 0.0051\nEpoch 16/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.2280 - accuracy: 0.0042 - val_loss: 0.3971 - val_accuracy: 0.0051\nEpoch 17/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.2165 - accuracy: 0.0042 - val_loss: 0.3974 - val_accuracy: 0.0051\nEpoch 18/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.2015 - accuracy: 0.0042 - val_loss: 0.4319 - val_accuracy: 0.0051\nEpoch 19/100\n98/98 [==============================] - 6s 63ms/step - loss: 0.2034 - accuracy: 0.0042 - val_loss: 0.4212 - val_accuracy: 0.0051\nEpoch 20/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.1853 - accuracy: 0.0042 - val_loss: 0.4386 - val_accuracy: 0.0051\nEpoch 21/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.1842 - accuracy: 0.0042 - val_loss: 0.4262 - val_accuracy: 0.0051\nEpoch 22/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.1850 - accuracy: 0.0042 - val_loss: 0.4152 - val_accuracy: 0.0051\nEpoch 23/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.1750 - accuracy: 0.0042 - val_loss: 0.4415 - val_accuracy: 0.0051\nEpoch 24/100\n98/98 [==============================] - 6s 63ms/step - loss: 0.1641 - accuracy: 0.0042 - val_loss: 0.4267 - val_accuracy: 0.0051\nEpoch 25/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.1596 - accuracy: 0.0042 - val_loss: 0.4508 - val_accuracy: 0.0051\nEpoch 26/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.1553 - accuracy: 0.0042 - val_loss: 0.4570 - val_accuracy: 0.0051\nEpoch 27/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.1509 - accuracy: 0.0042 - val_loss: 0.4296 - val_accuracy: 0.0051\nEpoch 28/100\n98/98 [==============================] - 6s 56ms/step - loss: 0.1391 - accuracy: 0.0042 - val_loss: 0.4411 - val_accuracy: 0.0051\nEpoch 29/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.1412 - accuracy: 0.0042 - val_loss: 0.4497 - val_accuracy: 0.0051\nEpoch 30/100\n98/98 [==============================] - 6s 62ms/step - loss: 0.1361 - accuracy: 0.0042 - val_loss: 0.4395 - val_accuracy: 0.0051\nEpoch 31/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.1285 - accuracy: 0.0042 - val_loss: 0.4662 - val_accuracy: 0.0051\nEpoch 32/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.1267 - accuracy: 0.0042 - val_loss: 0.4357 - val_accuracy: 0.0051\nEpoch 33/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.1137 - accuracy: 0.0042 - val_loss: 0.4550 - val_accuracy: 0.0051\nEpoch 34/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.1126 - accuracy: 0.0042 - val_loss: 0.4357 - val_accuracy: 0.0051\nEpoch 35/100\n98/98 [==============================] - 6s 63ms/step - loss: 0.1114 - accuracy: 0.0042 - val_loss: 0.4394 - val_accuracy: 0.0051\nEpoch 36/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.1077 - accuracy: 0.0042 - val_loss: 0.4641 - val_accuracy: 0.0051\nEpoch 37/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.1031 - accuracy: 0.0042 - val_loss: 0.4596 - val_accuracy: 0.0051\nEpoch 38/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0948 - accuracy: 0.0042 - val_loss: 0.4572 - val_accuracy: 0.0051\nEpoch 39/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0986 - accuracy: 0.0042 - val_loss: 0.4672 - val_accuracy: 0.0051\nEpoch 40/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0923 - accuracy: 0.0042 - val_loss: 0.4613 - val_accuracy: 0.0051\nEpoch 41/100\n98/98 [==============================] - 6s 63ms/step - loss: 0.0859 - accuracy: 0.0042 - val_loss: 0.4731 - val_accuracy: 0.0051\nEpoch 42/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0847 - accuracy: 0.0038 - val_loss: 0.4696 - val_accuracy: 0.0051\nEpoch 43/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0773 - accuracy: 0.0042 - val_loss: 0.4684 - val_accuracy: 0.0051\nEpoch 44/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.0801 - accuracy: 0.0038 - val_loss: 0.4704 - val_accuracy: 0.0051\nEpoch 45/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.0722 - accuracy: 0.0042 - val_loss: 0.4790 - val_accuracy: 0.0051\nEpoch 46/100\n98/98 [==============================] - 6s 66ms/step - loss: 0.0707 - accuracy: 0.0042 - val_loss: 0.4739 - val_accuracy: 0.0051\nEpoch 47/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0713 - accuracy: 0.0042 - val_loss: 0.4857 - val_accuracy: 0.0051\nEpoch 48/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0698 - accuracy: 0.0035 - val_loss: 0.4837 - val_accuracy: 0.0051\nEpoch 49/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0635 - accuracy: 0.0042 - val_loss: 0.4793 - val_accuracy: 0.0051\nEpoch 50/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.0598 - accuracy: 0.0042 - val_loss: 0.4782 - val_accuracy: 0.0051\nEpoch 51/100\n98/98 [==============================] - 6s 62ms/step - loss: 0.0621 - accuracy: 0.0042 - val_loss: 0.5126 - val_accuracy: 0.0051\nEpoch 52/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.0575 - accuracy: 0.0038 - val_loss: 0.4921 - val_accuracy: 0.0051\nEpoch 53/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0556 - accuracy: 0.0042 - val_loss: 0.4969 - val_accuracy: 0.0051\nEpoch 54/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.0546 - accuracy: 0.0042 - val_loss: 0.4900 - val_accuracy: 0.0051\nEpoch 55/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.0547 - accuracy: 0.0042 - val_loss: 0.4967 - val_accuracy: 0.0051\nEpoch 56/100\n98/98 [==============================] - 6s 63ms/step - loss: 0.0487 - accuracy: 0.0042 - val_loss: 0.5073 - val_accuracy: 0.0051\nEpoch 57/100\n98/98 [==============================] - 7s 68ms/step - loss: 0.0496 - accuracy: 0.0038 - val_loss: 0.4902 - val_accuracy: 0.0051\nEpoch 58/100\n98/98 [==============================] - 6s 62ms/step - loss: 0.0473 - accuracy: 0.0042 - val_loss: 0.5226 - val_accuracy: 0.0051\nEpoch 59/100\n98/98 [==============================] - 6s 61ms/step - loss: 0.0459 - accuracy: 0.0042 - val_loss: 0.5245 - val_accuracy: 0.0051\nEpoch 60/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.0416 - accuracy: 0.0038 - val_loss: 0.5109 - val_accuracy: 0.0051\nEpoch 61/100\n98/98 [==============================] - 6s 62ms/step - loss: 0.0432 - accuracy: 0.0042 - val_loss: 0.5320 - val_accuracy: 0.0051\nEpoch 62/100\n98/98 [==============================] - 6s 66ms/step - loss: 0.0391 - accuracy: 0.0042 - val_loss: 0.5298 - val_accuracy: 0.0051\nEpoch 63/100\n98/98 [==============================] - 6s 62ms/step - loss: 0.0386 - accuracy: 0.0035 - val_loss: 0.5081 - val_accuracy: 0.0051\nEpoch 64/100\n98/98 [==============================] - 6s 61ms/step - loss: 0.0393 - accuracy: 0.0042 - val_loss: 0.5281 - val_accuracy: 0.0051\nEpoch 65/100\n98/98 [==============================] - 6s 62ms/step - loss: 0.0367 - accuracy: 0.0038 - val_loss: 0.5125 - val_accuracy: 0.0051\nEpoch 66/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0370 - accuracy: 0.0042 - val_loss: 0.5117 - val_accuracy: 0.0051\nEpoch 67/100\n98/98 [==============================] - 6s 64ms/step - loss: 0.0357 - accuracy: 0.0038 - val_loss: 0.5132 - val_accuracy: 0.0051\nEpoch 68/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0347 - accuracy: 0.0042 - val_loss: 0.5287 - val_accuracy: 0.0051\nEpoch 69/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0317 - accuracy: 0.0042 - val_loss: 0.5188 - val_accuracy: 0.0051\nEpoch 70/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0343 - accuracy: 0.0042 - val_loss: 0.5124 - val_accuracy: 0.0051\nEpoch 71/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0301 - accuracy: 0.0035 - val_loss: 0.5123 - val_accuracy: 0.0051\nEpoch 72/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0308 - accuracy: 0.0042 - val_loss: 0.4953 - val_accuracy: 0.0051\nEpoch 73/100\n98/98 [==============================] - 6s 63ms/step - loss: 0.0314 - accuracy: 0.0038 - val_loss: 0.4989 - val_accuracy: 0.0051\nEpoch 74/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0305 - accuracy: 0.0042 - val_loss: 0.4982 - val_accuracy: 0.0051\nEpoch 75/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0280 - accuracy: 0.0042 - val_loss: 0.5144 - val_accuracy: 0.0051\nEpoch 76/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0262 - accuracy: 0.0038 - val_loss: 0.5158 - val_accuracy: 0.0051\nEpoch 77/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0272 - accuracy: 0.0042 - val_loss: 0.5136 - val_accuracy: 0.0051\nEpoch 78/100\n98/98 [==============================] - 6s 64ms/step - loss: 0.0264 - accuracy: 0.0042 - val_loss: 0.5310 - val_accuracy: 0.0051\nEpoch 79/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0264 - accuracy: 0.0038 - val_loss: 0.5297 - val_accuracy: 0.0051\nEpoch 80/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0262 - accuracy: 0.0042 - val_loss: 0.4979 - val_accuracy: 0.0051\nEpoch 81/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0252 - accuracy: 0.0038 - val_loss: 0.5004 - val_accuracy: 0.0051\nEpoch 82/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0247 - accuracy: 0.0042 - val_loss: 0.5061 - val_accuracy: 0.0051\nEpoch 83/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0245 - accuracy: 0.0035 - val_loss: 0.5109 - val_accuracy: 0.0051\nEpoch 84/100\n98/98 [==============================] - 6s 63ms/step - loss: 0.0248 - accuracy: 0.0042 - val_loss: 0.5066 - val_accuracy: 0.0051\nEpoch 85/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0244 - accuracy: 0.0042 - val_loss: 0.5202 - val_accuracy: 0.0051\nEpoch 86/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0237 - accuracy: 0.0038 - val_loss: 0.5114 - val_accuracy: 0.0051\nEpoch 87/100\n98/98 [==============================] - 6s 57ms/step - loss: 0.0219 - accuracy: 0.0042 - val_loss: 0.4984 - val_accuracy: 0.0051\nEpoch 88/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0229 - accuracy: 0.0042 - val_loss: 0.5140 - val_accuracy: 0.0051\nEpoch 89/100\n98/98 [==============================] - 6s 64ms/step - loss: 0.0220 - accuracy: 0.0042 - val_loss: 0.5228 - val_accuracy: 0.0051\nEpoch 90/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0220 - accuracy: 0.0042 - val_loss: 0.5175 - val_accuracy: 0.0051\nEpoch 91/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.0212 - accuracy: 0.0038 - val_loss: 0.5395 - val_accuracy: 0.0051\nEpoch 92/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0201 - accuracy: 0.0042 - val_loss: 0.5178 - val_accuracy: 0.0051\nEpoch 93/100\n98/98 [==============================] - 6s 58ms/step - loss: 0.0214 - accuracy: 0.0042 - val_loss: 0.5120 - val_accuracy: 0.0051\nEpoch 94/100\n98/98 [==============================] - 6s 63ms/step - loss: 0.0204 - accuracy: 0.0038 - val_loss: 0.5087 - val_accuracy: 0.0051\nEpoch 95/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.0206 - accuracy: 0.0042 - val_loss: 0.5087 - val_accuracy: 0.0051\nEpoch 96/100\n98/98 [==============================] - 6s 60ms/step - loss: 0.0200 - accuracy: 0.0042 - val_loss: 0.5056 - val_accuracy: 0.0051\nEpoch 97/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.0211 - accuracy: 0.0042 - val_loss: 0.5022 - val_accuracy: 0.0051\nEpoch 98/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.0199 - accuracy: 0.0038 - val_loss: 0.4918 - val_accuracy: 0.0051\nEpoch 99/100\n98/98 [==============================] - 6s 59ms/step - loss: 0.0192 - accuracy: 0.0035 - val_loss: 0.4961 - val_accuracy: 0.0051\nEpoch 100/100\n98/98 [==============================] - 6s 63ms/step - loss: 0.0185 - accuracy: 0.0042 - val_loss: 0.5098 - val_accuracy: 0.0051\n","output_type":"stream"},{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"3"},"metadata":{}}]},{"cell_type":"code","source":"results1 = embedding_model1.predict(lstm_embed_test).flatten()\nresults1= [round(r,1) for r in results1]  \n\nresults2 = embedding_model2.predict(lstm_embed_test).flatten()\nresults2 = [round(r,1) for r in results2]  \n\nresults3 = embedding_model3.predict(lstm_embed_test).flatten()\nresults3 = [round(r,1) for r in results3]  \n\nresults4 = embedding_model4.predict(lstm_embed_test).flatten()\nresults4 = [round(r,1) for r in results4]  \n\nresults5 = embedding_model5.predict(lstm_embed_test).flatten()\nresults5 = [round(r,1) for r in results5]  \n\nresults6 = embedding_model6.predict(lstm_embed_test).flatten()\nresults6 = [round(r,1) for r in results6]  ","metadata":{"execution":{"iopub.status.busy":"2022-11-26T08:55:53.313580Z","iopub.execute_input":"2022-11-26T08:55:53.314454Z","iopub.status.idle":"2022-11-26T08:55:55.141603Z","shell.execute_reply.started":"2022-11-26T08:55:53.314402Z","shell.execute_reply":"2022-11-26T08:55:55.140302Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"values1 = mean_squared_error(results1,y1_test)\nvalues2 = mean_squared_error(results2,y2_test)\nvalues3 = mean_squared_error(results3,y3_test)\nvalues4 = mean_squared_error(results4,y4_test)\nvalues5 = mean_squared_error(results5,y5_test)\nvalues6 = mean_squared_error(results6,y6_test)","metadata":{"execution":{"iopub.status.busy":"2022-11-26T08:55:55.143598Z","iopub.execute_input":"2022-11-26T08:55:55.144679Z","iopub.status.idle":"2022-11-26T08:55:55.152986Z","shell.execute_reply.started":"2022-11-26T08:55:55.144641Z","shell.execute_reply":"2022-11-26T08:55:55.152004Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"markdown","source":"Test error for LSTM","metadata":{}},{"cell_type":"code","source":"test_error=values1+values2+values3+values4+values5+values6\ntest_mcrmse= test_error/6\ntest_mcrmse","metadata":{"execution":{"iopub.status.busy":"2022-11-26T08:55:55.154661Z","iopub.execute_input":"2022-11-26T08:55:55.155407Z","iopub.status.idle":"2022-11-26T08:55:55.165399Z","shell.execute_reply.started":"2022-11-26T08:55:55.155367Z","shell.execute_reply":"2022-11-26T08:55:55.163927Z"},"trusted":true},"execution_count":60,"outputs":[{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"0.46996163308468525"},"metadata":{}}]},{"cell_type":"markdown","source":"# Random Forest","metadata":{}},{"cell_type":"code","source":"rf1 = RandomForestRegressor(n_estimators = 100, random_state = 42)\nrf1.fit(tfidf_train, y1_train)\ny1_pred = rf1.predict(tfidf_test)\ny1_pred = [round(r,1) for r in y1_pred]\n","metadata":{"execution":{"iopub.status.busy":"2022-11-26T08:55:55.169956Z","iopub.execute_input":"2022-11-26T08:55:55.170912Z","iopub.status.idle":"2022-11-26T09:00:28.521299Z","shell.execute_reply.started":"2022-11-26T08:55:55.170874Z","shell.execute_reply":"2022-11-26T09:00:28.519871Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"rf2 = RandomForestRegressor(n_estimators = 100, random_state = 42)\nrf2.fit(tfidf_train, y2_train)\ny2_pred = rf2.predict(tfidf_test)\ny2_pred = [round(r,1) for r in y2_pred]","metadata":{"execution":{"iopub.status.busy":"2022-11-26T09:00:28.522706Z","iopub.execute_input":"2022-11-26T09:00:28.523140Z","iopub.status.idle":"2022-11-26T09:04:51.534916Z","shell.execute_reply.started":"2022-11-26T09:00:28.523096Z","shell.execute_reply":"2022-11-26T09:04:51.533466Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"rf3 = RandomForestRegressor(n_estimators = 100, random_state = 42)\nrf3.fit(tfidf_train, y3_train)\ny3_pred = rf3.predict(tfidf_test)\ny3_pred = [round(r,1) for r in y3_pred]","metadata":{"execution":{"iopub.status.busy":"2022-11-26T09:04:51.536374Z","iopub.execute_input":"2022-11-26T09:04:51.536700Z","iopub.status.idle":"2022-11-26T09:09:23.727133Z","shell.execute_reply.started":"2022-11-26T09:04:51.536671Z","shell.execute_reply":"2022-11-26T09:09:23.725597Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"rf4 = RandomForestRegressor(n_estimators = 100, random_state = 42)\nrf4.fit(tfidf_train, y4_train)\ny4_pred = rf4.predict(tfidf_test)\ny4_pred = [round(r,1) for r in y4_pred]","metadata":{"execution":{"iopub.status.busy":"2022-11-26T09:09:23.728716Z","iopub.execute_input":"2022-11-26T09:09:23.729243Z","iopub.status.idle":"2022-11-26T09:13:51.972589Z","shell.execute_reply.started":"2022-11-26T09:09:23.729156Z","shell.execute_reply":"2022-11-26T09:13:51.971529Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"rf5 = RandomForestRegressor(n_estimators = 100, random_state = 42)\nrf5.fit(tfidf_train, y5_train)\ny5_pred = rf5.predict(tfidf_test)\ny5_pred = [round(r,1) for r in y5_pred]","metadata":{"execution":{"iopub.status.busy":"2022-11-26T09:13:51.974081Z","iopub.execute_input":"2022-11-26T09:13:51.974502Z","iopub.status.idle":"2022-11-26T09:18:23.213181Z","shell.execute_reply.started":"2022-11-26T09:13:51.974458Z","shell.execute_reply":"2022-11-26T09:18:23.211863Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"rf6 = RandomForestRegressor(n_estimators = 100, random_state = 42)\nrf6.fit(tfidf_train, y6_train)\ny6_pred = rf6.predict(tfidf_test)\ny6_pred = [round(r,1) for r in y6_pred]","metadata":{"execution":{"iopub.status.busy":"2022-11-26T09:18:23.214660Z","iopub.execute_input":"2022-11-26T09:18:23.215042Z","iopub.status.idle":"2022-11-26T09:23:02.222138Z","shell.execute_reply.started":"2022-11-26T09:18:23.215009Z","shell.execute_reply":"2022-11-26T09:23:02.221058Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"values1 = mean_squared_error(y1_pred,y1_test)\nvalues2 = mean_squared_error(y2_pred,y2_test)\nvalues3 = mean_squared_error(y3_pred,y3_test)\nvalues4 = mean_squared_error(y4_pred,y4_test)\nvalues5 = mean_squared_error(y5_pred,y5_test)\nvalues6 = mean_squared_error(y6_pred,y6_test)\n","metadata":{"execution":{"iopub.status.busy":"2022-11-26T09:23:02.223655Z","iopub.execute_input":"2022-11-26T09:23:02.224198Z","iopub.status.idle":"2022-11-26T09:23:02.231793Z","shell.execute_reply.started":"2022-11-26T09:23:02.224164Z","shell.execute_reply":"2022-11-26T09:23:02.230911Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"markdown","source":"Test error for Random Forest : ","metadata":{}},{"cell_type":"code","source":"test_error=values1+values2+values3+values4+values5+values6\ntest_mcrmse= test_error/6\ntest_mcrmse","metadata":{"execution":{"iopub.status.busy":"2022-11-26T09:23:02.233067Z","iopub.execute_input":"2022-11-26T09:23:02.234008Z","iopub.status.idle":"2022-11-26T09:23:02.247432Z","shell.execute_reply.started":"2022-11-26T09:23:02.233971Z","shell.execute_reply":"2022-11-26T09:23:02.246261Z"},"trusted":true},"execution_count":68,"outputs":[{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"0.30343563512361466"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Final predictions : ","metadata":{}},{"cell_type":"code","source":"t1=pd.read_csv(\"/kaggle/input/feedback-prize-english-language-learning/test.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Linear regression Predictions**","metadata":{}},{"cell_type":"code","source":"y1_pred = lr1.predict(test)\ny2_pred = lr2.predict(test)\ny3_pred = lr3.predict(test)\ny4_pred = lr4.predict(test)\ny5_pred = lr5.predict(test)\ny6_pred = lr6.predict(test)\n\n\ntest_lr1 = [round(r,1) for r in y1_pred]\ntest_lr2 = [round(r,1) for r in y2_pred]\ntest_lr3 = [round(r,1) for r in y3_pred]\ntest_lr4 = [round(r,1) for r in y4_pred]\ntest_lr5 = [round(r,1) for r in y5_pred]\ntest_lr6 = [round(r,1) for r in y6_pred]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_lr=pd.DataFrame()\n\nfinal_lr['text_id']=t1[\"text_id\"]\nfinal_lr['syntax']=test_lr1\nfinal_lr['cohesion']=test_lr2\nfinal_lr['vocabulary']=test_lr3\nfinal_lr['phraseology']=test_lr4\nfinal_lr['grammar']=test_lr5\nfinal_lr['conventions']=test_lr6  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_lr","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**SVR predictions**","metadata":{}},{"cell_type":"code","source":"y1_pred = clf1.predict(test)\ny2_pred = clf2.predict(test)\ny3_pred = clf3.predict(test)\ny4_pred = clf4.predict(test)\ny5_pred = clf5.predict(test)\ny6_pred = clf6.predict(test)\n\n\ntest_clf1 = [round(r,1) for r in y1_pred]\ntest_clf2 = [round(r,1) for r in y2_pred]\ntest_clf3 = [round(r,1) for r in y3_pred]\ntest_clf4 = [round(r,1) for r in y4_pred]\ntest_clf5 = [round(r,1) for r in y5_pred]\ntest_clf6 = [round(r,1) for r in y6_pred]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_clf=pd.DataFrame()\n\nfinal_clf['text_id']=t1[\"text_id\"]\nfinal_clf['syntax']=test_clf1\nfinal_clf['cohesion']=test_clf2\nfinal_clf['vocabulary']=test_clf3\nfinal_clf['phraseology']=test_clf4\nfinal_clf['grammar']=test_clf5\nfinal_clf['conventions']=test_clf6  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_clf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Neural Net predictions**","metadata":{}},{"cell_type":"code","source":"test1 = embedding_model1.predict(test).flatten()\ntest_nn1= [round(r,1) for r in test1]  \n\ntest2 = embedding_model2.predict(test).flatten()\ntest_nn2= [round(r,1) for r in test2]\n\ntest3 = embedding_model3.predict(test).flatten()\ntest_nn3= [round(r,1) for r in test3]\n\ntest4 = embedding_model4.predict(test).flatten()\ntest_nn4= [round(r,1) for r in test4]\n\ntest5 = embedding_model5.predict(test).flatten()\ntest_nn5= [round(r,1) for r in test5]\n\ntest6 = embedding_model6.predict(test).flatten()\ntest_nn6= [round(r,1) for r in test6]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_nn=pd.DataFrame()\n\nfinal_nn['text_id']=t1[\"text_id\"]\nfinal_nn['syntax']=test_nn1\nfinal_nn['cohesion']=test_nn2\nfinal_nn['vocabulary']=test_nn3\nfinal_nn['phraseology']=test_nn4\nfinal_nn['grammar']=test_nn5\nfinal_nn['conventions']=test_nn6","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_nn","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**LSTM predictions**","metadata":{}},{"cell_type":"code","source":"lstm_result_1 = lstm_model1.predict(lstm_embed_test_final).flatten()\nlstm_result_1 = [int(r) for r in lstm_result_1]\n\nlstm_result_2 = lstm_model2.predict(lstm_embed_test_final).flatten()\nlstm_result_2 = [int(r) for r in lstm_result_2]\n\nlstm_result_3 = lstm_model3.predict(lstm_embed_test_final).flatten()\nlstm_result_3 = [int(r) for r in lstm_result_3]\n\nlstm_result_4 = lstm_model4.predict(lstm_embed_test_final).flatten()\nlstm_result_4 = [int(r) for r in lstm_result_4]\n\nlstm_result_5 = lstm_model5.predict(lstm_embed_test_final).flatten()\nlstm_result_5 = [int(r) for r in lstm_result_5]\n\nlstm_result_6 = lstm_model6.predict(lstm_embed_test_final).flatten()\nlstm_result_6 = [int(r) for r in lstm_result_6]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_LSTM=pd.DataFrame()\n\nfinal_LSTM['text_id']=t1[\"text_id\"]\nfinal_LSTM['syntax']=lstm_result_1\nfinal_LSTM['cohesion']=lstm_result_2\nfinal_LSTM['vocabulary']=lstm_result_3\nfinal_LSTM['phraseology']=lstm_result_4\nfinal_LSTM['grammar']=lstm_result_5\nfinal_LSTM['conventions']=lstm_result_6","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_LSTM","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Random Forest predictions**","metadata":{}},{"cell_type":"code","source":"y1_pred = rf1.predict(test)\npred_rf1 = [round(r,1) for r in y1_pred]\n\ny2_pred = rf2.predict(test)\npred_rf2 = [round(r,1) for r in y2_pred]\n\ny3_pred = rf3.predict(test)\npred_rf3 = [round(r,1) for r in y3_pred]\n\ny4_pred = rf4.predict(test)\npred_rf4 = [round(r,1) for r in y4_pred]\n\ny4_pred = rf5.predict(test)\npred_rf5 = [round(r,1) for r in y5_pred]\n\ny6_pred = rf6.predict(test)\npred_rf6 = [round(r,1) for r in y6_pred]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_rf=pd.DataFrame()\n\nfinal_rf['text_id']=t1[\"text_id\"]\nfinal_rf['syntax']=pred_rf1\nfinal_rf['cohesion']=pred_rf2\nfinal_rf['vocabulary']=pred_rf3\nfinal_rf['phraseology']=pred_rf4\nfinal_rf['grammar']=pred_rf5\nfinal_rf['conventions']=pred_rf6","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_rf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**To csv...**","metadata":{}},{"cell_type":"code","source":"final_lr.to_csv('submission1.csv', index=False)\nfinal_clf.to_csv('submission2.csv', index=False)\nfinal_nn.to_csv('submission3.csv', index=False)\nfinal_LSTM.to_csv('submission4.csv', index=False)\nfinal_rf.to_csv('submission5.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}